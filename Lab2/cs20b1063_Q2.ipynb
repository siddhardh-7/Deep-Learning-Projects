{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siddhardha - CS20B1063"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward & Back-Propagation Learning Algorithm for Multiple  Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Implement the feedforward and backpropagation learning algorithm for multiple perceptrons in Python for the question provided in the attached image. Initialize the weights and biases randomly. Implement the forward pass. Compute the loss between the predicted output and the actual output using an appropriate loss function. Compute the gradients of the loss function with respect to the weights and biases using the chain rule. Update the weights and biases. Iterate over multiple times (epochs), performing forward propagation, loss calculation, backpropagation, and parameter updates in each iteration till convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported\n"
     ]
    }
   ],
   "source": [
    "# Importing Required Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Activation Function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative Of Sigmoid Function\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    # intializing the weights and biases\n",
    "    def __init__(self, learning_rate=1):\n",
    "        self.weights0 = np.random.rand(3, 2)\n",
    "        self.weights1 = np.random.rand(3, 2)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def feedforward(self):\n",
    "        self.hidden_layer_output = sigmoid(np.dot(self.input, self.weights0))\n",
    "        # adding a bias term to the hidden layer\n",
    "        self.hidden_layer_output = np.array([np.append(self.hidden_layer_output[0], 1)])\n",
    "        self.output = sigmoid(np.dot(self.hidden_layer_output, self.weights1))\n",
    "\n",
    "    def backprop(self):\n",
    "        # Application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights1_2 = np.dot(\n",
    "            self.hidden_layer_output.T,\n",
    "            (2 * (self.output - self.y) * sigmoid_derivative(self.output)),\n",
    "        )\n",
    "        back_prop_weights_1_2 = np.array([self.weights1[0], self.weights1[1]])\n",
    "        back_prop_hidden_layer_output = np.array(\n",
    "            (self.hidden_layer_output[0][0], self.hidden_layer_output[0][1])\n",
    "        )\n",
    "        d_weights0_1 = np.dot(\n",
    "            self.input.T,\n",
    "            (\n",
    "                np.dot(\n",
    "                    2 * (self.output - self.y) * sigmoid_derivative(self.output),\n",
    "                    back_prop_weights_1_2.T,\n",
    "                )\n",
    "                * sigmoid_derivative(back_prop_hidden_layer_output)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Applying gradient descent to update the weights\n",
    "        self.weights1 -= self.learning_rate * d_weights1_2\n",
    "        self.weights0 -= self.learning_rate * d_weights0_1\n",
    "\n",
    "    # function to train the model\n",
    "    def train(self, x, y, epochs=1000, early_stopping=True):\n",
    "        self.input = x\n",
    "        self.y = y\n",
    "        loss = []\n",
    "        for i in range(epochs):\n",
    "            self.feedforward()\n",
    "            self.backprop()\n",
    "\n",
    "            print(f\"Loss at iteration {i} : {self.mean_square_error()}\")\n",
    "            loss.append(self.mean_square_error())\n",
    "\n",
    "            # defining stopping criterion if MSE is less than 0.0001\n",
    "            if self.mean_square_error() < 0.0001 and early_stopping:\n",
    "                print(\n",
    "                    f\"Neural Network Converged at epoch {i} with loss {self.mean_square_error()}\"\n",
    "                )\n",
    "                break\n",
    "        return loss\n",
    "\n",
    "    # loss function\n",
    "    def mean_square_error(self):\n",
    "        return np.mean(np.square(self.y - self.output))\n",
    "\n",
    "    # function to print the weights of the model when called\n",
    "    def return_weights(self):\n",
    "        return f\"weights0_1 : {self.weights0} \\nweights1_2 : {self.weights1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 : 0.3499410688570656\n",
      "Loss at iteration 1 : 0.23003681939741769\n",
      "Loss at iteration 2 : 0.13831671113169206\n",
      "Loss at iteration 3 : 0.08283774420135093\n",
      "Loss at iteration 4 : 0.05196172170192472\n",
      "Loss at iteration 5 : 0.034511857083717526\n",
      "Loss at iteration 6 : 0.024142208474734604\n",
      "Loss at iteration 7 : 0.017634704862952735\n",
      "Loss at iteration 8 : 0.013344867509404845\n",
      "Loss at iteration 9 : 0.01039531241553961\n",
      "Loss at iteration 10 : 0.008293918534629515\n",
      "Loss at iteration 11 : 0.006751169448195074\n",
      "Loss at iteration 12 : 0.0055892840703365716\n",
      "Loss at iteration 13 : 0.0046948978386926795\n",
      "Loss at iteration 14 : 0.003993295876233413\n",
      "Loss at iteration 15 : 0.003433790728998285\n",
      "Loss at iteration 16 : 0.0029811092303779155\n",
      "Loss at iteration 17 : 0.0026101466071714223\n",
      "Loss at iteration 18 : 0.0023026744739186793\n",
      "Loss at iteration 19 : 0.0020452188944161047\n",
      "Loss at iteration 20 : 0.001827659328306154\n",
      "Loss at iteration 21 : 0.001642283269969902\n",
      "Loss at iteration 22 : 0.0014831357197075238\n",
      "Loss at iteration 23 : 0.001345563482588531\n",
      "Loss at iteration 24 : 0.0012258907129673712\n",
      "Loss at iteration 25 : 0.0011211844422626296\n",
      "Loss at iteration 26 : 0.0010290828039998022\n",
      "Loss at iteration 27 : 0.0009476675978131249\n",
      "Loss at iteration 28 : 0.0008753686422994123\n",
      "Loss at iteration 29 : 0.0008108912098456923\n",
      "Loss at iteration 30 : 0.000753160419775955\n",
      "Loss at iteration 31 : 0.000701278227943726\n",
      "Loss at iteration 32 : 0.0006544898688446009\n",
      "Loss at iteration 33 : 0.0006121574590227622\n",
      "Loss at iteration 34 : 0.0005737390746297343\n",
      "Loss at iteration 35 : 0.0005387720487146321\n",
      "Loss at iteration 36 : 0.0005068595470324128\n",
      "Loss at iteration 37 : 0.0004776597100860872\n",
      "Loss at iteration 38 : 0.0004508768179947699\n",
      "Loss at iteration 39 : 0.0004262540604430553\n",
      "Loss at iteration 40 : 0.00040356758824593435\n",
      "Loss at iteration 41 : 0.00038262159434827457\n",
      "Loss at iteration 42 : 0.00036324422637454994\n",
      "Loss at iteration 43 : 0.00034528417449240973\n",
      "Loss at iteration 44 : 0.0003286078105118101\n",
      "Loss at iteration 45 : 0.000313096779129966\n",
      "Loss at iteration 46 : 0.00029864596176686585\n",
      "Loss at iteration 47 : 0.0002851617487950002\n",
      "Loss at iteration 48 : 0.0002725605681092575\n",
      "Loss at iteration 49 : 0.00026076762763267626\n",
      "Loss at iteration 50 : 0.0002497158370612601\n",
      "Loss at iteration 51 : 0.00023934488033670504\n",
      "Loss at iteration 52 : 0.0002296004153233712\n",
      "Loss at iteration 53 : 0.00022043338120470335\n",
      "Loss at iteration 54 : 0.00021179939739910726\n",
      "Loss at iteration 55 : 0.00020365824047767348\n",
      "Loss at iteration 56 : 0.00019597338776509434\n",
      "Loss at iteration 57 : 0.000188711618114711\n",
      "Loss at iteration 58 : 0.00018184266184311749\n",
      "Loss at iteration 59 : 0.00017533889304832912\n",
      "Loss at iteration 60 : 0.00016917505856566236\n",
      "Loss at iteration 61 : 0.0001633280386746474\n",
      "Loss at iteration 62 : 0.0001577766353897213\n",
      "Loss at iteration 63 : 0.00015250138477100985\n",
      "Loss at iteration 64 : 0.00014748439019998783\n",
      "Loss at iteration 65 : 0.00014270917399393962\n",
      "Loss at iteration 66 : 0.00013816054509655754\n",
      "Loss at iteration 67 : 0.00013382448089047536\n",
      "Loss at iteration 68 : 0.000129688021440163\n",
      "Loss at iteration 69 : 0.00012573917469751216\n",
      "Loss at iteration 70 : 0.00012196683139421795\n",
      "Loss at iteration 71 : 0.00011836068850911758\n",
      "Loss at iteration 72 : 0.0001149111803400573\n",
      "Loss at iteration 73 : 0.00011160941633115267\n",
      "Loss at iteration 74 : 0.0001084471249114551\n",
      "Loss at iteration 75 : 0.00010541660269159378\n",
      "Loss at iteration 76 : 0.00010251066844368145\n",
      "Loss at iteration 77 : 9.972262135804805e-05\n",
      "Neural Network Converged at epoch 77 with loss 9.972262135804805e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3499410688570656,\n",
       " 0.23003681939741769,\n",
       " 0.13831671113169206,\n",
       " 0.08283774420135093,\n",
       " 0.05196172170192472,\n",
       " 0.034511857083717526,\n",
       " 0.024142208474734604,\n",
       " 0.017634704862952735,\n",
       " 0.013344867509404845,\n",
       " 0.01039531241553961,\n",
       " 0.008293918534629515,\n",
       " 0.006751169448195074,\n",
       " 0.0055892840703365716,\n",
       " 0.0046948978386926795,\n",
       " 0.003993295876233413,\n",
       " 0.003433790728998285,\n",
       " 0.0029811092303779155,\n",
       " 0.0026101466071714223,\n",
       " 0.0023026744739186793,\n",
       " 0.0020452188944161047,\n",
       " 0.001827659328306154,\n",
       " 0.001642283269969902,\n",
       " 0.0014831357197075238,\n",
       " 0.001345563482588531,\n",
       " 0.0012258907129673712,\n",
       " 0.0011211844422626296,\n",
       " 0.0010290828039998022,\n",
       " 0.0009476675978131249,\n",
       " 0.0008753686422994123,\n",
       " 0.0008108912098456923,\n",
       " 0.000753160419775955,\n",
       " 0.000701278227943726,\n",
       " 0.0006544898688446009,\n",
       " 0.0006121574590227622,\n",
       " 0.0005737390746297343,\n",
       " 0.0005387720487146321,\n",
       " 0.0005068595470324128,\n",
       " 0.0004776597100860872,\n",
       " 0.0004508768179947699,\n",
       " 0.0004262540604430553,\n",
       " 0.00040356758824593435,\n",
       " 0.00038262159434827457,\n",
       " 0.00036324422637454994,\n",
       " 0.00034528417449240973,\n",
       " 0.0003286078105118101,\n",
       " 0.000313096779129966,\n",
       " 0.00029864596176686585,\n",
       " 0.0002851617487950002,\n",
       " 0.0002725605681092575,\n",
       " 0.00026076762763267626,\n",
       " 0.0002497158370612601,\n",
       " 0.00023934488033670504,\n",
       " 0.0002296004153233712,\n",
       " 0.00022043338120470335,\n",
       " 0.00021179939739910726,\n",
       " 0.00020365824047767348,\n",
       " 0.00019597338776509434,\n",
       " 0.000188711618114711,\n",
       " 0.00018184266184311749,\n",
       " 0.00017533889304832912,\n",
       " 0.00016917505856566236,\n",
       " 0.0001633280386746474,\n",
       " 0.0001577766353897213,\n",
       " 0.00015250138477100985,\n",
       " 0.00014748439019998783,\n",
       " 0.00014270917399393962,\n",
       " 0.00013816054509655754,\n",
       " 0.00013382448089047536,\n",
       " 0.000129688021440163,\n",
       " 0.00012573917469751216,\n",
       " 0.00012196683139421795,\n",
       " 0.00011836068850911758,\n",
       " 0.0001149111803400573,\n",
       " 0.00011160941633115267,\n",
       " 0.0001084471249114551,\n",
       " 0.00010541660269159378,\n",
       " 0.00010251066844368145,\n",
       " 9.972262135804805e-05]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.train(np.array([[1, 0.91, 1.37]]), np.array([[1, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of learning rate 1: \n",
      "Loss at iteration 0 : 9.704620312969e-05\n",
      "Loss at iteration 1 : 9.447556347921696e-05\n",
      "Loss at iteration 2 : 9.200522875815696e-05\n",
      "Loss at iteration 3 : 8.963007332812937e-05\n",
      "Loss at iteration 4 : 8.734529343800728e-05\n",
      "Loss at iteration 5 : 8.514638335359252e-05\n",
      "Loss at iteration 6 : 8.302911352112494e-05\n",
      "Loss at iteration 7 : 8.098951056944163e-05\n",
      "Loss at iteration 8 : 7.902383897640357e-05\n",
      "Loss at iteration 9 : 7.712858424356924e-05\n",
      "Loss at iteration 10 : 7.530043743927721e-05\n",
      "Loss at iteration 11 : 7.353628098475193e-05\n",
      "Loss at iteration 12 : 7.183317557053848e-05\n",
      "Loss at iteration 13 : 7.018834810194644e-05\n",
      "Loss at iteration 14 : 6.859918058226064e-05\n",
      "Loss at iteration 15 : 6.706319985145642e-05\n",
      "Loss at iteration 16 : 6.557806810617147e-05\n",
      "Loss at iteration 17 : 6.414157413384448e-05\n",
      "Loss at iteration 18 : 6.275162520032215e-05\n",
      "Loss at iteration 19 : 6.140623953599561e-05\n",
      "Loss at iteration 20 : 6.010353937060537e-05\n",
      "Loss at iteration 21 : 5.8841744471542215e-05\n",
      "Loss at iteration 22 : 5.7619166144524074e-05\n",
      "Loss at iteration 23 : 5.64342016593359e-05\n",
      "Loss at iteration 24 : 5.528532906661835e-05\n",
      "Loss at iteration 25 : 5.4171102374727355e-05\n",
      "Loss at iteration 26 : 5.309014705843201e-05\n",
      "Loss at iteration 27 : 5.204115587366101e-05\n",
      "Loss at iteration 28 : 5.10228849547439e-05\n",
      "Loss at iteration 29 : 5.0034150172608834e-05\n",
      "Loss at iteration 30 : 4.907382373422118e-05\n",
      "Loss at iteration 31 : 4.8140831005232085e-05\n",
      "Loss at iteration 32 : 4.723414753922956e-05\n",
      "Loss at iteration 33 : 4.635279629848476e-05\n",
      "Loss at iteration 34 : 4.549584505217095e-05\n",
      "Loss at iteration 35 : 4.466240393930073e-05\n",
      "Loss at iteration 36 : 4.385162318456066e-05\n",
      "Loss at iteration 37 : 4.306269095621151e-05\n",
      "Loss at iteration 38 : 4.2294831356065666e-05\n",
      "Loss at iteration 39 : 4.1547302532338937e-05\n",
      "Loss at iteration 40 : 4.081939490686055e-05\n",
      "Loss at iteration 41 : 4.0110429508830825e-05\n",
      "Loss at iteration 42 : 3.9419756407869754e-05\n",
      "Loss at iteration 43 : 3.8746753239669786e-05\n",
      "Loss at iteration 44 : 3.8090823818051804e-05\n",
      "Loss at iteration 45 : 3.7451396827717195e-05\n",
      "Loss at iteration 46 : 3.6827924592361134e-05\n",
      "Loss at iteration 47 : 3.6219881913251066e-05\n",
      "Loss at iteration 48 : 3.562676497370545e-05\n",
      "Loss at iteration 49 : 3.504809030523637e-05\n",
      "Loss at iteration 50 : 3.448339381143397e-05\n",
      "Loss at iteration 51 : 3.3932229845927284e-05\n",
      "Loss at iteration 52 : 3.3394170341063174e-05\n",
      "Loss at iteration 53 : 3.2868803984109185e-05\n",
      "Loss at iteration 54 : 3.235573543806304e-05\n",
      "Loss at iteration 55 : 3.185458460434417e-05\n",
      "Loss at iteration 56 : 3.1364985924788343e-05\n",
      "Loss at iteration 57 : 3.088658772061415e-05\n",
      "Loss at iteration 58 : 3.0419051566097815e-05\n",
      "Loss at iteration 59 : 2.996205169493661e-05\n",
      "Loss at iteration 60 : 2.951527443733774e-05\n",
      "Loss at iteration 61 : 2.9078417686036246e-05\n",
      "Loss at iteration 62 : 2.86511903895846e-05\n",
      "Loss at iteration 63 : 2.823331207129008e-05\n",
      "Loss at iteration 64 : 2.7824512372370755e-05\n",
      "Loss at iteration 65 : 2.7424530617929038e-05\n",
      "Loss at iteration 66 : 2.7033115404451e-05\n",
      "Loss at iteration 67 : 2.6650024207632945e-05\n",
      "Loss at iteration 68 : 2.6275023009384432e-05\n",
      "Loss at iteration 69 : 2.5907885942963303e-05\n",
      "Loss at iteration 70 : 2.5548394955223393e-05\n",
      "Loss at iteration 71 : 2.5196339485067337e-05\n",
      "Loss at iteration 72 : 2.4851516157182025e-05\n",
      "Loss at iteration 73 : 2.4513728490287883e-05\n",
      "Loss at iteration 74 : 2.418278661906579e-05\n",
      "Loss at iteration 75 : 2.3858507029075044e-05\n",
      "Loss at iteration 76 : 2.3540712303961205e-05\n",
      "Loss at iteration 77 : 2.32292308843021e-05\n",
      "Loss at iteration 78 : 2.2923896837495155e-05\n",
      "Loss at iteration 79 : 2.2624549638098712e-05\n",
      "Loss at iteration 80 : 2.2331033958107485e-05\n",
      "Loss at iteration 81 : 2.2043199466642234e-05\n",
      "Loss at iteration 82 : 2.1760900638563377e-05\n",
      "Loss at iteration 83 : 2.1483996571584984e-05\n",
      "Loss at iteration 84 : 2.1212350811433945e-05\n",
      "Loss at iteration 85 : 2.094583118466993e-05\n",
      "Loss at iteration 86 : 2.0684309638779522e-05\n",
      "Loss at iteration 87 : 2.042766208918178e-05\n",
      "Loss at iteration 88 : 2.01757682728168e-05\n",
      "Loss at iteration 89 : 1.992851160798278e-05\n",
      "Loss at iteration 90 : 1.9685779060128893e-05\n",
      "Loss at iteration 91 : 1.9447461013320928e-05\n",
      "Loss at iteration 92 : 1.9213451147082773e-05\n",
      "Loss at iteration 93 : 1.898364631839731e-05\n",
      "Loss at iteration 94 : 1.875794644858483e-05\n",
      "Loss at iteration 95 : 1.853625441485393e-05\n",
      "Loss at iteration 96 : 1.8318475946295406e-05\n",
      "Loss at iteration 97 : 1.8104519524116704e-05\n",
      "Loss at iteration 98 : 1.7894296285913645e-05\n",
      "Loss at iteration 99 : 1.7687719933812088e-05\n",
      "Loss at iteration 100 : 1.7484706646270637e-05\n",
      "Loss at iteration 101 : 1.7285174993417216e-05\n",
      "Loss at iteration 102 : 1.7089045855725872e-05\n",
      "Loss at iteration 103 : 1.6896242345898126e-05\n",
      "Loss at iteration 104 : 1.6706689733815763e-05\n",
      "Loss at iteration 105 : 1.6520315374403294e-05\n",
      "Loss at iteration 106 : 1.633704863829406e-05\n",
      "Loss at iteration 107 : 1.6156820845169226e-05\n",
      "Loss at iteration 108 : 1.5979565199640007e-05\n",
      "Loss at iteration 109 : 1.5805216729593367e-05\n",
      "Loss at iteration 110 : 1.5633712226855703e-05\n",
      "Loss at iteration 111 : 1.5464990190109946e-05\n",
      "Loss at iteration 112 : 1.529899076993858e-05\n",
      "Loss at iteration 113 : 1.5135655715935481e-05\n",
      "Loss at iteration 114 : 1.4974928325764597e-05\n",
      "Loss at iteration 115 : 1.4816753396109254e-05\n",
      "Loss at iteration 116 : 1.4661077175418882e-05\n",
      "Loss at iteration 117 : 1.4507847318383702e-05\n",
      "Loss at iteration 118 : 1.435701284206663e-05\n",
      "Loss at iteration 119 : 1.420852408361773e-05\n",
      "Loss at iteration 120 : 1.4062332659513361e-05\n",
      "Loss at iteration 121 : 1.391839142625244e-05\n",
      "Loss at iteration 122 : 1.3776654442454877e-05\n",
      "Loss at iteration 123 : 1.3637076932302856e-05\n",
      "Loss at iteration 124 : 1.3499615250268037e-05\n",
      "Loss at iteration 125 : 1.3364226847083713e-05\n",
      "Loss at iteration 126 : 1.3230870236894595e-05\n",
      "Loss at iteration 127 : 1.3099504965560387e-05\n",
      "Loss at iteration 128 : 1.2970091580044176e-05\n",
      "Loss at iteration 129 : 1.2842591598859832e-05\n",
      "Loss at iteration 130 : 1.2716967483530181e-05\n",
      "Loss at iteration 131 : 1.2593182611020187e-05\n",
      "Loss at iteration 132 : 1.2471201247097056e-05\n",
      "Loss at iteration 133 : 1.2350988520599107e-05\n",
      "Loss at iteration 134 : 1.2232510398559806e-05\n",
      "Loss at iteration 135 : 1.2115733662173102e-05\n",
      "Loss at iteration 136 : 1.2000625883551899e-05\n",
      "Loss at iteration 137 : 1.188715540325223e-05\n",
      "Loss at iteration 138 : 1.1775291308550946e-05\n",
      "Loss at iteration 139 : 1.166500341242258e-05\n",
      "Loss at iteration 140 : 1.1556262233211595e-05\n",
      "Loss at iteration 141 : 1.1449038974962577e-05\n",
      "Loss at iteration 142 : 1.1343305508384137e-05\n",
      "Loss at iteration 143 : 1.1239034352430889e-05\n",
      "Loss at iteration 144 : 1.1136198656470439e-05\n",
      "Loss at iteration 145 : 1.103477218302726e-05\n",
      "Loss at iteration 146 : 1.0934729291063385e-05\n",
      "Loss at iteration 147 : 1.0836044919801866e-05\n",
      "Loss at iteration 148 : 1.0738694573045158e-05\n",
      "Loss at iteration 149 : 1.0642654303998202e-05\n",
      "Loss at iteration 150 : 1.0547900700553838e-05\n",
      "Loss at iteration 151 : 1.045441087104558e-05\n",
      "Loss at iteration 152 : 1.036216243043142e-05\n",
      "Loss at iteration 153 : 1.0271133486913525e-05\n",
      "Loss at iteration 154 : 1.0181302628956033e-05\n",
      "Loss at iteration 155 : 1.0092648912711772e-05\n",
      "Loss at iteration 156 : 1.0005151849822746e-05\n",
      "Loss at iteration 157 : 9.918791395591823e-06\n",
      "Loss at iteration 158 : 9.8335479375124e-06\n",
      "Loss at iteration 159 : 9.749402284142524e-06\n",
      "Loss at iteration 160 : 9.666335654308564e-06\n",
      "Loss at iteration 161 : 9.584329666634982e-06\n",
      "Loss at iteration 162 : 9.503366329377223e-06\n",
      "Loss at iteration 163 : 9.423428030561466e-06\n",
      "Loss at iteration 164 : 9.344497528413376e-06\n",
      "Loss at iteration 165 : 9.266557942061719e-06\n",
      "Loss at iteration 166 : 9.189592742517924e-06\n",
      "Loss at iteration 167 : 9.113585743915645e-06\n",
      "Loss at iteration 168 : 9.03852109500437e-06\n",
      "Loss at iteration 169 : 8.964383270885545e-06\n",
      "Loss at iteration 170 : 8.891157064990236e-06\n",
      "Loss at iteration 171 : 8.818827581279131e-06\n",
      "Loss at iteration 172 : 8.747380226671493e-06\n",
      "Loss at iteration 173 : 8.676800703683945e-06\n",
      "Loss at iteration 174 : 8.607075003277773e-06\n",
      "Loss at iteration 175 : 8.538189397907678e-06\n",
      "Loss at iteration 176 : 8.470130434766473e-06\n",
      "Loss at iteration 177 : 8.40288492921434e-06\n",
      "Loss at iteration 178 : 8.336439958395242e-06\n",
      "Loss at iteration 179 : 8.270782855023583e-06\n",
      "Loss at iteration 180 : 8.205901201350594e-06\n",
      "Loss at iteration 181 : 8.141782823288748e-06\n",
      "Loss at iteration 182 : 8.078415784698762e-06\n",
      "Loss at iteration 183 : 8.015788381836272e-06\n",
      "Loss at iteration 184 : 7.95388913794154e-06\n",
      "Loss at iteration 185 : 7.89270679798405e-06\n",
      "Loss at iteration 186 : 7.832230323539511e-06\n",
      "Loss at iteration 187 : 7.77244888781303e-06\n",
      "Loss at iteration 188 : 7.713351870788827e-06\n",
      "Loss at iteration 189 : 7.654928854510026e-06\n",
      "Loss at iteration 190 : 7.597169618488263e-06\n",
      "Loss at iteration 191 : 7.540064135226751e-06\n",
      "Loss at iteration 192 : 7.483602565869331e-06\n",
      "Loss at iteration 193 : 7.42777525595676e-06\n",
      "Loss at iteration 194 : 7.372572731298061e-06\n",
      "Loss at iteration 195 : 7.317985693947585e-06\n",
      "Loss at iteration 196 : 7.264005018286329e-06\n",
      "Loss at iteration 197 : 7.210621747206414e-06\n",
      "Loss at iteration 198 : 7.15782708838968e-06\n",
      "Loss at iteration 199 : 7.105612410686474e-06\n",
      "Loss at iteration 200 : 7.053969240583174e-06\n",
      "Loss at iteration 201 : 7.00288925876105e-06\n",
      "Loss at iteration 202 : 6.952364296744732e-06\n",
      "Loss at iteration 203 : 6.902386333629901e-06\n",
      "Loss at iteration 204 : 6.852947492897904e-06\n",
      "Loss at iteration 205 : 6.804040039311788e-06\n",
      "Loss at iteration 206 : 6.755656375881267e-06\n",
      "Loss at iteration 207 : 6.7077890409135145e-06\n",
      "Loss at iteration 208 : 6.660430705133486e-06\n",
      "Loss at iteration 209 : 6.613574168871335e-06\n",
      "Loss at iteration 210 : 6.567212359323397e-06\n",
      "Loss at iteration 211 : 6.521338327883688e-06\n",
      "Loss at iteration 212 : 6.475945247531385e-06\n",
      "Loss at iteration 213 : 6.431026410290489e-06\n",
      "Loss at iteration 214 : 6.386575224746853e-06\n",
      "Loss at iteration 215 : 6.342585213628109e-06\n",
      "Loss at iteration 216 : 6.2990500114386856e-06\n",
      "Loss at iteration 217 : 6.255963362155209e-06\n",
      "Loss at iteration 218 : 6.213319116975202e-06\n",
      "Loss at iteration 219 : 6.171111232118652e-06\n",
      "Loss at iteration 220 : 6.129333766684536e-06\n",
      "Loss at iteration 221 : 6.087980880558027e-06\n",
      "Loss at iteration 222 : 6.04704683236269e-06\n",
      "Loss at iteration 223 : 6.0065259774674e-06\n",
      "Loss at iteration 224 : 5.96641276603595e-06\n",
      "Loss at iteration 225 : 5.92670174112403e-06\n",
      "Loss at iteration 226 : 5.887387536817489e-06\n",
      "Loss at iteration 227 : 5.848464876421429e-06\n",
      "Loss at iteration 228 : 5.8099285706818075e-06\n",
      "Loss at iteration 229 : 5.771773516053318e-06\n",
      "Loss at iteration 230 : 5.7339946930087115e-06\n",
      "Loss at iteration 231 : 5.6965871643837485e-06\n",
      "Loss at iteration 232 : 5.659546073759527e-06\n",
      "Loss at iteration 233 : 5.622866643884533e-06\n",
      "Loss at iteration 234 : 5.5865441751318115e-06\n",
      "Loss at iteration 235 : 5.550574043988674e-06\n",
      "Loss at iteration 236 : 5.514951701584646e-06\n",
      "Loss at iteration 237 : 5.479672672247237e-06\n",
      "Loss at iteration 238 : 5.4447325520969455e-06\n",
      "Loss at iteration 239 : 5.410127007667056e-06\n",
      "Loss at iteration 240 : 5.375851774556948e-06\n",
      "Loss at iteration 241 : 5.341902656118735e-06\n",
      "Loss at iteration 242 : 5.308275522165908e-06\n",
      "Loss at iteration 243 : 5.274966307716041e-06\n",
      "Loss at iteration 244 : 5.241971011760409e-06\n",
      "Loss at iteration 245 : 5.209285696058571e-06\n",
      "Loss at iteration 246 : 5.176906483959576e-06\n",
      "Loss at iteration 247 : 5.144829559253359e-06\n",
      "Loss at iteration 248 : 5.113051165037681e-06\n",
      "Loss at iteration 249 : 5.081567602622673e-06\n",
      "Loss at iteration 250 : 5.050375230445562e-06\n",
      "Loss at iteration 251 : 5.019470463018624e-06\n",
      "Loss at iteration 252 : 4.9888497698956e-06\n",
      "Loss at iteration 253 : 4.9585096746611475e-06\n",
      "Loss at iteration 254 : 4.928446753939695e-06\n",
      "Loss at iteration 255 : 4.898657636430458e-06\n",
      "Loss at iteration 256 : 4.869139001957514e-06\n",
      "Loss at iteration 257 : 4.8398875805418574e-06\n",
      "Loss at iteration 258 : 4.810900151496323e-06\n",
      "Loss at iteration 259 : 4.782173542533609e-06\n",
      "Loss at iteration 260 : 4.753704628897443e-06\n",
      "Loss at iteration 261 : 4.725490332510852e-06\n",
      "Loss at iteration 262 : 4.697527621140215e-06\n",
      "Loss at iteration 263 : 4.669813507581719e-06\n",
      "Loss at iteration 264 : 4.642345048856855e-06\n",
      "Loss at iteration 265 : 4.6151193454322175e-06\n",
      "Loss at iteration 266 : 4.588133540450854e-06\n",
      "Loss at iteration 267 : 4.5613848189817415e-06\n",
      "Loss at iteration 268 : 4.534870407281948e-06\n",
      "Loss at iteration 269 : 4.508587572077137e-06\n",
      "Loss at iteration 270 : 4.482533619853903e-06\n",
      "Loss at iteration 271 : 4.456705896167726e-06\n",
      "Loss at iteration 272 : 4.431101784965549e-06\n",
      "Loss at iteration 273 : 4.405718707922145e-06\n",
      "Loss at iteration 274 : 4.380554123786419e-06\n",
      "Loss at iteration 275 : 4.355605527745862e-06\n",
      "Loss at iteration 276 : 4.330870450799406e-06\n",
      "Loss at iteration 277 : 4.30634645914761e-06\n",
      "Loss at iteration 278 : 4.282031153589263e-06\n",
      "Loss at iteration 279 : 4.257922168932593e-06\n",
      "Loss at iteration 280 : 4.234017173421956e-06\n",
      "Loss at iteration 281 : 4.210313868167873e-06\n",
      "Loss at iteration 282 : 4.1868099865946255e-06\n",
      "Loss at iteration 283 : 4.163503293898008e-06\n",
      "Loss at iteration 284 : 4.140391586508746e-06\n",
      "Loss at iteration 285 : 4.117472691573817e-06\n",
      "Loss at iteration 286 : 4.094744466441888e-06\n",
      "Loss at iteration 287 : 4.07220479816099e-06\n",
      "Loss at iteration 288 : 4.049851602986859e-06\n",
      "Loss at iteration 289 : 4.027682825898963e-06\n",
      "Loss at iteration 290 : 4.0056964401256025e-06\n",
      "Loss at iteration 291 : 3.983890446681492e-06\n",
      "Loss at iteration 292 : 3.962262873910118e-06\n",
      "Loss at iteration 293 : 3.940811777037781e-06\n",
      "Loss at iteration 294 : 3.919535237732616e-06\n",
      "Loss at iteration 295 : 3.898431363676851e-06\n",
      "Loss at iteration 296 : 3.877498288143708e-06\n",
      "Loss at iteration 297 : 3.856734169581801e-06\n",
      "Loss at iteration 298 : 3.8361371912105134e-06\n",
      "Loss at iteration 299 : 3.815705560621383e-06\n",
      "Loss at iteration 300 : 3.7954375093837984e-06\n",
      "Loss at iteration 301 : 3.7753312926651725e-06\n",
      "Loss at iteration 302 : 3.7553851888511713e-06\n",
      "Loss at iteration 303 : 3.735597499176066e-06\n",
      "Loss at iteration 304 : 3.7159665473612112e-06\n",
      "Loss at iteration 305 : 3.6964906792574818e-06\n",
      "Loss at iteration 306 : 3.677168262496504e-06\n",
      "Loss at iteration 307 : 3.6579976861449505e-06\n",
      "Loss at iteration 308 : 3.6389773603718088e-06\n",
      "Loss at iteration 309 : 3.6201057161131105e-06\n",
      "Loss at iteration 310 : 3.6013812047505753e-06\n",
      "Loss at iteration 311 : 3.5828022977901094e-06\n",
      "Loss at iteration 312 : 3.5643674865499795e-06\n",
      "Loss at iteration 313 : 3.5460752818542245e-06\n",
      "Loss at iteration 314 : 3.5279242137288716e-06\n",
      "Loss at iteration 315 : 3.5099128311059085e-06\n",
      "Loss at iteration 316 : 3.4920397015340277e-06\n",
      "Loss at iteration 317 : 3.474303410889835e-06\n",
      "Loss at iteration 318 : 3.456702563100411e-06\n",
      "Loss at iteration 319 : 3.439235779863482e-06\n",
      "Loss at iteration 320 : 3.4219017003809726e-06\n",
      "Loss at iteration 321 : 3.404698981088013e-06\n",
      "Loss at iteration 322 : 3.3876262953969296e-06\n",
      "Loss at iteration 323 : 3.3706823334352004e-06\n",
      "Loss at iteration 324 : 3.3538658017981766e-06\n",
      "Loss at iteration 325 : 3.337175423297257e-06\n",
      "Loss at iteration 326 : 3.320609936718612e-06\n",
      "Loss at iteration 327 : 3.3041680965829988e-06\n",
      "Loss at iteration 328 : 3.287848672910876e-06\n",
      "Loss at iteration 329 : 3.271650450993131e-06\n",
      "Loss at iteration 330 : 3.2555722311609684e-06\n",
      "Loss at iteration 331 : 3.239612828565047e-06\n",
      "Loss at iteration 332 : 3.22377107295651e-06\n",
      "Loss at iteration 333 : 3.2080458084692035e-06\n",
      "Loss at iteration 334 : 3.192435893411341e-06\n",
      "Loss at iteration 335 : 3.176940200054732e-06\n",
      "Loss at iteration 336 : 3.161557614431588e-06\n",
      "Loss at iteration 337 : 3.1462870361324775e-06\n",
      "Loss at iteration 338 : 3.131127378110423e-06\n",
      "Loss at iteration 339 : 3.116077566484525e-06\n",
      "Loss at iteration 340 : 3.10113654035027e-06\n",
      "Loss at iteration 341 : 3.086303251591847e-06\n",
      "Loss at iteration 342 : 3.0715766646969103e-06\n",
      "Loss at iteration 343 : 3.0569557565750233e-06\n",
      "Loss at iteration 344 : 3.0424395163799155e-06\n",
      "Loss at iteration 345 : 3.0280269453331697e-06\n",
      "Loss at iteration 346 : 3.0137170565531317e-06\n",
      "Loss at iteration 347 : 2.999508874883448e-06\n",
      "Loss at iteration 348 : 2.9854014367267466e-06\n",
      "Loss at iteration 349 : 2.9713937898820707e-06\n",
      "Loss at iteration 350 : 2.9574849933799605e-06\n",
      "Loss at iteration 351 : 2.9436741173286135e-06\n",
      "Loss at iteration 352 : 2.929960242753778e-06\n",
      "Loss at iteration 353 : 2.9163424614465144e-06\n",
      "Loss at iteration 354 : 2.90281987581238e-06\n",
      "Loss at iteration 355 : 2.8893915987229037e-06\n",
      "Loss at iteration 356 : 2.8760567533690925e-06\n",
      "Loss at iteration 357 : 2.862814473117737e-06\n",
      "Loss at iteration 358 : 2.8496639013707093e-06\n",
      "Loss at iteration 359 : 2.836604191424122e-06\n",
      "Loss at iteration 360 : 2.823634506332851e-06\n",
      "Loss at iteration 361 : 2.810754018775683e-06\n",
      "Loss at iteration 362 : 2.7979619109226673e-06\n",
      "Loss at iteration 363 : 2.7852573743038506e-06\n",
      "Loss at iteration 364 : 2.7726396096819995e-06\n",
      "Loss at iteration 365 : 2.7601078269262088e-06\n",
      "Loss at iteration 366 : 2.747661244887608e-06\n",
      "Loss at iteration 367 : 2.735299091275705e-06\n",
      "Loss at iteration 368 : 2.7230206025405968e-06\n",
      "Loss at iteration 369 : 2.7108250237525373e-06\n",
      "Loss at iteration 370 : 2.6987116084854632e-06\n",
      "Loss at iteration 371 : 2.686679618703497e-06\n",
      "Loss at iteration 372 : 2.6747283246473164e-06\n",
      "Loss at iteration 373 : 2.662857004721641e-06\n",
      "Loss at iteration 374 : 2.6510649453883236e-06\n",
      "Loss at iteration 375 : 2.6393514410573187e-06\n",
      "Loss at iteration 376 : 2.627715793979824e-06\n",
      "Loss at iteration 377 : 2.6161573141449947e-06\n",
      "Loss at iteration 378 : 2.604675319177813e-06\n",
      "Loss at iteration 379 : 2.5932691342349105e-06\n",
      "Loss at iteration 380 : 2.5819380919094135e-06\n",
      "Loss at iteration 381 : 2.570681532128769e-06\n",
      "Loss at iteration 382 : 2.5594988020603455e-06\n",
      "Loss at iteration 383 : 2.5483892560155194e-06\n",
      "Loss at iteration 384 : 2.5373522553569013e-06\n",
      "Loss at iteration 385 : 2.526387168404272e-06\n",
      "Loss at iteration 386 : 2.515493370346518e-06\n",
      "Loss at iteration 387 : 2.5046702431494845e-06\n",
      "Loss at iteration 388 : 2.493917175468672e-06\n",
      "Loss at iteration 389 : 2.4832335625647336e-06\n",
      "Loss at iteration 390 : 2.4726188062145247e-06\n",
      "Loss at iteration 391 : 2.462072314628776e-06\n",
      "Loss at iteration 392 : 2.4515935023693054e-06\n",
      "Loss at iteration 393 : 2.4411817902674488e-06\n",
      "Loss at iteration 394 : 2.4308366053419965e-06\n",
      "Loss at iteration 395 : 2.420557380722688e-06\n",
      "Loss at iteration 396 : 2.410343555569395e-06\n",
      "Loss at iteration 397 : 2.400194574997942e-06\n",
      "Loss at iteration 398 : 2.390109890001215e-06\n",
      "Loss at iteration 399 : 2.3800889573782044e-06\n",
      "Loss at iteration 400 : 2.370131239657145e-06\n",
      "Loss at iteration 401 : 2.360236205024895e-06\n",
      "Loss at iteration 402 : 2.3504033272558216e-06\n",
      "Loss at iteration 403 : 2.340632085640104e-06\n",
      "Loss at iteration 404 : 2.3309219649153348e-06\n",
      "Loss at iteration 405 : 2.3212724551980023e-06\n",
      "Loss at iteration 406 : 2.311683051917311e-06\n",
      "Loss at iteration 407 : 2.3021532557463064e-06\n",
      "Loss at iteration 408 : 2.2926825725391576e-06\n",
      "Loss at iteration 409 : 2.2832705132655426e-06\n",
      "Loss at iteration 410 : 2.2739165939472843e-06\n",
      "Loss at iteration 411 : 2.264620335596312e-06\n",
      "Loss at iteration 412 : 2.255381264152076e-06\n",
      "Loss at iteration 413 : 2.24619891042156e-06\n",
      "Loss at iteration 414 : 2.237072810019084e-06\n",
      "Loss at iteration 415 : 2.2280025033073857e-06\n",
      "Loss at iteration 416 : 2.2189875353399415e-06\n",
      "Loss at iteration 417 : 2.2100274558028976e-06\n",
      "Loss at iteration 418 : 2.2011218189582333e-06\n",
      "Loss at iteration 419 : 2.1922701835895723e-06\n",
      "Loss at iteration 420 : 2.183472112944878e-06\n",
      "Loss at iteration 421 : 2.1747271746851885e-06\n",
      "Loss at iteration 422 : 2.1660349408282485e-06\n",
      "Loss at iteration 423 : 2.1573949876990415e-06\n",
      "Loss at iteration 424 : 2.148806895874317e-06\n",
      "Loss at iteration 425 : 2.140270250134531e-06\n",
      "Loss at iteration 426 : 2.131784639411903e-06\n",
      "Loss at iteration 427 : 2.12334965673979e-06\n",
      "Loss at iteration 428 : 2.1149648992069106e-06\n",
      "Loss at iteration 429 : 2.106629967904841e-06\n",
      "Loss at iteration 430 : 2.098344467883182e-06\n",
      "Loss at iteration 431 : 2.090108008101566e-06\n",
      "Loss at iteration 432 : 2.081920201382706e-06\n",
      "Loss at iteration 433 : 2.0737806643677907e-06\n",
      "Loss at iteration 434 : 2.0656890174709535e-06\n",
      "Loss at iteration 435 : 2.057644884834809e-06\n",
      "Loss at iteration 436 : 2.0496478942854477e-06\n",
      "Loss at iteration 437 : 2.041697677291253e-06\n",
      "Loss at iteration 438 : 2.0337938689178505e-06\n",
      "Loss at iteration 439 : 2.0259361077889427e-06\n",
      "Loss at iteration 440 : 2.018124036041183e-06\n",
      "Loss at iteration 441 : 2.010357299286655e-06\n",
      "Loss at iteration 442 : 2.0026355465700766e-06\n",
      "Loss at iteration 443 : 1.994958430329936e-06\n",
      "Loss at iteration 444 : 1.987325606358866e-06\n",
      "Loss at iteration 445 : 1.97973673376549e-06\n",
      "Loss at iteration 446 : 1.972191474934821e-06\n",
      "Loss at iteration 447 : 1.964689495491654e-06\n",
      "Loss at iteration 448 : 1.9572304642635323e-06\n",
      "Loss at iteration 449 : 1.9498140532429303e-06\n",
      "Loss at iteration 450 : 1.942439937551552e-06\n",
      "Loss at iteration 451 : 1.9351077954043624e-06\n",
      "Loss at iteration 452 : 1.9278173080745055e-06\n",
      "Loss at iteration 453 : 1.9205681598584748e-06\n",
      "Loss at iteration 454 : 1.9133600380419674e-06\n",
      "Loss at iteration 455 : 1.906192632865478e-06\n",
      "Loss at iteration 456 : 1.8990656374907585e-06\n",
      "Loss at iteration 457 : 1.891978747968316e-06\n",
      "Loss at iteration 458 : 1.884931663204609e-06\n",
      "Loss at iteration 459 : 1.8779240849294289e-06\n",
      "Loss at iteration 460 : 1.870955717665478e-06\n",
      "Loss at iteration 461 : 1.8640262686951162e-06\n",
      "Loss at iteration 462 : 1.8571354480311194e-06\n",
      "Loss at iteration 463 : 1.8502829683854465e-06\n",
      "Loss at iteration 464 : 1.8434685451388282e-06\n",
      "Loss at iteration 465 : 1.8366918963123571e-06\n",
      "Loss at iteration 466 : 1.829952742536069e-06\n",
      "Loss at iteration 467 : 1.823250807022149e-06\n",
      "Loss at iteration 468 : 1.8165858155344922e-06\n",
      "Loss at iteration 469 : 1.8099574963618576e-06\n",
      "Loss at iteration 470 : 1.8033655802893617e-06\n",
      "Loss at iteration 471 : 1.7968098005712452e-06\n",
      "Loss at iteration 472 : 1.7902898929029577e-06\n",
      "Loss at iteration 473 : 1.7838055953961512e-06\n",
      "Loss at iteration 474 : 1.7773566485501953e-06\n",
      "Loss at iteration 475 : 1.7709427952272399e-06\n",
      "Loss at iteration 476 : 1.7645637806262546e-06\n",
      "Loss at iteration 477 : 1.7582193522576639e-06\n",
      "Loss at iteration 478 : 1.7519092599167858e-06\n",
      "Loss at iteration 479 : 1.7456332556627382e-06\n",
      "Loss at iteration 480 : 1.7393910937885216e-06\n",
      "Loss at iteration 481 : 1.7331825308022043e-06\n",
      "Loss at iteration 482 : 1.727007325399321e-06\n",
      "Loss at iteration 483 : 1.7208652384408334e-06\n",
      "Loss at iteration 484 : 1.7147560329302106e-06\n",
      "Loss at iteration 485 : 1.7086794739883644e-06\n",
      "Loss at iteration 486 : 1.7026353288344001e-06\n",
      "Loss at iteration 487 : 1.6966233667592734e-06\n",
      "Loss at iteration 488 : 1.690643359106376e-06\n",
      "Loss at iteration 489 : 1.6846950792497917e-06\n",
      "Loss at iteration 490 : 1.678778302569773e-06\n",
      "Loss at iteration 491 : 1.6728928064351054e-06\n",
      "Loss at iteration 492 : 1.6670383701794972e-06\n",
      "Loss at iteration 493 : 1.6612147750815284e-06\n",
      "Loss at iteration 494 : 1.6554218043449512e-06\n",
      "Loss at iteration 495 : 1.6496592430766968e-06\n",
      "Loss at iteration 496 : 1.6439268782685454e-06\n",
      "Loss at iteration 497 : 1.6382244987756941e-06\n",
      "Loss at iteration 498 : 1.6325518952988363e-06\n",
      "Loss at iteration 499 : 1.6269088603636054e-06\n",
      "Loss at iteration 500 : 1.6212951883019464e-06\n",
      "Loss at iteration 501 : 1.6157106752336783e-06\n",
      "Loss at iteration 502 : 1.6101551190465256e-06\n",
      "Loss at iteration 503 : 1.60462831937993e-06\n",
      "Loss at iteration 504 : 1.5991300776043794e-06\n",
      "Loss at iteration 505 : 1.593660196805104e-06\n",
      "Loss at iteration 506 : 1.5882184817641085e-06\n",
      "Loss at iteration 507 : 1.5828047389422097e-06\n",
      "Loss at iteration 508 : 1.5774187764621914e-06\n",
      "Loss at iteration 509 : 1.5720604040910424e-06\n",
      "Loss at iteration 510 : 1.5667294332237631e-06\n",
      "Loss at iteration 511 : 1.5614256768662495e-06\n",
      "Loss at iteration 512 : 1.5561489496191224e-06\n",
      "Loss at iteration 513 : 1.5508990676609503e-06\n",
      "Loss at iteration 514 : 1.5456758487327025e-06\n",
      "Loss at iteration 515 : 1.5404791121216034e-06\n",
      "Loss at iteration 516 : 1.5353086786451362e-06\n",
      "Loss at iteration 517 : 1.5301643706356698e-06\n",
      "Loss at iteration 518 : 1.525046011925381e-06\n",
      "Loss at iteration 519 : 1.519953427830573e-06\n",
      "Loss at iteration 520 : 1.5148864451373523e-06\n",
      "Loss at iteration 521 : 1.5098448920862467e-06\n",
      "Loss at iteration 522 : 1.5048285983577195e-06\n",
      "Loss at iteration 523 : 1.4998373950575282e-06\n",
      "Loss at iteration 524 : 1.4948711147032702e-06\n",
      "Loss at iteration 525 : 1.4899295912086816e-06\n",
      "Loss at iteration 526 : 1.4850126598713481e-06\n",
      "Loss at iteration 527 : 1.4801201573572833e-06\n",
      "Loss at iteration 528 : 1.475251921689352e-06\n",
      "Loss at iteration 529 : 1.4704077922312212e-06\n",
      "Loss at iteration 530 : 1.4655876096761983e-06\n",
      "Loss at iteration 531 : 1.4607912160332206e-06\n",
      "Loss at iteration 532 : 1.4560184546128334e-06\n",
      "Loss at iteration 533 : 1.4512691700168373e-06\n",
      "Loss at iteration 534 : 1.4465432081225996e-06\n",
      "Loss at iteration 535 : 1.4418404160729316e-06\n",
      "Loss at iteration 536 : 1.4371606422618373e-06\n",
      "Loss at iteration 537 : 1.4325037363235948e-06\n",
      "Loss at iteration 538 : 1.4278695491199054e-06\n",
      "Loss at iteration 539 : 1.4232579327271738e-06\n",
      "Loss at iteration 540 : 1.4186687404269476e-06\n",
      "Loss at iteration 541 : 1.4141018266910876e-06\n",
      "Loss at iteration 542 : 1.4095570471727288e-06\n",
      "Loss at iteration 543 : 1.40503425869341e-06\n",
      "Loss at iteration 544 : 1.4005333192325146e-06\n",
      "Loss at iteration 545 : 1.396054087915342e-06\n",
      "Loss at iteration 546 : 1.3915964250018872e-06\n",
      "Loss at iteration 547 : 1.38716019187744e-06\n",
      "Loss at iteration 548 : 1.3827452510396897e-06\n",
      "Loss at iteration 549 : 1.3783514660892456e-06\n",
      "Loss at iteration 550 : 1.3739787017186685e-06\n",
      "Loss at iteration 551 : 1.3696268237023216e-06\n",
      "Loss at iteration 552 : 1.365295698885325e-06\n",
      "Loss at iteration 553 : 1.3609851951737349e-06\n",
      "Loss at iteration 554 : 1.3566951815249752e-06\n",
      "Loss at iteration 555 : 1.35242552793664e-06\n",
      "Loss at iteration 556 : 1.3481761054372497e-06\n",
      "Loss at iteration 557 : 1.3439467860765278e-06\n",
      "Loss at iteration 558 : 1.3397374429150524e-06\n",
      "Loss at iteration 559 : 1.3355479500159889e-06\n",
      "Loss at iteration 560 : 1.3313781824346375e-06\n",
      "Loss at iteration 561 : 1.327228016208222e-06\n",
      "Loss at iteration 562 : 1.3230973283488576e-06\n",
      "Loss at iteration 563 : 1.3189859968323772e-06\n",
      "Loss at iteration 564 : 1.314893900590347e-06\n",
      "Loss at iteration 565 : 1.3108209195008874e-06\n",
      "Loss at iteration 566 : 1.3067669343790223e-06\n",
      "Loss at iteration 567 : 1.3027318269692097e-06\n",
      "Loss at iteration 568 : 1.2987154799355728e-06\n",
      "Loss at iteration 569 : 1.294717776854302e-06\n",
      "Loss at iteration 570 : 1.2907386022043275e-06\n",
      "Loss at iteration 571 : 1.2867778413587558e-06\n",
      "Loss at iteration 572 : 1.2828353805779279e-06\n",
      "Loss at iteration 573 : 1.2789111069993392e-06\n",
      "Loss at iteration 574 : 1.2750049086312522e-06\n",
      "Loss at iteration 575 : 1.2711166743434658e-06\n",
      "Loss at iteration 576 : 1.2672462938596868e-06\n",
      "Loss at iteration 577 : 1.2633936577499649e-06\n",
      "Loss at iteration 578 : 1.2595586574226432e-06\n",
      "Loss at iteration 579 : 1.2557411851168093e-06\n",
      "Loss at iteration 580 : 1.2519411338942367e-06\n",
      "Loss at iteration 581 : 1.2481583976322524e-06\n",
      "Loss at iteration 582 : 1.2443928710160915e-06\n",
      "Loss at iteration 583 : 1.2406444495322893e-06\n",
      "Loss at iteration 584 : 1.2369130294598217e-06\n",
      "Loss at iteration 585 : 1.2331985078645726e-06\n",
      "Loss at iteration 586 : 1.229500782590331e-06\n",
      "Loss at iteration 587 : 1.2258197522540667e-06\n",
      "Loss at iteration 588 : 1.2221553162369177e-06\n",
      "Loss at iteration 589 : 1.218507374678224e-06\n",
      "Loss at iteration 590 : 1.2148758284682781e-06\n",
      "Loss at iteration 591 : 1.2112605792416602e-06\n",
      "Loss at iteration 592 : 1.207661529370914e-06\n",
      "Loss at iteration 593 : 1.2040785819595987e-06\n",
      "Loss at iteration 594 : 1.2005116408355443e-06\n",
      "Loss at iteration 595 : 1.1969606105449575e-06\n",
      "Loss at iteration 596 : 1.1934253963445847e-06\n",
      "Loss at iteration 597 : 1.189905904197404e-06\n",
      "Loss at iteration 598 : 1.1864020407650319e-06\n",
      "Loss at iteration 599 : 1.1829137134012524e-06\n",
      "Loss at iteration 600 : 1.1794408301466663e-06\n",
      "Loss at iteration 601 : 1.1759832997226003e-06\n",
      "Loss at iteration 602 : 1.1725410315243884e-06\n",
      "Loss at iteration 603 : 1.169113935615789e-06\n",
      "Loss at iteration 604 : 1.1657019227225097e-06\n",
      "Loss at iteration 605 : 1.1623049042279104e-06\n",
      "Loss at iteration 606 : 1.1589227921654326e-06\n",
      "Loss at iteration 607 : 1.1555554992138828e-06\n",
      "Loss at iteration 608 : 1.1522029386911524e-06\n",
      "Loss at iteration 609 : 1.1488650245494509e-06\n",
      "Loss at iteration 610 : 1.1455416713688733e-06\n",
      "Loss at iteration 611 : 1.1422327943521978e-06\n",
      "Loss at iteration 612 : 1.138938309319986e-06\n",
      "Loss at iteration 613 : 1.1356581327044256e-06\n",
      "Loss at iteration 614 : 1.132392181543489e-06\n",
      "Loss at iteration 615 : 1.1291403734777303e-06\n",
      "Loss at iteration 616 : 1.1259026267433507e-06\n",
      "Loss at iteration 617 : 1.1226788601672734e-06\n",
      "Loss at iteration 618 : 1.1194689931618582e-06\n",
      "Loss at iteration 619 : 1.116272945720579e-06\n",
      "Loss at iteration 620 : 1.113090638412946e-06\n",
      "Loss at iteration 621 : 1.1099219923785933e-06\n",
      "Loss at iteration 622 : 1.1067669293231915e-06\n",
      "Loss at iteration 623 : 1.103625371512999e-06\n",
      "Loss at iteration 624 : 1.1004972417709888e-06\n",
      "Loss at iteration 625 : 1.0973824634713462e-06\n",
      "Loss at iteration 626 : 1.09428096053427e-06\n",
      "Loss at iteration 627 : 1.091192657422599e-06\n",
      "Loss at iteration 628 : 1.0881174791360485e-06\n",
      "Loss at iteration 629 : 1.0850553512071482e-06\n",
      "Loss at iteration 630 : 1.0820061996968334e-06\n",
      "Loss at iteration 631 : 1.0789699511898162e-06\n",
      "Loss at iteration 632 : 1.075946532789362e-06\n",
      "Loss at iteration 633 : 1.0729358721140124e-06\n",
      "Loss at iteration 634 : 1.0699378972931889e-06\n",
      "Loss at iteration 635 : 1.0669525369617046e-06\n",
      "Loss at iteration 636 : 1.063979720256961e-06\n",
      "Loss at iteration 637 : 1.0610193768136578e-06\n",
      "Loss at iteration 638 : 1.058071436759798e-06\n",
      "Loss at iteration 639 : 1.0551358307128494e-06\n",
      "Loss at iteration 640 : 1.0522124897756951e-06\n",
      "Loss at iteration 641 : 1.0493013455319824e-06\n",
      "Loss at iteration 642 : 1.046402330043009e-06\n",
      "Loss at iteration 643 : 1.0435153758422754e-06\n",
      "Loss at iteration 644 : 1.0406404159334293e-06\n",
      "Loss at iteration 645 : 1.0377773837845107e-06\n",
      "Loss at iteration 646 : 1.0349262133257038e-06\n",
      "Loss at iteration 647 : 1.0320868389440239e-06\n",
      "Loss at iteration 648 : 1.029259195480761e-06\n",
      "Loss at iteration 649 : 1.0264432182272142e-06\n",
      "Loss at iteration 650 : 1.0236388429199694e-06\n",
      "Loss at iteration 651 : 1.020846005739668e-06\n",
      "Loss at iteration 652 : 1.0180646433043603e-06\n",
      "Loss at iteration 653 : 1.0152946926685788e-06\n",
      "Loss at iteration 654 : 1.012536091317746e-06\n",
      "Loss at iteration 655 : 1.0097887771655707e-06\n",
      "Loss at iteration 656 : 1.007052688550854e-06\n",
      "Loss at iteration 657 : 1.0043277642329775e-06\n",
      "Loss at iteration 658 : 1.0016139433894983e-06\n",
      "Loss at iteration 659 : 9.989111656114498e-07\n",
      "Loss at iteration 660 : 9.9621937090197e-07\n",
      "Loss at iteration 661 : 9.935384996703104e-07\n",
      "Loss at iteration 662 : 9.908684927312496e-07\n",
      "Loss at iteration 663 : 9.882092912996466e-07\n",
      "Loss at iteration 664 : 9.855608369881937e-07\n",
      "Loss at iteration 665 : 9.829230718044629e-07\n",
      "Loss at iteration 666 : 9.802959381466426e-07\n",
      "Loss at iteration 667 : 9.776793788014758e-07\n",
      "Loss at iteration 668 : 9.750733369403004e-07\n",
      "Loss at iteration 669 : 9.72477756116546e-07\n",
      "Loss at iteration 670 : 9.69892580262307e-07\n",
      "Loss at iteration 671 : 9.673177536852882e-07\n",
      "Loss at iteration 672 : 9.64753221066142e-07\n",
      "Loss at iteration 673 : 9.621989274549879e-07\n",
      "Loss at iteration 674 : 9.596548182685498e-07\n",
      "Loss at iteration 675 : 9.571208392880448e-07\n",
      "Loss at iteration 676 : 9.545969366546875e-07\n",
      "Loss at iteration 677 : 9.520830568682231e-07\n",
      "Loss at iteration 678 : 9.495791467833155e-07\n",
      "Loss at iteration 679 : 9.470851536075204e-07\n",
      "Loss at iteration 680 : 9.44601024896893e-07\n",
      "Loss at iteration 681 : 9.42126708555305e-07\n",
      "Loss at iteration 682 : 9.396621528297448e-07\n",
      "Loss at iteration 683 : 9.372073063089653e-07\n",
      "Loss at iteration 684 : 9.347621179205963e-07\n",
      "Loss at iteration 685 : 9.323265369273521e-07\n",
      "Loss at iteration 686 : 9.299005129257293e-07\n",
      "Loss at iteration 687 : 9.274839958426012e-07\n",
      "Loss at iteration 688 : 9.25076935933364e-07\n",
      "Loss at iteration 689 : 9.226792837782249e-07\n",
      "Loss at iteration 690 : 9.202909902807372e-07\n",
      "Loss at iteration 691 : 9.179120066643644e-07\n",
      "Loss at iteration 692 : 9.155422844709345e-07\n",
      "Loss at iteration 693 : 9.13181775557125e-07\n",
      "Loss at iteration 694 : 9.108304320933074e-07\n",
      "Loss at iteration 695 : 9.084882065592487e-07\n",
      "Loss at iteration 696 : 9.06155051743581e-07\n",
      "Loss at iteration 697 : 9.038309207404752e-07\n",
      "Loss at iteration 698 : 9.015157669471511e-07\n",
      "Loss at iteration 699 : 8.992095440616518e-07\n",
      "Loss at iteration 700 : 8.969122060810842e-07\n",
      "Loss at iteration 701 : 8.946237072983723e-07\n",
      "Loss at iteration 702 : 8.923440023006563e-07\n",
      "Loss at iteration 703 : 8.900730459668973e-07\n",
      "Loss at iteration 704 : 8.87810793465487e-07\n",
      "Loss at iteration 705 : 8.855572002516601e-07\n",
      "Loss at iteration 706 : 8.833122220666462e-07\n",
      "Loss at iteration 707 : 8.810758149334939e-07\n",
      "Loss at iteration 708 : 8.788479351563653e-07\n",
      "Loss at iteration 709 : 8.766285393182469e-07\n",
      "Loss at iteration 710 : 8.744175842783099e-07\n",
      "Loss at iteration 711 : 8.722150271694268e-07\n",
      "Loss at iteration 712 : 8.70020825397749e-07\n",
      "Loss at iteration 713 : 8.678349366390993e-07\n",
      "Loss at iteration 714 : 8.656573188369829e-07\n",
      "Loss at iteration 715 : 8.634879302014074e-07\n",
      "Loss at iteration 716 : 8.613267292063587e-07\n",
      "Loss at iteration 717 : 8.591736745877369e-07\n",
      "Loss at iteration 718 : 8.57028725341538e-07\n",
      "Loss at iteration 719 : 8.548918407217138e-07\n",
      "Loss at iteration 720 : 8.52762980238496e-07\n",
      "Loss at iteration 721 : 8.506421036560519e-07\n",
      "Loss at iteration 722 : 8.485291709914063e-07\n",
      "Loss at iteration 723 : 8.46424142511333e-07\n",
      "Loss at iteration 724 : 8.443269787314178e-07\n",
      "Loss at iteration 725 : 8.422376404134329e-07\n",
      "Loss at iteration 726 : 8.401560885649817e-07\n",
      "Loss at iteration 727 : 8.380822844354458e-07\n",
      "Loss at iteration 728 : 8.36016189516099e-07\n",
      "Loss at iteration 729 : 8.339577655372074e-07\n",
      "Loss at iteration 730 : 8.319069744664885e-07\n",
      "Loss at iteration 731 : 8.298637785081389e-07\n",
      "Loss at iteration 732 : 8.278281400993067e-07\n",
      "Loss at iteration 733 : 8.258000219104816e-07\n",
      "Loss at iteration 734 : 8.237793868421095e-07\n",
      "Loss at iteration 735 : 8.217661980235588e-07\n",
      "Loss at iteration 736 : 8.197604188115328e-07\n",
      "Loss at iteration 737 : 8.177620127882894e-07\n",
      "Loss at iteration 738 : 8.157709437595237e-07\n",
      "Loss at iteration 739 : 8.137871757532697e-07\n",
      "Loss at iteration 740 : 8.118106730183682e-07\n",
      "Loss at iteration 741 : 8.098414000222798e-07\n",
      "Loss at iteration 742 : 8.078793214500185e-07\n",
      "Loss at iteration 743 : 8.05924402202102e-07\n",
      "Loss at iteration 744 : 8.039766073931758e-07\n",
      "Loss at iteration 745 : 8.020359023504259e-07\n",
      "Loss at iteration 746 : 8.001022526123331e-07\n",
      "Loss at iteration 747 : 7.981756239263423e-07\n",
      "Loss at iteration 748 : 7.96255982248625e-07\n",
      "Loss at iteration 749 : 7.943432937408917e-07\n",
      "Loss at iteration 750 : 7.924375247703943e-07\n",
      "Loss at iteration 751 : 7.905386419075342e-07\n",
      "Loss at iteration 752 : 7.886466119248911e-07\n",
      "Loss at iteration 753 : 7.867614017951835e-07\n",
      "Loss at iteration 754 : 7.848829786905379e-07\n",
      "Loss at iteration 755 : 7.830113099802507e-07\n",
      "Loss at iteration 756 : 7.811463632306225e-07\n",
      "Loss at iteration 757 : 7.792881062018659e-07\n",
      "Loss at iteration 758 : 7.774365068481813e-07\n",
      "Loss at iteration 759 : 7.755915333149049e-07\n",
      "Loss at iteration 760 : 7.737531539388128e-07\n",
      "Loss at iteration 761 : 7.719213372456176e-07\n",
      "Loss at iteration 762 : 7.700960519488822e-07\n",
      "Loss at iteration 763 : 7.682772669482987e-07\n",
      "Loss at iteration 764 : 7.664649513295829e-07\n",
      "Loss at iteration 765 : 7.646590743616988e-07\n",
      "Loss at iteration 766 : 7.62859605496237e-07\n",
      "Loss at iteration 767 : 7.610665143662617e-07\n",
      "Loss at iteration 768 : 7.592797707844238e-07\n",
      "Loss at iteration 769 : 7.574993447424683e-07\n",
      "Loss at iteration 770 : 7.557252064091535e-07\n",
      "Loss at iteration 771 : 7.539573261297713e-07\n",
      "Loss at iteration 772 : 7.521956744242978e-07\n",
      "Loss at iteration 773 : 7.504402219866118e-07\n",
      "Loss at iteration 774 : 7.486909396824534e-07\n",
      "Loss at iteration 775 : 7.469477985491903e-07\n",
      "Loss at iteration 776 : 7.452107697946323e-07\n",
      "Loss at iteration 777 : 7.434798247947027e-07\n",
      "Loss at iteration 778 : 7.417549350931196e-07\n",
      "Loss at iteration 779 : 7.400360724001349e-07\n",
      "Loss at iteration 780 : 7.383232085915963e-07\n",
      "Loss at iteration 781 : 7.36616315706758e-07\n",
      "Loss at iteration 782 : 7.349153659488292e-07\n",
      "Loss at iteration 783 : 7.332203316817537e-07\n",
      "Loss at iteration 784 : 7.315311854307696e-07\n",
      "Loss at iteration 785 : 7.298478998809887e-07\n",
      "Loss at iteration 786 : 7.281704478754573e-07\n",
      "Loss at iteration 787 : 7.264988024146909e-07\n",
      "Loss at iteration 788 : 7.248329366557969e-07\n",
      "Loss at iteration 789 : 7.231728239106679e-07\n",
      "Loss at iteration 790 : 7.215184376457426e-07\n",
      "Loss at iteration 791 : 7.198697514800038e-07\n",
      "Loss at iteration 792 : 7.182267391850694e-07\n",
      "Loss at iteration 793 : 7.165893746824781e-07\n",
      "Loss at iteration 794 : 7.149576320449314e-07\n",
      "Loss at iteration 795 : 7.133314854929749e-07\n",
      "Loss at iteration 796 : 7.117109093953193e-07\n",
      "Loss at iteration 797 : 7.100958782677131e-07\n",
      "Loss at iteration 798 : 7.084863667716184e-07\n",
      "Loss at iteration 799 : 7.068823497129939e-07\n",
      "Loss at iteration 800 : 7.052838020420189e-07\n",
      "Loss at iteration 801 : 7.03690698851477e-07\n",
      "Loss at iteration 802 : 7.021030153759752e-07\n",
      "Loss at iteration 803 : 7.005207269909622e-07\n",
      "Loss at iteration 804 : 6.989438092123662e-07\n",
      "Loss at iteration 805 : 6.973722376939875e-07\n",
      "Loss at iteration 806 : 6.958059882290959e-07\n",
      "Loss at iteration 807 : 6.942450367465066e-07\n",
      "Loss at iteration 808 : 6.926893593123874e-07\n",
      "Loss at iteration 809 : 6.911389321275832e-07\n",
      "Loss at iteration 810 : 6.895937315272841e-07\n",
      "Loss at iteration 811 : 6.880537339802e-07\n",
      "Loss at iteration 812 : 6.865189160872256e-07\n",
      "Loss at iteration 813 : 6.84989254581334e-07\n",
      "Loss at iteration 814 : 6.834647263260503e-07\n",
      "Loss at iteration 815 : 6.81945308314545e-07\n",
      "Loss at iteration 816 : 6.804309776691367e-07\n",
      "Loss at iteration 817 : 6.78921711640093e-07\n",
      "Loss at iteration 818 : 6.774174876052402e-07\n",
      "Loss at iteration 819 : 6.759182830681749e-07\n",
      "Loss at iteration 820 : 6.744240756584876e-07\n",
      "Loss at iteration 821 : 6.729348431304867e-07\n",
      "Loss at iteration 822 : 6.714505633621311e-07\n",
      "Loss at iteration 823 : 6.699712143544631e-07\n",
      "Loss at iteration 824 : 6.684967742306555e-07\n",
      "Loss at iteration 825 : 6.670272212357544e-07\n",
      "Loss at iteration 826 : 6.655625337346338e-07\n",
      "Loss at iteration 827 : 6.641026902122517e-07\n",
      "Loss at iteration 828 : 6.626476692731137e-07\n",
      "Loss at iteration 829 : 6.611974496390425e-07\n",
      "Loss at iteration 830 : 6.597520101497474e-07\n",
      "Loss at iteration 831 : 6.583113297615072e-07\n",
      "Loss at iteration 832 : 6.56875387546644e-07\n",
      "Loss at iteration 833 : 6.554441626919274e-07\n",
      "Loss at iteration 834 : 6.540176344994452e-07\n",
      "Loss at iteration 835 : 6.525957823839237e-07\n",
      "Loss at iteration 836 : 6.511785858738093e-07\n",
      "Loss at iteration 837 : 6.49766024608894e-07\n",
      "Loss at iteration 838 : 6.483580783407169e-07\n",
      "Loss at iteration 839 : 6.46954726931281e-07\n",
      "Loss at iteration 840 : 6.455559503524804e-07\n",
      "Loss at iteration 841 : 6.441617286860096e-07\n",
      "Loss at iteration 842 : 6.427720421208281e-07\n",
      "Loss at iteration 843 : 6.413868709547526e-07\n",
      "Loss at iteration 844 : 6.400061955923229e-07\n",
      "Loss at iteration 845 : 6.386299965439524e-07\n",
      "Loss at iteration 846 : 6.372582544264445e-07\n",
      "Loss at iteration 847 : 6.358909499612739e-07\n",
      "Loss at iteration 848 : 6.345280639740354e-07\n",
      "Loss at iteration 849 : 6.331695773941011e-07\n",
      "Loss at iteration 850 : 6.318154712541769e-07\n",
      "Loss at iteration 851 : 6.304657266883079e-07\n",
      "Loss at iteration 852 : 6.291203249331979e-07\n",
      "Loss at iteration 853 : 6.277792473257395e-07\n",
      "Loss at iteration 854 : 6.264424753035579e-07\n",
      "Loss at iteration 855 : 6.251099904038167e-07\n",
      "Loss at iteration 856 : 6.237817742627988e-07\n",
      "Loss at iteration 857 : 6.224578086148163e-07\n",
      "Loss at iteration 858 : 6.211380752925716e-07\n",
      "Loss at iteration 859 : 6.198225562252114e-07\n",
      "Loss at iteration 860 : 6.185112334388817e-07\n",
      "Loss at iteration 861 : 6.17204089055083e-07\n",
      "Loss at iteration 862 : 6.159011052914262e-07\n",
      "Loss at iteration 863 : 6.146022644594138e-07\n",
      "Loss at iteration 864 : 6.133075489648226e-07\n",
      "Loss at iteration 865 : 6.120169413068372e-07\n",
      "Loss at iteration 866 : 6.107304240779579e-07\n",
      "Loss at iteration 867 : 6.094479799622797e-07\n",
      "Loss at iteration 868 : 6.081695917357923e-07\n",
      "Loss at iteration 869 : 6.068952422660998e-07\n",
      "Loss at iteration 870 : 6.056249145104328e-07\n",
      "Loss at iteration 871 : 6.043585915169052e-07\n",
      "Loss at iteration 872 : 6.030962564220578e-07\n",
      "Loss at iteration 873 : 6.018378924521178e-07\n",
      "Loss at iteration 874 : 6.005834829210275e-07\n",
      "Loss at iteration 875 : 5.993330112303804e-07\n",
      "Loss at iteration 876 : 5.980864608695457e-07\n",
      "Loss at iteration 877 : 5.96843815413618e-07\n",
      "Loss at iteration 878 : 5.956050585242112e-07\n",
      "Loss at iteration 879 : 5.943701739484607e-07\n",
      "Loss at iteration 880 : 5.931391455185896e-07\n",
      "Loss at iteration 881 : 5.919119571509156e-07\n",
      "Loss at iteration 882 : 5.906885928457151e-07\n",
      "Loss at iteration 883 : 5.894690366867028e-07\n",
      "Loss at iteration 884 : 5.882532728407127e-07\n",
      "Loss at iteration 885 : 5.870412855565272e-07\n",
      "Loss at iteration 886 : 5.858330591650342e-07\n",
      "Loss at iteration 887 : 5.846285780780641e-07\n",
      "Loss at iteration 888 : 5.834278267890162e-07\n",
      "Loss at iteration 889 : 5.822307898707711e-07\n",
      "Loss at iteration 890 : 5.810374519763221e-07\n",
      "Loss at iteration 891 : 5.798477978380021e-07\n",
      "Loss at iteration 892 : 5.786618122673712e-07\n",
      "Loss at iteration 893 : 5.774794801534237e-07\n",
      "Loss at iteration 894 : 5.763007864636968e-07\n",
      "Loss at iteration 895 : 5.751257162429498e-07\n",
      "Loss at iteration 896 : 5.739542546126904e-07\n",
      "Loss at iteration 897 : 5.727863867710722e-07\n",
      "Loss at iteration 898 : 5.716220979918698e-07\n",
      "Loss at iteration 899 : 5.704613736247528e-07\n",
      "Loss at iteration 900 : 5.693041990938016e-07\n",
      "Loss at iteration 901 : 5.681505598985303e-07\n",
      "Loss at iteration 902 : 5.670004416117567e-07\n",
      "Loss at iteration 903 : 5.658538298799864e-07\n",
      "Loss at iteration 904 : 5.647107104235075e-07\n",
      "Loss at iteration 905 : 5.63571069035018e-07\n",
      "Loss at iteration 906 : 5.624348915790883e-07\n",
      "Loss at iteration 907 : 5.613021639928192e-07\n",
      "Loss at iteration 908 : 5.601728722843862e-07\n",
      "Loss at iteration 909 : 5.590470025330609e-07\n",
      "Loss at iteration 910 : 5.579245408884981e-07\n",
      "Loss at iteration 911 : 5.56805473570574e-07\n",
      "Loss at iteration 912 : 5.556897868691373e-07\n",
      "Loss at iteration 913 : 5.545774671425734e-07\n",
      "Loss at iteration 914 : 5.534685008187492e-07\n",
      "Loss at iteration 915 : 5.523628743941287e-07\n",
      "Loss at iteration 916 : 5.512605744323503e-07\n",
      "Loss at iteration 917 : 5.501615875655342e-07\n",
      "Loss at iteration 918 : 5.490659004924113e-07\n",
      "Loss at iteration 919 : 5.479734999789975e-07\n",
      "Loss at iteration 920 : 5.468843728571827e-07\n",
      "Loss at iteration 921 : 5.457985060253176e-07\n",
      "Loss at iteration 922 : 5.447158864468072e-07\n",
      "Loss at iteration 923 : 5.436365011509757e-07\n",
      "Loss at iteration 924 : 5.425603372312136e-07\n",
      "Loss at iteration 925 : 5.414873818461103e-07\n",
      "Loss at iteration 926 : 5.40417622217435e-07\n",
      "Loss at iteration 927 : 5.39351045631269e-07\n",
      "Loss at iteration 928 : 5.382876394367126e-07\n",
      "Loss at iteration 929 : 5.372273910457602e-07\n",
      "Loss at iteration 930 : 5.361702879330027e-07\n",
      "Loss at iteration 931 : 5.351163176350579e-07\n",
      "Loss at iteration 932 : 5.340654677504558e-07\n",
      "Loss at iteration 933 : 5.330177259388937e-07\n",
      "Loss at iteration 934 : 5.319730799215743e-07\n",
      "Loss at iteration 935 : 5.309315174798371e-07\n",
      "Loss at iteration 936 : 5.29893026455682e-07\n",
      "Loss at iteration 937 : 5.288575947511196e-07\n",
      "Loss at iteration 938 : 5.278252103274451e-07\n",
      "Loss at iteration 939 : 5.267958612053986e-07\n",
      "Loss at iteration 940 : 5.257695354648891e-07\n",
      "Loss at iteration 941 : 5.247462212439117e-07\n",
      "Loss at iteration 942 : 5.237259067388088e-07\n",
      "Loss at iteration 943 : 5.227085802039917e-07\n",
      "Loss at iteration 944 : 5.216942299514042e-07\n",
      "Loss at iteration 945 : 5.206828443500742e-07\n",
      "Loss at iteration 946 : 5.196744118256675e-07\n",
      "Loss at iteration 947 : 5.186689208604881e-07\n",
      "Loss at iteration 948 : 5.176663599935654e-07\n",
      "Loss at iteration 949 : 5.166667178188888e-07\n",
      "Loss at iteration 950 : 5.156699829868251e-07\n",
      "Loss at iteration 951 : 5.146761442022692e-07\n",
      "Loss at iteration 952 : 5.136851902255345e-07\n",
      "Loss at iteration 953 : 5.126971098712125e-07\n",
      "Loss at iteration 954 : 5.117118920080128e-07\n",
      "Loss at iteration 955 : 5.107295255591182e-07\n",
      "Loss at iteration 956 : 5.097499995007108e-07\n",
      "Loss at iteration 957 : 5.087733028626847e-07\n",
      "Loss at iteration 958 : 5.077994247279603e-07\n",
      "Loss at iteration 959 : 5.068283542316268e-07\n",
      "Loss at iteration 960 : 5.058600805619205e-07\n",
      "Loss at iteration 961 : 5.048945929584159e-07\n",
      "Loss at iteration 962 : 5.039318807132578e-07\n",
      "Loss at iteration 963 : 5.029719331693635e-07\n",
      "Loss at iteration 964 : 5.020147397211369e-07\n",
      "Loss at iteration 965 : 5.010602898138862e-07\n",
      "Loss at iteration 966 : 5.0010857294359e-07\n",
      "Loss at iteration 967 : 4.991595786564031e-07\n",
      "Loss at iteration 968 : 4.98213296548511e-07\n",
      "Loss at iteration 969 : 4.972697162657304e-07\n",
      "Loss at iteration 970 : 4.963288275037975e-07\n",
      "Loss at iteration 971 : 4.95390620006929e-07\n",
      "Loss at iteration 972 : 4.944550835688115e-07\n",
      "Loss at iteration 973 : 4.935222080311654e-07\n",
      "Loss at iteration 974 : 4.925919832847309e-07\n",
      "Loss at iteration 975 : 4.916643992677558e-07\n",
      "Loss at iteration 976 : 4.907394459662921e-07\n",
      "Loss at iteration 977 : 4.898171134141503e-07\n",
      "Loss at iteration 978 : 4.888973916923402e-07\n",
      "Loss at iteration 979 : 4.879802709285113e-07\n",
      "Loss at iteration 980 : 4.870657412974261e-07\n",
      "Loss at iteration 981 : 4.861537930200625e-07\n",
      "Loss at iteration 982 : 4.852444163634043e-07\n",
      "Loss at iteration 983 : 4.843376016408289e-07\n",
      "Loss at iteration 984 : 4.83433339210961e-07\n",
      "Loss at iteration 985 : 4.825316194778058e-07\n",
      "Loss at iteration 986 : 4.816324328907173e-07\n",
      "Loss at iteration 987 : 4.807357699435959e-07\n",
      "Loss at iteration 988 : 4.798416211757073e-07\n",
      "Loss at iteration 989 : 4.789499771696964e-07\n",
      "Loss at iteration 990 : 4.780608285529182e-07\n",
      "Loss at iteration 991 : 4.771741659964732e-07\n",
      "Loss at iteration 992 : 4.7628998021518e-07\n",
      "Loss at iteration 993 : 4.754082619672111e-07\n",
      "Loss at iteration 994 : 4.7452900205364475e-07\n",
      "Loss at iteration 995 : 4.7365219131886186e-07\n",
      "Loss at iteration 996 : 4.727778206495099e-07\n",
      "Loss at iteration 997 : 4.7190588097490467e-07\n",
      "Loss at iteration 998 : 4.71036363266585e-07\n",
      "Loss at iteration 999 : 4.701692585376209e-07\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"loss of learning rate 1: \",\n",
    ")\n",
    "loss_list = nn.train(\n",
    "    np.array([[1, 0.91, 1.37]]),\n",
    "    np.array([[1, 0]]),\n",
    "    early_stopping=False,\n",
    "    epochs=no_of_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_l1 = NeuralNetwork(learning_rate=0.1)\n",
    "nn_l2 = NeuralNetwork(learning_rate=0.01)\n",
    "nn_l3 = NeuralNetwork(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss List for Different Learning Rates: \n",
      "loss of learning rate 0.1: \n",
      "Loss at iteration 0 : 0.3781119552962855\n",
      "Loss at iteration 1 : 0.36596323669810016\n",
      "Loss at iteration 2 : 0.35377289406310036\n",
      "Loss at iteration 3 : 0.34157100509399274\n",
      "Loss at iteration 4 : 0.32938964752614264\n",
      "Loss at iteration 5 : 0.3172622614615516\n",
      "Loss at iteration 6 : 0.30522298753836496\n",
      "Loss at iteration 7 : 0.29330600095939635\n",
      "Loss at iteration 8 : 0.2815448620997955\n",
      "Loss at iteration 9 : 0.26997190391568776\n",
      "Loss at iteration 10 : 0.25861767469085994\n",
      "Loss at iteration 11 : 0.24751045190576193\n",
      "Loss at iteration 12 : 0.23667583940821468\n",
      "Loss at iteration 13 : 0.2261364558970335\n",
      "Loss at iteration 14 : 0.2159117183261461\n",
      "Loss at iteration 15 : 0.20601771952763004\n",
      "Loss at iteration 16 : 0.1964671954342715\n",
      "Loss at iteration 17 : 0.1872695739916059\n",
      "Loss at iteration 18 : 0.17843109534301607\n",
      "Loss at iteration 19 : 0.16995499122157987\n",
      "Loss at iteration 20 : 0.1618417106810926\n",
      "Loss at iteration 21 : 0.15408917927132185\n",
      "Loss at iteration 22 : 0.14669307938601484\n",
      "Loss at iteration 23 : 0.1396471406354725\n",
      "Loss at iteration 24 : 0.13294343055891414\n",
      "Loss at iteration 25 : 0.12657263764300408\n",
      "Loss at iteration 26 : 0.120524340318295\n",
      "Loss at iteration 27 : 0.11478725725723912\n",
      "Loss at iteration 28 : 0.10934947581653073\n",
      "Loss at iteration 29 : 0.10419865680119655\n",
      "Loss at iteration 30 : 0.09932221485091058\n",
      "Loss at iteration 31 : 0.09470747465340068\n",
      "Loss at iteration 32 : 0.09034180388357894\n",
      "Loss at iteration 33 : 0.08621272426855794\n",
      "Loss at iteration 34 : 0.08230800251253394\n",
      "Loss at iteration 35 : 0.07861572300886449\n",
      "Loss at iteration 36 : 0.07512434434692547\n",
      "Loss at iteration 37 : 0.07182274161423718\n",
      "Loss at iteration 38 : 0.06870023642290607\n",
      "Loss at iteration 39 : 0.06574661647334691\n",
      "Loss at iteration 40 : 0.06295214632380244\n",
      "Loss at iteration 41 : 0.06030757087433075\n",
      "Loss at iteration 42 : 0.05780411290864052\n",
      "Loss at iteration 43 : 0.05543346587377436\n",
      "Loss at iteration 44 : 0.05318778292132563\n",
      "Loss at iteration 45 : 0.051059663088018716\n",
      "Loss at iteration 46 : 0.049042135360080424\n",
      "Loss at iteration 47 : 0.04712864124582501\n",
      "Loss at iteration 48 : 0.045313016374427424\n",
      "Loss at iteration 49 : 0.04358947154559506\n",
      "Loss at iteration 50 : 0.041952573574017736\n",
      "Loss at iteration 51 : 0.04039722620312148\n",
      "Loss at iteration 52 : 0.038918651303692445\n",
      "Loss at iteration 53 : 0.037512370523258926\n",
      "Loss at iteration 54 : 0.03617418751062307\n",
      "Loss at iteration 55 : 0.03490017080557179\n",
      "Loss at iteration 56 : 0.03368663745560111\n",
      "Loss at iteration 57 : 0.032530137398567915\n",
      "Loss at iteration 58 : 0.03142743863175231\n",
      "Loss at iteration 59 : 0.030375513173166623\n",
      "Loss at iteration 60 : 0.029371523809466997\n",
      "Loss at iteration 61 : 0.02841281161598339\n",
      "Loss at iteration 62 : 0.02749688422771831\n",
      "Loss at iteration 63 : 0.02662140483528816\n",
      "Loss at iteration 64 : 0.025784181876355602\n",
      "Loss at iteration 65 : 0.024983159390852844\n",
      "Loss at iteration 66 : 0.02421640800698319\n",
      "Loss at iteration 67 : 0.023482116524421927\n",
      "Loss at iteration 68 : 0.022778584061150027\n",
      "Loss at iteration 69 : 0.02210421273081567\n",
      "Loss at iteration 70 : 0.021457500818317266\n",
      "Loss at iteration 71 : 0.020837036422348697\n",
      "Loss at iteration 72 : 0.02024149153487219\n",
      "Loss at iteration 73 : 0.019669616528825228\n",
      "Loss at iteration 74 : 0.019120235026783616\n",
      "Loss at iteration 75 : 0.018592239124751248\n",
      "Loss at iteration 76 : 0.018084584946706117\n",
      "Loss at iteration 77 : 0.017596288506972813\n",
      "Loss at iteration 78 : 0.017126421858904513\n",
      "Loss at iteration 79 : 0.0166741095097242\n",
      "Loss at iteration 80 : 0.01623852508269131\n",
      "Loss at iteration 81 : 0.015818888209017258\n",
      "Loss at iteration 82 : 0.015414461633149457\n",
      "Loss at iteration 83 : 0.01502454851617543\n",
      "Loss at iteration 84 : 0.014648489923167324\n",
      "Loss at iteration 85 : 0.014285662481290493\n",
      "Loss at iteration 86 : 0.013935476196443117\n",
      "Loss at iteration 87 : 0.013597372417073605\n",
      "Loss at iteration 88 : 0.013270821934646553\n",
      "Loss at iteration 89 : 0.012955323210994962\n",
      "Loss at iteration 90 : 0.012650400723510355\n",
      "Loss at iteration 91 : 0.01235560341978649\n",
      "Loss at iteration 92 : 0.012070503273949294\n",
      "Loss at iteration 93 : 0.011794693937477176\n",
      "Loss at iteration 94 : 0.011527789477847012\n",
      "Loss at iteration 95 : 0.011269423198832007\n",
      "Loss at iteration 96 : 0.01101924653673296\n",
      "Loss at iteration 97 : 0.010776928027245725\n",
      "Loss at iteration 98 : 0.01054215233805749\n",
      "Loss at iteration 99 : 0.010314619362624546\n",
      "Loss at iteration 100 : 0.01009404337091829\n",
      "Loss at iteration 101 : 0.009880152213233764\n",
      "Loss at iteration 102 : 0.009672686573440382\n",
      "Loss at iteration 103 : 0.009471399268317946\n",
      "Loss at iteration 104 : 0.009276054589864142\n",
      "Loss at iteration 105 : 0.009086427687685384\n",
      "Loss at iteration 106 : 0.00890230398879049\n",
      "Loss at iteration 107 : 0.008723478652299417\n",
      "Loss at iteration 108 : 0.008549756056756818\n",
      "Loss at iteration 109 : 0.008380949317905163\n",
      "Loss at iteration 110 : 0.008216879834923965\n",
      "Loss at iteration 111 : 0.008057376863282381\n",
      "Loss at iteration 112 : 0.007902277112483279\n",
      "Loss at iteration 113 : 0.007751424367096596\n",
      "Loss at iteration 114 : 0.007604669129592115\n",
      "Loss at iteration 115 : 0.007461868283584595\n",
      "Loss at iteration 116 : 0.007322884776200411\n",
      "Loss at iteration 117 : 0.007187587318362941\n",
      "Loss at iteration 118 : 0.007055850101876739\n",
      "Loss at iteration 119 : 0.006927552532266085\n",
      "Loss at iteration 120 : 0.006802578976394763\n",
      "Loss at iteration 121 : 0.006680818523958824\n",
      "Loss at iteration 122 : 0.006562164762005408\n",
      "Loss at iteration 123 : 0.0064465155616867985\n",
      "Loss at iteration 124 : 0.0063337728765114135\n",
      "Loss at iteration 125 : 0.006223842551402119\n",
      "Loss at iteration 126 : 0.006116634141917354\n",
      "Loss at iteration 127 : 0.006012060743032739\n",
      "Loss at iteration 128 : 0.005910038826919702\n",
      "Loss at iteration 129 : 0.005810488089194214\n",
      "Loss at iteration 130 : 0.005713331303142568\n",
      "Loss at iteration 131 : 0.00561849418146213\n",
      "Loss at iteration 132 : 0.005525905245085181\n",
      "Loss at iteration 133 : 0.005435495698680137\n",
      "Loss at iteration 134 : 0.005347199312451045\n",
      "Loss at iteration 135 : 0.005260952309878978\n",
      "Loss at iteration 136 : 0.005176693261071607\n",
      "Loss at iteration 137 : 0.005094362981407714\n",
      "Loss at iteration 138 : 0.005013904435182577\n",
      "Loss at iteration 139 : 0.00493526264397824\n",
      "Loss at iteration 140 : 0.00485838459949923\n",
      "Loss at iteration 141 : 0.00478321918063027\n",
      "Loss at iteration 142 : 0.004709717074486829\n",
      "Loss at iteration 143 : 0.004637830701243392\n",
      "Loss at iteration 144 : 0.004567514142536625\n",
      "Loss at iteration 145 : 0.004498723073253256\n",
      "Loss at iteration 146 : 0.004431414696522987\n",
      "Loss at iteration 147 : 0.00436554768174775\n",
      "Loss at iteration 148 : 0.004301082105508188\n",
      "Loss at iteration 149 : 0.0042379793951975156\n",
      "Loss at iteration 150 : 0.004176202275241474\n",
      "Loss at iteration 151 : 0.0041157147157712196\n",
      "Loss at iteration 152 : 0.004056481883623697\n",
      "Loss at iteration 153 : 0.003998470095550624\n",
      "Loss at iteration 154 : 0.003941646773524721\n",
      "Loss at iteration 155 : 0.00388598040203736\n",
      "Loss at iteration 156 : 0.003831440487287858\n",
      "Loss at iteration 157 : 0.0037779975181704895\n",
      "Loss at iteration 158 : 0.0037256229289700186\n",
      "Loss at iteration 159 : 0.003674289063681777\n",
      "Loss at iteration 160 : 0.0036239691418765776\n",
      "Loss at iteration 161 : 0.00357463722603542\n",
      "Loss at iteration 162 : 0.003526268190282752\n",
      "Loss at iteration 163 : 0.0034788376904508578\n",
      "Loss at iteration 164 : 0.0034323221354116877\n",
      "Loss at iteration 165 : 0.003386698659615722\n",
      "Loss at iteration 166 : 0.003341945096780737\n",
      "Loss at iteration 167 : 0.003298039954676122\n",
      "Loss at iteration 168 : 0.0032549623909515664\n",
      "Loss at iteration 169 : 0.003212692189961339\n",
      "Loss at iteration 170 : 0.0031712097405378883\n",
      "Loss at iteration 171 : 0.003130496014671186\n",
      "Loss at iteration 172 : 0.003090532547052104\n",
      "Loss at iteration 173 : 0.0030513014154402536\n",
      "Loss at iteration 174 : 0.0030127852218192024\n",
      "Loss at iteration 175 : 0.0029749670743031385\n",
      "Loss at iteration 176 : 0.002937830569761355\n",
      "Loss at iteration 177 : 0.002901359777128563\n",
      "Loss at iteration 178 : 0.00286553922137025\n",
      "Loss at iteration 179 : 0.0028303538680744455\n",
      "Loss at iteration 180 : 0.0027957891086419933\n",
      "Loss at iteration 181 : 0.002761830746049304\n",
      "Loss at iteration 182 : 0.0027284649811585545\n",
      "Loss at iteration 183 : 0.0026956783995516678\n",
      "Loss at iteration 184 : 0.0026634579588653813\n",
      "Loss at iteration 185 : 0.0026317909766059256\n",
      "Loss at iteration 186 : 0.002600665118422896\n",
      "Loss at iteration 187 : 0.0025700683868226425\n",
      "Loss at iteration 188 : 0.0025399891103027395\n",
      "Loss at iteration 189 : 0.002510415932889758\n",
      "Loss at iteration 190 : 0.002481337804063396\n",
      "Loss at iteration 191 : 0.002452743969050949\n",
      "Loss at iteration 192 : 0.002424623959476677\n",
      "Loss at iteration 193 : 0.002396967584351483\n",
      "Loss at iteration 194 : 0.002369764921388932\n",
      "Loss at iteration 195 : 0.0023430063086341416\n",
      "Loss at iteration 196 : 0.0023166823363930094\n",
      "Loss at iteration 197 : 0.0022907838394494416\n",
      "Loss at iteration 198 : 0.0022653018895590965\n",
      "Loss at iteration 199 : 0.002240227788208457\n",
      "Loss at iteration 200 : 0.002215553059628706\n",
      "Loss at iteration 201 : 0.0021912694440542595\n",
      "Loss at iteration 202 : 0.0021673688912162556\n",
      "Loss at iteration 203 : 0.002143843554061783\n",
      "Loss at iteration 204 : 0.002120685782690016\n",
      "Loss at iteration 205 : 0.0020978881184966908\n",
      "Loss at iteration 206 : 0.0020754432885189992\n",
      "Loss at iteration 207 : 0.0020533441999729713\n",
      "Loss at iteration 208 : 0.002031583934976158\n",
      "Loss at iteration 209 : 0.0020101557454482565\n",
      "Loss at iteration 210 : 0.0019890530481830766\n",
      "Loss at iteration 211 : 0.001968269420085363\n",
      "Loss at iteration 212 : 0.001947798593566058\n",
      "Loss at iteration 213 : 0.0019276344520902599\n",
      "Loss at iteration 214 : 0.001907771025871974\n",
      "Loss at iteration 215 : 0.0018882024877103407\n",
      "Loss at iteration 216 : 0.0018689231489619818\n",
      "Loss at iteration 217 : 0.0018499274556444427\n",
      "Loss at iteration 218 : 0.001831209984665968\n",
      "Loss at iteration 219 : 0.0018127654401769193\n",
      "Loss at iteration 220 : 0.0017945886500384443\n",
      "Loss at iteration 221 : 0.0017766745624040628\n",
      "Loss at iteration 222 : 0.001759018242410199\n",
      "Loss at iteration 223 : 0.0017416148689716148\n",
      "Loss at iteration 224 : 0.0017244597316781033\n",
      "Loss at iteration 225 : 0.0017075482277886882\n",
      "Loss at iteration 226 : 0.001690875859319996\n",
      "Loss at iteration 227 : 0.001674438230225397\n",
      "Loss at iteration 228 : 0.0016582310436616936\n",
      "Loss at iteration 229 : 0.0016422500993403485\n",
      "Loss at iteration 230 : 0.001626491290960232\n",
      "Loss at iteration 231 : 0.0016109506037191074\n",
      "Loss at iteration 232 : 0.0015956241119010769\n",
      "Loss at iteration 233 : 0.0015805079765373693\n",
      "Loss at iteration 234 : 0.0015655984431379856\n",
      "Loss at iteration 235 : 0.0015508918394917498\n",
      "Loss at iteration 236 : 0.0015363845735324073\n",
      "Loss at iteration 237 : 0.001522073131268539\n",
      "Loss at iteration 238 : 0.0015079540747752298\n",
      "Loss at iteration 239 : 0.0014940240402451853\n",
      "Loss at iteration 240 : 0.0014802797360975637\n",
      "Loss at iteration 241 : 0.001466717941142388\n",
      "Loss at iteration 242 : 0.0014533355027988243\n",
      "Loss at iteration 243 : 0.0014401293353654193\n",
      "Loss at iteration 244 : 0.0014270964183406955\n",
      "Loss at iteration 245 : 0.0014142337947923782\n",
      "Loss at iteration 246 : 0.0014015385697736926\n",
      "Loss at iteration 247 : 0.001389007908785104\n",
      "Loss at iteration 248 : 0.001376639036280214\n",
      "Loss at iteration 249 : 0.0013644292342141792\n",
      "Loss at iteration 250 : 0.0013523758406333779\n",
      "Loss at iteration 251 : 0.001340476248305026\n",
      "Loss at iteration 252 : 0.001328727903385348\n",
      "Loss at iteration 253 : 0.0013171283041252622\n",
      "Loss at iteration 254 : 0.0013056749996121309\n",
      "Loss at iteration 255 : 0.0012943655885467018\n",
      "Loss at iteration 256 : 0.0012831977180539369\n",
      "Loss at iteration 257 : 0.0012721690825267338\n",
      "Loss at iteration 258 : 0.0012612774225015187\n",
      "Loss at iteration 259 : 0.0012505205235647265\n",
      "Loss at iteration 260 : 0.001239896215289141\n",
      "Loss at iteration 261 : 0.0012294023701992563\n",
      "Loss at iteration 262 : 0.0012190369027646922\n",
      "Loss at iteration 263 : 0.0012087977684208727\n",
      "Loss at iteration 264 : 0.001198682962616057\n",
      "Loss at iteration 265 : 0.0011886905198839402\n",
      "Loss at iteration 266 : 0.0011788185129411534\n",
      "Loss at iteration 267 : 0.0011690650518086936\n",
      "Loss at iteration 268 : 0.0011594282829567673\n",
      "Loss at iteration 269 : 0.0011499063884722576\n",
      "Loss at iteration 270 : 0.00114049758524808\n",
      "Loss at iteration 271 : 0.001131200124193917\n",
      "Loss at iteration 272 : 0.0011220122894675375\n",
      "Loss at iteration 273 : 0.0011129323977262173\n",
      "Loss at iteration 274 : 0.001103958797397611\n",
      "Loss at iteration 275 : 0.0010950898679694403\n",
      "Loss at iteration 276 : 0.0010863240192976297\n",
      "Loss at iteration 277 : 0.0010776596909321439\n",
      "Loss at iteration 278 : 0.0010690953514601166\n",
      "Loss at iteration 279 : 0.001060629497865779\n",
      "Loss at iteration 280 : 0.001052260654906678\n",
      "Loss at iteration 281 : 0.0010439873745056822\n",
      "Loss at iteration 282 : 0.0010358082351583798\n",
      "Loss at iteration 283 : 0.0010277218413553726\n",
      "Loss at iteration 284 : 0.0010197268230191419\n",
      "Loss at iteration 285 : 0.0010118218349549\n",
      "Loss at iteration 286 : 0.0010040055563151926\n",
      "Loss at iteration 287 : 0.0009962766900778212\n",
      "Loss at iteration 288 : 0.0009886339625366125\n",
      "Loss at iteration 289 : 0.0009810761228048561\n",
      "Loss at iteration 290 : 0.0009736019423308463\n",
      "Loss at iteration 291 : 0.0009662102144254096\n",
      "Loss at iteration 292 : 0.0009588997538008766\n",
      "Loss at iteration 293 : 0.0009516693961213296\n",
      "Loss at iteration 294 : 0.0009445179975637904\n",
      "Loss at iteration 295 : 0.0009374444343899218\n",
      "Loss at iteration 296 : 0.000930447602528187\n",
      "Loss at iteration 297 : 0.0009235264171659409\n",
      "Loss at iteration 298 : 0.0009166798123513259\n",
      "Loss at iteration 299 : 0.0009099067406047081\n",
      "Loss at iteration 300 : 0.0009032061725393066\n",
      "Loss at iteration 301 : 0.0008965770964908548\n",
      "Loss at iteration 302 : 0.0008900185181559614\n",
      "Loss at iteration 303 : 0.0008835294602390992\n",
      "Loss at iteration 304 : 0.0008771089621077597\n",
      "Loss at iteration 305 : 0.0008707560794557764\n",
      "Loss at iteration 306 : 0.00086446988397446\n",
      "Loss at iteration 307 : 0.000858249463031394\n",
      "Loss at iteration 308 : 0.0008520939193566949\n",
      "Loss at iteration 309 : 0.0008460023707364826\n",
      "Loss at iteration 310 : 0.0008399739497134554\n",
      "Loss at iteration 311 : 0.0008340078032943528\n",
      "Loss at iteration 312 : 0.0008281030926640634\n",
      "Loss at iteration 313 : 0.000822258992906294\n",
      "Loss at iteration 314 : 0.0008164746927306014\n",
      "Loss at iteration 315 : 0.0008107493942056186\n",
      "Loss at iteration 316 : 0.0008050823124982817\n",
      "Loss at iteration 317 : 0.0007994726756189619\n",
      "Loss at iteration 318 : 0.0007939197241723338\n",
      "Loss at iteration 319 : 0.000788422711113794\n",
      "Loss at iteration 320 : 0.0007829809015113748\n",
      "Loss at iteration 321 : 0.0007775935723128982\n",
      "Loss at iteration 322 : 0.000772260012118331\n",
      "Loss at iteration 323 : 0.0007669795209571951\n",
      "Loss at iteration 324 : 0.0007617514100708655\n",
      "Loss at iteration 325 : 0.0007565750016996573\n",
      "Loss at iteration 326 : 0.0007514496288746006\n",
      "Loss at iteration 327 : 0.0007463746352137711\n",
      "Loss at iteration 328 : 0.0007413493747230253\n",
      "Loss at iteration 329 : 0.0007363732116011084\n",
      "Loss at iteration 330 : 0.0007314455200489963\n",
      "Loss at iteration 331 : 0.0007265656840832941\n",
      "Loss at iteration 332 : 0.0007217330973537273\n",
      "Loss at iteration 333 : 0.0007169471629645094\n",
      "Loss at iteration 334 : 0.0007122072932995665\n",
      "Loss at iteration 335 : 0.0007075129098514504\n",
      "Loss at iteration 336 : 0.0007028634430539695\n",
      "Loss at iteration 337 : 0.0006982583321182866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 338 : 0.0006936970248725463\n",
      "Loss at iteration 339 : 0.0006891789776048841\n",
      "Loss at iteration 340 : 0.0006847036549097157\n",
      "Loss at iteration 341 : 0.0006802705295372578\n",
      "Loss at iteration 342 : 0.0006758790822462424\n",
      "Loss at iteration 343 : 0.0006715288016596112\n",
      "Loss at iteration 344 : 0.0006672191841233389\n",
      "Loss at iteration 345 : 0.0006629497335680623\n",
      "Loss at iteration 346 : 0.0006587199613736733\n",
      "Loss at iteration 347 : 0.0006545293862366343\n",
      "Loss at iteration 348 : 0.000650377534040058\n",
      "Loss at iteration 349 : 0.0006462639377264759\n",
      "Loss at iteration 350 : 0.0006421881371731318\n",
      "Loss at iteration 351 : 0.000638149679069917\n",
      "Loss at iteration 352 : 0.0006341481167997304\n",
      "Loss at iteration 353 : 0.0006301830103212509\n",
      "Loss at iteration 354 : 0.0006262539260541496\n",
      "Loss at iteration 355 : 0.000622360436766566\n",
      "Loss at iteration 356 : 0.0006185021214648514\n",
      "Loss at iteration 357 : 0.0006146785652855363\n",
      "Loss at iteration 358 : 0.0006108893593894866\n",
      "Loss at iteration 359 : 0.0006071341008581017\n",
      "Loss at iteration 360 : 0.0006034123925916612\n",
      "Loss at iteration 361 : 0.0005997238432096208\n",
      "Loss at iteration 362 : 0.0005960680669529351\n",
      "Loss at iteration 363 : 0.0005924446835882653\n",
      "Loss at iteration 364 : 0.0005888533183141149\n",
      "Loss at iteration 365 : 0.0005852936016687656\n",
      "Loss at iteration 366 : 0.0005817651694400461\n",
      "Loss at iteration 367 : 0.000578267662576874\n",
      "Loss at iteration 368 : 0.0005748007271024609\n",
      "Loss at iteration 369 : 0.0005713640140292897\n",
      "Loss at iteration 370 : 0.0005679571792756495\n",
      "Loss at iteration 371 : 0.0005645798835838777\n",
      "Loss at iteration 372 : 0.0005612317924400803\n",
      "Loss at iteration 373 : 0.000557912575995484\n",
      "Loss at iteration 374 : 0.0005546219089892314\n",
      "Loss at iteration 375 : 0.0005513594706726861\n",
      "Loss at iteration 376 : 0.000548124944735176\n",
      "Loss at iteration 377 : 0.000544918019231125\n",
      "Loss at iteration 378 : 0.0005417383865086369\n",
      "Loss at iteration 379 : 0.000538585743139324\n",
      "Loss at iteration 380 : 0.0005354597898495554\n",
      "Loss at iteration 381 : 0.0005323602314529565\n",
      "Loss at iteration 382 : 0.000529286776784171\n",
      "Loss at iteration 383 : 0.0005262391386338883\n",
      "Loss at iteration 384 : 0.0005232170336850678\n",
      "Loss at iteration 385 : 0.0005202201824503565\n",
      "Loss at iteration 386 : 0.000517248309210662\n",
      "Loss at iteration 387 : 0.00051430114195487\n",
      "Loss at iteration 388 : 0.0005113784123207043\n",
      "Loss at iteration 389 : 0.0005084798555366017\n",
      "Loss at iteration 390 : 0.0005056052103647613\n",
      "Loss at iteration 391 : 0.0005027542190451467\n",
      "Loss at iteration 392 : 0.0004999266272405535\n",
      "Loss at iteration 393 : 0.0004971221839827029\n",
      "Loss at iteration 394 : 0.0004943406416192586\n",
      "Loss at iteration 395 : 0.0004915817557618542\n",
      "Loss at iteration 396 : 0.0004888452852350505\n",
      "Loss at iteration 397 : 0.0004861309920262163\n",
      "Loss at iteration 398 : 0.0004834386412362909\n",
      "Loss at iteration 399 : 0.0004807680010314706\n",
      "Loss at iteration 400 : 0.00047811884259573085\n",
      "Loss at iteration 401 : 0.0004754909400842182\n",
      "Loss at iteration 402 : 0.0004728840705774682\n",
      "Loss at iteration 403 : 0.00047029801403642465\n",
      "Loss at iteration 404 : 0.0004677325532582897\n",
      "Loss at iteration 405 : 0.0004651874738331308\n",
      "Loss at iteration 406 : 0.00046266256410123894\n",
      "Loss at iteration 407 : 0.0004601576151113215\n",
      "Loss at iteration 408 : 0.00045767242057930766\n",
      "Loss at iteration 409 : 0.00045520677684798285\n",
      "Loss at iteration 410 : 0.0004527604828472784\n",
      "Loss at iteration 411 : 0.00045033334005526127\n",
      "Loss at iteration 412 : 0.0004479251524598196\n",
      "Loss at iteration 413 : 0.0004455357265209841\n",
      "Loss at iteration 414 : 0.00044316487113394885\n",
      "Loss at iteration 415 : 0.00044081239759269657\n",
      "Loss at iteration 416 : 0.0004384781195542407\n",
      "Loss at iteration 417 : 0.0004361618530035422\n",
      "Loss at iteration 418 : 0.0004338634162189474\n",
      "Loss at iteration 419 : 0.0004315826297383158\n",
      "Loss at iteration 420 : 0.00042931931632562043\n",
      "Loss at iteration 421 : 0.00042707330093821384\n",
      "Loss at iteration 422 : 0.00042484441069457575\n",
      "Loss at iteration 423 : 0.0004226324748426787\n",
      "Loss at iteration 424 : 0.00042043732472880923\n",
      "Loss at iteration 425 : 0.0004182587937670071\n",
      "Loss at iteration 426 : 0.00041609671740893317\n",
      "Loss at iteration 427 : 0.0004139509331143143\n",
      "Loss at iteration 428 : 0.0004118212803218311\n",
      "Loss at iteration 429 : 0.0004097076004205474\n",
      "Loss at iteration 430 : 0.00040760973672174163\n",
      "Loss at iteration 431 : 0.0004055275344313022\n",
      "Loss at iteration 432 : 0.0004034608406225002\n",
      "Loss at iteration 433 : 0.0004014095042092539\n",
      "Loss at iteration 434 : 0.00039937337591984187\n",
      "Loss at iteration 435 : 0.0003973523082710233\n",
      "Loss at iteration 436 : 0.00039534615554260563\n",
      "Loss at iteration 437 : 0.0003933547737524167\n",
      "Loss at iteration 438 : 0.0003913780206317224\n",
      "Loss at iteration 439 : 0.0003894157556009765\n",
      "Loss at iteration 440 : 0.0003874678397460393\n",
      "Loss at iteration 441 : 0.0003855341357947654\n",
      "Loss at iteration 442 : 0.000383614508093921\n",
      "Loss at iteration 443 : 0.00038170882258655884\n",
      "Loss at iteration 444 : 0.0003798169467896939\n",
      "Loss at iteration 445 : 0.0003779387497723635\n",
      "Loss at iteration 446 : 0.00037607410213404873\n",
      "Loss at iteration 447 : 0.00037422287598343787\n",
      "Loss at iteration 448 : 0.0003723849449175185\n",
      "Loss at iteration 449 : 0.00037056018400101346\n",
      "Loss at iteration 450 : 0.00036874846974615806\n",
      "Loss at iteration 451 : 0.0003669496800927766\n",
      "Loss at iteration 452 : 0.00036516369438868967\n",
      "Loss at iteration 453 : 0.00036339039337042776\n",
      "Loss at iteration 454 : 0.0003616296591442633\n",
      "Loss at iteration 455 : 0.0003598813751675168\n",
      "Loss at iteration 456 : 0.0003581454262301838\n",
      "Loss at iteration 457 : 0.0003564216984368295\n",
      "Loss at iteration 458 : 0.00035471007918879484\n",
      "Loss at iteration 459 : 0.00035301045716664613\n",
      "Loss at iteration 460 : 0.00035132272231293006\n",
      "Loss at iteration 461 : 0.0003496467658151783\n",
      "Loss at iteration 462 : 0.0003479824800891972\n",
      "Loss at iteration 463 : 0.00034632975876258134\n",
      "Loss at iteration 464 : 0.00034468849665853505\n",
      "Loss at iteration 465 : 0.00034305858977988013\n",
      "Loss at iteration 466 : 0.0003414399352933788\n",
      "Loss at iteration 467 : 0.000339832431514243\n",
      "Loss at iteration 468 : 0.00033823597789091125\n",
      "Loss at iteration 469 : 0.00033665047499003913\n",
      "Loss at iteration 470 : 0.00033507582448175826\n",
      "Loss at iteration 471 : 0.00033351192912509916\n",
      "Loss at iteration 472 : 0.00033195869275370746\n",
      "Loss at iteration 473 : 0.0003304160202617017\n",
      "Loss at iteration 474 : 0.00032888381758982454\n",
      "Loss at iteration 475 : 0.0003273619917117316\n",
      "Loss at iteration 476 : 0.0003258504506205384\n",
      "Loss at iteration 477 : 0.0003243491033155534\n",
      "Loss at iteration 478 : 0.00032285785978919315\n",
      "Loss at iteration 479 : 0.00032137663101413554\n",
      "Loss at iteration 480 : 0.0003199053289306068\n",
      "Loss at iteration 481 : 0.000318443866433929\n",
      "Loss at iteration 482 : 0.00031699215736219585\n",
      "Loss at iteration 483 : 0.0003155501164841545\n",
      "Loss at iteration 484 : 0.0003141176594872776\n",
      "Loss at iteration 485 : 0.00031269470296598064\n",
      "Loss at iteration 486 : 0.0003112811644100606\n",
      "Loss at iteration 487 : 0.00030987696219326175\n",
      "Loss at iteration 488 : 0.0003084820155620313\n",
      "Loss at iteration 489 : 0.0003070962446244381\n",
      "Loss at iteration 490 : 0.0003057195703392568\n",
      "Loss at iteration 491 : 0.0003043519145051961\n",
      "Loss at iteration 492 : 0.0003029931997503144\n",
      "Loss at iteration 493 : 0.00030164334952156684\n",
      "Loss at iteration 494 : 0.00030030228807449537\n",
      "Loss at iteration 495 : 0.0002989699404630992\n",
      "Loss at iteration 496 : 0.0002976462325298449\n",
      "Loss at iteration 497 : 0.0002963310908957891\n",
      "Loss at iteration 498 : 0.0002950244429508901\n",
      "Loss at iteration 499 : 0.0002937262168444194\n",
      "Loss at iteration 500 : 0.00029243634147554356\n",
      "Loss at iteration 501 : 0.0002911547464840247\n",
      "Loss at iteration 502 : 0.00028988136224104865\n",
      "Loss at iteration 503 : 0.000288616119840201\n",
      "Loss at iteration 504 : 0.00028735895108856677\n",
      "Loss at iteration 505 : 0.00028610978849793166\n",
      "Loss at iteration 506 : 0.0002848685652761633\n",
      "Loss at iteration 507 : 0.0002836352153186649\n",
      "Loss at iteration 508 : 0.0002824096731999641\n",
      "Loss at iteration 509 : 0.0002811918741654309\n",
      "Loss at iteration 510 : 0.0002799817541231052\n",
      "Loss at iteration 511 : 0.0002787792496356396\n",
      "Loss at iteration 512 : 0.000277584297912366\n",
      "Loss at iteration 513 : 0.0002763968368014454\n",
      "Loss at iteration 514 : 0.0002752168047821548\n",
      "Loss at iteration 515 : 0.00027404414095727985\n",
      "Loss at iteration 516 : 0.0002728787850456049\n",
      "Loss at iteration 517 : 0.000271720677374502\n",
      "Loss at iteration 518 : 0.0002705697588726364\n",
      "Loss at iteration 519 : 0.00026942597106276926\n",
      "Loss at iteration 520 : 0.0002682892560546622\n",
      "Loss at iteration 521 : 0.00026715955653806704\n",
      "Loss at iteration 522 : 0.000266036815775828\n",
      "Loss at iteration 523 : 0.0002649209775970736\n",
      "Loss at iteration 524 : 0.0002638119863904989\n",
      "Loss at iteration 525 : 0.0002627097870977413\n",
      "Loss at iteration 526 : 0.00026161432520685143\n",
      "Loss at iteration 527 : 0.0002605255467458522\n",
      "Loss at iteration 528 : 0.00025944339827637427\n",
      "Loss at iteration 529 : 0.00025836782688739104\n",
      "Loss at iteration 530 : 0.0002572987801890474\n",
      "Loss at iteration 531 : 0.0002562362063065471\n",
      "Loss at iteration 532 : 0.0002551800538741295\n",
      "Loss at iteration 533 : 0.00025413027202915347\n",
      "Loss at iteration 534 : 0.00025308681040623807\n",
      "Loss at iteration 535 : 0.00025204961913146074\n",
      "Loss at iteration 536 : 0.00025101864881670066\n",
      "Loss at iteration 537 : 0.00024999385055397155\n",
      "Loss at iteration 538 : 0.00024897517590991697\n",
      "Loss at iteration 539 : 0.000247962576920306\n",
      "Loss at iteration 540 : 0.0002469560060846473\n",
      "Loss at iteration 541 : 0.00024595541636085537\n",
      "Loss at iteration 542 : 0.00024496076116000635\n",
      "Loss at iteration 543 : 0.00024397199434113075\n",
      "Loss at iteration 544 : 0.00024298907020611112\n",
      "Loss at iteration 545 : 0.0002420119434946224\n",
      "Loss at iteration 546 : 0.0002410405693791547\n",
      "Loss at iteration 547 : 0.00024007490346008762\n",
      "Loss at iteration 548 : 0.00023911490176084093\n",
      "Loss at iteration 549 : 0.000238160520723084\n",
      "Loss at iteration 550 : 0.00023721171720200504\n",
      "Loss at iteration 551 : 0.00023626844846165202\n",
      "Loss at iteration 552 : 0.00023533067217032657\n",
      "Loss at iteration 553 : 0.00023439834639603368\n",
      "Loss at iteration 554 : 0.0002334714296019982\n",
      "Loss at iteration 555 : 0.00023254988064224684\n",
      "Loss at iteration 556 : 0.00023163365875722918\n",
      "Loss at iteration 557 : 0.00023072272356950218\n",
      "Loss at iteration 558 : 0.00022981703507947985\n",
      "Loss at iteration 559 : 0.00022891655366123076\n",
      "Loss at iteration 560 : 0.00022802124005833323\n",
      "Loss at iteration 561 : 0.00022713105537976197\n",
      "Loss at iteration 562 : 0.00022624596109586275\n",
      "Loss at iteration 563 : 0.00022536591903435794\n",
      "Loss at iteration 564 : 0.00022449089137640857\n",
      "Loss at iteration 565 : 0.00022362084065271823\n",
      "Loss at iteration 566 : 0.0002227557297397002\n",
      "Loss at iteration 567 : 0.0002218955218556751\n",
      "Loss at iteration 568 : 0.0002210401805571487\n",
      "Loss at iteration 569 : 0.00022018966973509367\n",
      "Loss at iteration 570 : 0.00021934395361131274\n",
      "Loss at iteration 571 : 0.00021850299673483646\n",
      "Loss at iteration 572 : 0.00021766676397836653\n",
      "Loss at iteration 573 : 0.00021683522053475175\n",
      "Loss at iteration 574 : 0.000216008331913536\n",
      "Loss at iteration 575 : 0.00021518606393751964\n",
      "Loss at iteration 576 : 0.000214368382739393\n",
      "Loss at iteration 577 : 0.0002135552547583728\n",
      "Loss at iteration 578 : 0.0002127466467369327\n",
      "Loss at iteration 579 : 0.00021194252571752307\n",
      "Loss at iteration 580 : 0.00021114285903936904\n",
      "Loss at iteration 581 : 0.00021034761433528257\n",
      "Loss at iteration 582 : 0.00020955675952854012\n",
      "Loss at iteration 583 : 0.00020877026282976446\n",
      "Loss at iteration 584 : 0.00020798809273388447\n",
      "Loss at iteration 585 : 0.00020721021801709953\n",
      "Loss at iteration 586 : 0.0002064366077338948\n",
      "Loss at iteration 587 : 0.0002056672312141086\n",
      "Loss at iteration 588 : 0.0002049020580599976\n",
      "Loss at iteration 589 : 0.00020414105814337143\n",
      "Loss at iteration 590 : 0.00020338420160275064\n",
      "Loss at iteration 591 : 0.00020263145884056756\n",
      "Loss at iteration 592 : 0.00020188280052037784\n",
      "Loss at iteration 593 : 0.00020113819756412338\n",
      "Loss at iteration 594 : 0.00020039762114944888\n",
      "Loss at iteration 595 : 0.00019966104270700022\n",
      "Loss at iteration 596 : 0.00019892843391780012\n",
      "Loss at iteration 597 : 0.0001981997667106374\n",
      "Loss at iteration 598 : 0.00019747501325949153\n",
      "Loss at iteration 599 : 0.000196754145980971\n",
      "Loss at iteration 600 : 0.00019603713753182624\n",
      "Loss at iteration 601 : 0.00019532396080644332\n",
      "Loss at iteration 602 : 0.00019461458893438603\n",
      "Loss at iteration 603 : 0.00019390899527798358\n",
      "Loss at iteration 604 : 0.00019320715342993448\n",
      "Loss at iteration 605 : 0.0001925090372109143\n",
      "Loss at iteration 606 : 0.00019181462066726992\n",
      "Loss at iteration 607 : 0.00019112387806867847\n",
      "Loss at iteration 608 : 0.0001904367839058707\n",
      "Loss at iteration 609 : 0.0001897533128883833\n",
      "Loss at iteration 610 : 0.00018907343994231654\n",
      "Loss at iteration 611 : 0.00018839714020812726\n",
      "Loss at iteration 612 : 0.0001877243890384633\n",
      "Loss at iteration 613 : 0.00018705516199599327\n",
      "Loss at iteration 614 : 0.0001863894348512942\n",
      "Loss at iteration 615 : 0.0001857271835807423\n",
      "Loss at iteration 616 : 0.00018506838436441815\n",
      "Loss at iteration 617 : 0.00018441301358408934\n",
      "Loss at iteration 618 : 0.00018376104782114521\n",
      "Loss at iteration 619 : 0.0001831124638546112\n",
      "Loss at iteration 620 : 0.00018246723865915338\n",
      "Loss at iteration 621 : 0.00018182534940312724\n",
      "Loss at iteration 622 : 0.00018118677344663623\n",
      "Loss at iteration 623 : 0.0001805514883396209\n",
      "Loss at iteration 624 : 0.0001799194718199523\n",
      "Loss at iteration 625 : 0.0001792907018115861\n",
      "Loss at iteration 626 : 0.00017866515642269196\n",
      "Loss at iteration 627 : 0.000178042813943831\n",
      "Loss at iteration 628 : 0.00017742365284614825\n",
      "Loss at iteration 629 : 0.00017680765177959694\n",
      "Loss at iteration 630 : 0.00017619478957115484\n",
      "Loss at iteration 631 : 0.0001755850452230967\n",
      "Loss at iteration 632 : 0.00017497839791125294\n",
      "Loss at iteration 633 : 0.00017437482698331446\n",
      "Loss at iteration 634 : 0.00017377431195713666\n",
      "Loss at iteration 635 : 0.0001731768325190861\n",
      "Loss at iteration 636 : 0.00017258236852237436\n",
      "Loss at iteration 637 : 0.0001719908999854423\n",
      "Loss at iteration 638 : 0.0001714024070903442\n",
      "Loss at iteration 639 : 0.00017081687018115328\n",
      "Loss at iteration 640 : 0.0001702342697623816\n",
      "Loss at iteration 641 : 0.00016965458649743047\n",
      "Loss at iteration 642 : 0.00016907780120705983\n",
      "Loss at iteration 643 : 0.00016850389486783334\n",
      "Loss at iteration 644 : 0.00016793284861065172\n",
      "Loss at iteration 645 : 0.0001673646437192335\n",
      "Loss at iteration 646 : 0.0001667992616286607\n",
      "Loss at iteration 647 : 0.00016623668392391452\n",
      "Loss at iteration 648 : 0.0001656768923384402\n",
      "Loss at iteration 649 : 0.00016511986875272007\n",
      "Loss at iteration 650 : 0.00016456559519286869\n",
      "Loss at iteration 651 : 0.00016401405382924524\n",
      "Loss at iteration 652 : 0.00016346522697505974\n",
      "Loss at iteration 653 : 0.00016291909708503248\n",
      "Loss at iteration 654 : 0.0001623756467540382\n",
      "Loss at iteration 655 : 0.0001618348587157679\n",
      "Loss at iteration 656 : 0.00016129671584142515\n",
      "Loss at iteration 657 : 0.00016076120113841418\n",
      "Loss at iteration 658 : 0.00016022829774905862\n",
      "Loss at iteration 659 : 0.00015969798894931714\n",
      "Loss at iteration 660 : 0.00015917025814753556\n",
      "Loss at iteration 661 : 0.00015864508888319454\n",
      "Loss at iteration 662 : 0.00015812246482566886\n",
      "Loss at iteration 663 : 0.00015760236977302905\n",
      "Loss at iteration 664 : 0.00015708478765081164\n",
      "Loss at iteration 665 : 0.0001565697025108389\n",
      "Loss at iteration 666 : 0.0001560570985300433\n",
      "Loss at iteration 667 : 0.00015554696000928832\n",
      "Loss at iteration 668 : 0.00015503927137221866\n",
      "Loss at iteration 669 : 0.00015453401716412207\n",
      "Loss at iteration 670 : 0.00015403118205079377\n",
      "Loss at iteration 671 : 0.00015353075081742104\n",
      "Loss at iteration 672 : 0.00015303270836747613\n",
      "Loss at iteration 673 : 0.0001525370397216269\n",
      "Loss at iteration 674 : 0.0001520437300166496\n",
      "Loss at iteration 675 : 0.00015155276450435723\n",
      "Loss at iteration 676 : 0.00015106412855055105\n",
      "Loss at iteration 677 : 0.0001505778076339558\n",
      "Loss at iteration 678 : 0.00015009378734519497\n",
      "Loss at iteration 679 : 0.00014961205338576486\n",
      "Loss at iteration 680 : 0.0001491325915670173\n",
      "Loss at iteration 681 : 0.00014865538780915532\n",
      "Loss at iteration 682 : 0.00014818042814023099\n",
      "Loss at iteration 683 : 0.0001477076986951886\n",
      "Loss at iteration 684 : 0.00014723718571485732\n",
      "Loss at iteration 685 : 0.00014676887554502266\n",
      "Loss at iteration 686 : 0.000146302754635443\n",
      "Loss at iteration 687 : 0.0001458388095389345\n",
      "Loss at iteration 688 : 0.0001453770269104252\n",
      "Loss at iteration 689 : 0.0001449173935060266\n",
      "Loss at iteration 690 : 0.00014445989618213685\n",
      "Loss at iteration 691 : 0.00014400452189452986\n",
      "Loss at iteration 692 : 0.00014355125769745602\n",
      "Loss at iteration 693 : 0.00014310009074276336\n",
      "Loss at iteration 694 : 0.00014265100827902524\n",
      "Loss at iteration 695 : 0.00014220399765066822\n",
      "Loss at iteration 696 : 0.00014175904629711407\n",
      "Loss at iteration 697 : 0.00014131614175193894\n",
      "Loss at iteration 698 : 0.00014087527164202874\n",
      "Loss at iteration 699 : 0.000140436423686743\n",
      "Loss at iteration 700 : 0.00013999958569710618\n",
      "Loss at iteration 701 : 0.00013956474557498023\n",
      "Loss at iteration 702 : 0.00013913189131226474\n",
      "Loss at iteration 703 : 0.00013870101099010292\n",
      "Loss at iteration 704 : 0.00013827209277808477\n",
      "Loss at iteration 705 : 0.00013784512493347496\n",
      "Loss at iteration 706 : 0.0001374200958004342\n",
      "Loss at iteration 707 : 0.00013699699380925306\n",
      "Loss at iteration 708 : 0.00013657580747559645\n",
      "Loss at iteration 709 : 0.0001361565253997578\n",
      "Loss at iteration 710 : 0.00013573913626591737\n",
      "Loss at iteration 711 : 0.00013532362884139607\n",
      "Loss at iteration 712 : 0.00013490999197593754\n",
      "Loss at iteration 713 : 0.0001344982146009963\n",
      "Loss at iteration 714 : 0.00013408828572901042\n",
      "Loss at iteration 715 : 0.0001336801944527059\n",
      "Loss at iteration 716 : 0.00013327392994438882\n",
      "Loss at iteration 717 : 0.00013286948145527176\n",
      "Loss at iteration 718 : 0.0001324668383147719\n",
      "Loss at iteration 719 : 0.0001320659899298415\n",
      "Loss at iteration 720 : 0.00013166692578430413\n",
      "Loss at iteration 721 : 0.00013126963543817874\n",
      "Loss at iteration 722 : 0.00013087410852702895\n",
      "Loss at iteration 723 : 0.00013048033476130655\n",
      "Loss at iteration 724 : 0.00013008830392572318\n",
      "Loss at iteration 725 : 0.0001296980058785978\n",
      "Loss at iteration 726 : 0.00012930943055122518\n",
      "Loss at iteration 727 : 0.00012892256794726624\n",
      "Loss at iteration 728 : 0.00012853740814210824\n",
      "Loss at iteration 729 : 0.00012815394128226775\n",
      "Loss at iteration 730 : 0.00012777215758478394\n",
      "Loss at iteration 731 : 0.00012739204733660316\n",
      "Loss at iteration 732 : 0.0001270136008940037\n",
      "Loss at iteration 733 : 0.00012663680868199426\n",
      "Loss at iteration 734 : 0.00012626166119373235\n",
      "Loss at iteration 735 : 0.00012588814898995362\n",
      "Loss at iteration 736 : 0.00012551626269839127\n",
      "Loss at iteration 737 : 0.0001251459930132251\n",
      "Loss at iteration 738 : 0.00012477733069449565\n",
      "Loss at iteration 739 : 0.00012441026656757442\n",
      "Loss at iteration 740 : 0.0001240447915226018\n",
      "Loss at iteration 741 : 0.00012368089651394873\n",
      "Loss at iteration 742 : 0.00012331857255966624\n",
      "Loss at iteration 743 : 0.00012295781074097065\n",
      "Loss at iteration 744 : 0.00012259860220169603\n",
      "Loss at iteration 745 : 0.0001222409381477816\n",
      "Loss at iteration 746 : 0.00012188480984675667\n",
      "Loss at iteration 747 : 0.00012153020862721483\n",
      "Loss at iteration 748 : 0.00012117712587831388\n",
      "Loss at iteration 749 : 0.00012082555304927674\n",
      "Loss at iteration 750 : 0.00012047548164887962\n",
      "Loss at iteration 751 : 0.00012012690324497507\n",
      "Loss at iteration 752 : 0.00011977980946398746\n",
      "Loss at iteration 753 : 0.00011943419199043537\n",
      "Loss at iteration 754 : 0.00011909004256645904\n",
      "Loss at iteration 755 : 0.00011874735299132621\n",
      "Loss at iteration 756 : 0.00011840611512098321\n",
      "Loss at iteration 757 : 0.000118066320867573\n",
      "Loss at iteration 758 : 0.00011772796219898754\n",
      "Loss at iteration 759 : 0.00011739103113839747\n",
      "Loss at iteration 760 : 0.00011705551976379817\n",
      "Loss at iteration 761 : 0.00011672142020758126\n",
      "Loss at iteration 762 : 0.00011638872465606623\n",
      "Loss at iteration 763 : 0.0001160574253490747\n",
      "Loss at iteration 764 : 0.00011572751457948704\n",
      "Loss at iteration 765 : 0.00011539898469281856\n",
      "Loss at iteration 766 : 0.00011507182808678592\n",
      "Loss at iteration 767 : 0.00011474603721088153\n",
      "Loss at iteration 768 : 0.0001144216045659574\n",
      "Loss at iteration 769 : 0.00011409852270381215\n",
      "Loss at iteration 770 : 0.00011377678422677207\n",
      "Loss at iteration 771 : 0.0001134563817872897\n",
      "Loss at iteration 772 : 0.00011313730808753413\n",
      "Loss at iteration 773 : 0.00011281955587899299\n",
      "Loss at iteration 774 : 0.00011250311796207852\n",
      "Loss at iteration 775 : 0.00011218798718572997\n",
      "Loss at iteration 776 : 0.00011187415644702423\n",
      "Loss at iteration 777 : 0.00011156161869079513\n",
      "Loss at iteration 778 : 0.00011125036690924673\n",
      "Loss at iteration 779 : 0.00011094039414157642\n",
      "Loss at iteration 780 : 0.00011063169347359711\n",
      "Loss at iteration 781 : 0.00011032425803737349\n",
      "Loss at iteration 782 : 0.00011001808101084424\n",
      "Loss at iteration 783 : 0.00010971315561746162\n",
      "Loss at iteration 784 : 0.0001094094751258297\n",
      "Loss at iteration 785 : 0.00010910703284934606\n",
      "Loss at iteration 786 : 0.00010880582214584885\n",
      "Loss at iteration 787 : 0.00010850583641726632\n",
      "Loss at iteration 788 : 0.00010820706910925585\n",
      "Loss at iteration 789 : 0.00010790951371087828\n",
      "Loss at iteration 790 : 0.00010761316375424131\n",
      "Loss at iteration 791 : 0.00010731801281416999\n",
      "Loss at iteration 792 : 0.00010702405450786019\n",
      "Loss at iteration 793 : 0.00010673128249455998\n",
      "Loss at iteration 794 : 0.00010643969047522802\n",
      "Loss at iteration 795 : 0.0001061492721922089\n",
      "Loss at iteration 796 : 0.00010586002142891403\n",
      "Loss at iteration 797 : 0.00010557193200950025\n",
      "Loss at iteration 798 : 0.00010528499779855013\n",
      "Loss at iteration 799 : 0.00010499921270075111\n",
      "Loss at iteration 800 : 0.00010471457066059696\n",
      "Loss at iteration 801 : 0.00010443106566206425\n",
      "Loss at iteration 802 : 0.00010414869172831569\n",
      "Loss at iteration 803 : 0.00010386744292139466\n",
      "Loss at iteration 804 : 0.00010358731334191701\n",
      "Loss at iteration 805 : 0.00010330829712878061\n",
      "Loss at iteration 806 : 0.00010303038845886927\n",
      "Loss at iteration 807 : 0.00010275358154675368\n",
      "Loss at iteration 808 : 0.00010247787064440476\n",
      "Loss at iteration 809 : 0.00010220325004091024\n",
      "Loss at iteration 810 : 0.00010192971406218084\n",
      "Loss at iteration 811 : 0.00010165725707067183\n",
      "Loss at iteration 812 : 0.0001013858734651073\n",
      "Loss at iteration 813 : 0.00010111555768018869\n",
      "Loss at iteration 814 : 0.00010084630418633868\n",
      "Loss at iteration 815 : 0.00010057810748940979\n",
      "Loss at iteration 816 : 0.00010031096213042654\n",
      "Loss at iteration 817 : 0.00010004486268531933\n",
      "Loss at iteration 818 : 9.977980376463846e-05\n",
      "Loss at iteration 819 : 9.951578001331977e-05\n",
      "Loss at iteration 820 : 9.92527861103973e-05\n",
      "Loss at iteration 821 : 9.899081676876948e-05\n",
      "Loss at iteration 822 : 9.87298667349138e-05\n",
      "Loss at iteration 823 : 9.84699307886646e-05\n",
      "Loss at iteration 824 : 9.821100374293223e-05\n",
      "Loss at iteration 825 : 9.795308044347302e-05\n",
      "Loss at iteration 826 : 9.769615576863335e-05\n",
      "Loss at iteration 827 : 9.744022462910717e-05\n",
      "Loss at iteration 828 : 9.71852819676874e-05\n",
      "Loss at iteration 829 : 9.693132275903368e-05\n",
      "Loss at iteration 830 : 9.667834200942688e-05\n",
      "Loss at iteration 831 : 9.642633475652979e-05\n",
      "Loss at iteration 832 : 9.617529606916467e-05\n",
      "Loss at iteration 833 : 9.592522104706294e-05\n",
      "Loss at iteration 834 : 9.567610482065056e-05\n",
      "Loss at iteration 835 : 9.542794255080906e-05\n",
      "Loss at iteration 836 : 9.518072942865132e-05\n",
      "Loss at iteration 837 : 9.493446067529818e-05\n",
      "Loss at iteration 838 : 9.468913154165158e-05\n",
      "Loss at iteration 839 : 9.444473730818429e-05\n",
      "Loss at iteration 840 : 9.420127328469906e-05\n",
      "Loss at iteration 841 : 9.395873481013961e-05\n",
      "Loss at iteration 842 : 9.37171172523543e-05\n",
      "Loss at iteration 843 : 9.347641600788672e-05\n",
      "Loss at iteration 844 : 9.323662650177202e-05\n",
      "Loss at iteration 845 : 9.299774418731464e-05\n",
      "Loss at iteration 846 : 9.275976454589557e-05\n",
      "Loss at iteration 847 : 9.252268308674783e-05\n",
      "Loss at iteration 848 : 9.228649534676899e-05\n",
      "Loss at iteration 849 : 9.205119689030747e-05\n",
      "Loss at iteration 850 : 9.181678330896605e-05\n",
      "Loss at iteration 851 : 9.15832502213984e-05\n",
      "Loss at iteration 852 : 9.135059327312035e-05\n",
      "Loss at iteration 853 : 9.11188081363008e-05\n",
      "Loss at iteration 854 : 9.088789050957867e-05\n",
      "Loss at iteration 855 : 9.065783611786248e-05\n",
      "Loss at iteration 856 : 9.042864071214578e-05\n",
      "Loss at iteration 857 : 9.020030006931252e-05\n",
      "Loss at iteration 858 : 8.997280999195144e-05\n",
      "Loss at iteration 859 : 8.97461663081715e-05\n",
      "Loss at iteration 860 : 8.952036487141352e-05\n",
      "Loss at iteration 861 : 8.929540156026185e-05\n",
      "Loss at iteration 862 : 8.907127227828393e-05\n",
      "Loss at iteration 863 : 8.8847972953823e-05\n",
      "Loss at iteration 864 : 8.862549953983842e-05\n",
      "Loss at iteration 865 : 8.840384801371483e-05\n",
      "Loss at iteration 866 : 8.818301437710468e-05\n",
      "Loss at iteration 867 : 8.796299465573608e-05\n",
      "Loss at iteration 868 : 8.774378489924859e-05\n",
      "Loss at iteration 869 : 8.752538118101882e-05\n",
      "Loss at iteration 870 : 8.730777959799598e-05\n",
      "Loss at iteration 871 : 8.709097627052735e-05\n",
      "Loss at iteration 872 : 8.687496734219319e-05\n",
      "Loss at iteration 873 : 8.665974897964195e-05\n",
      "Loss at iteration 874 : 8.644531737242274e-05\n",
      "Loss at iteration 875 : 8.623166873283314e-05\n",
      "Loss at iteration 876 : 8.60187992957369e-05\n",
      "Loss at iteration 877 : 8.580670531842943e-05\n",
      "Loss at iteration 878 : 8.559538308045535e-05\n",
      "Loss at iteration 879 : 8.538482888346349e-05\n",
      "Loss at iteration 880 : 8.51750390510526e-05\n",
      "Loss at iteration 881 : 8.496600992860598e-05\n",
      "Loss at iteration 882 : 8.475773788314437e-05\n",
      "Loss at iteration 883 : 8.455021930317631e-05\n",
      "Loss at iteration 884 : 8.43434505985414e-05\n",
      "Loss at iteration 885 : 8.413742820025546e-05\n",
      "Loss at iteration 886 : 8.393214856037849e-05\n",
      "Loss at iteration 887 : 8.372760815184748e-05\n",
      "Loss at iteration 888 : 8.352380346834528e-05\n",
      "Loss at iteration 889 : 8.332073102414352e-05\n",
      "Loss at iteration 890 : 8.31183873539706e-05\n",
      "Loss at iteration 891 : 8.29167690128542e-05\n",
      "Loss at iteration 892 : 8.271587257599536e-05\n",
      "Loss at iteration 893 : 8.251569463861578e-05\n",
      "Loss at iteration 894 : 8.231623181582386e-05\n",
      "Loss at iteration 895 : 8.211748074247414e-05\n",
      "Loss at iteration 896 : 8.191943807303325e-05\n",
      "Loss at iteration 897 : 8.17221004814415e-05\n",
      "Loss at iteration 898 : 8.15254646609741e-05\n",
      "Loss at iteration 899 : 8.132952732411972e-05\n",
      "Loss at iteration 900 : 8.113428520242655e-05\n",
      "Loss at iteration 901 : 8.093973504639748e-05\n",
      "Loss at iteration 902 : 8.074587362533273e-05\n",
      "Loss at iteration 903 : 8.055269772721941e-05\n",
      "Loss at iteration 904 : 8.036020415859207e-05\n",
      "Loss at iteration 905 : 8.016838974441435e-05\n",
      "Loss at iteration 906 : 7.997725132794116e-05\n",
      "Loss at iteration 907 : 7.978678577060024e-05\n",
      "Loss at iteration 908 : 7.959698995186864e-05\n",
      "Loss at iteration 909 : 7.940786076914328e-05\n",
      "Loss at iteration 910 : 7.921939513762558e-05\n",
      "Loss at iteration 911 : 7.903158999018967e-05\n",
      "Loss at iteration 912 : 7.884444227727763e-05\n",
      "Loss at iteration 913 : 7.865794896675922e-05\n",
      "Loss at iteration 914 : 7.847210704383204e-05\n",
      "Loss at iteration 915 : 7.82869135108923e-05\n",
      "Loss at iteration 916 : 7.810236538742039e-05\n",
      "Loss at iteration 917 : 7.791845970987062e-05\n",
      "Loss at iteration 918 : 7.773519353154059e-05\n",
      "Loss at iteration 919 : 7.75525639224804e-05\n",
      "Loss at iteration 920 : 7.737056796935866e-05\n",
      "Loss at iteration 921 : 7.718920277536195e-05\n",
      "Loss at iteration 922 : 7.700846546007401e-05\n",
      "Loss at iteration 923 : 7.682835315937572e-05\n",
      "Loss at iteration 924 : 7.664886302533188e-05\n",
      "Loss at iteration 925 : 7.646999222607243e-05\n",
      "Loss at iteration 926 : 7.629173794569777e-05\n",
      "Loss at iteration 927 : 7.611409738416766e-05\n",
      "Loss at iteration 928 : 7.593706775719286e-05\n",
      "Loss at iteration 929 : 7.576064629612455e-05\n",
      "Loss at iteration 930 : 7.55848302478622e-05\n",
      "Loss at iteration 931 : 7.540961687474063e-05\n",
      "Loss at iteration 932 : 7.523500345442314e-05\n",
      "Loss at iteration 933 : 7.506098727981628e-05\n",
      "Loss at iteration 934 : 7.4887565658946e-05\n",
      "Loss at iteration 935 : 7.471473591487681e-05\n",
      "Loss at iteration 936 : 7.454249538559355e-05\n",
      "Loss at iteration 937 : 7.437084142391975e-05\n",
      "Loss at iteration 938 : 7.419977139740564e-05\n",
      "Loss at iteration 939 : 7.40292826882421e-05\n",
      "Loss at iteration 940 : 7.385937269315058e-05\n",
      "Loss at iteration 941 : 7.369003882329371e-05\n",
      "Loss at iteration 942 : 7.352127850418844e-05\n",
      "Loss at iteration 943 : 7.33530891755948e-05\n",
      "Loss at iteration 944 : 7.31854682914323e-05\n",
      "Loss at iteration 945 : 7.301841331968417e-05\n",
      "Loss at iteration 946 : 7.285192174230664e-05\n",
      "Loss at iteration 947 : 7.26859910551318e-05\n",
      "Loss at iteration 948 : 7.252061876778589e-05\n",
      "Loss at iteration 949 : 7.235580240358733e-05\n",
      "Loss at iteration 950 : 7.219153949946347e-05\n",
      "Loss at iteration 951 : 7.202782760586422e-05\n",
      "Loss at iteration 952 : 7.186466428666871e-05\n",
      "Loss at iteration 953 : 7.170204711909771e-05\n",
      "Loss at iteration 954 : 7.15399736936275e-05\n",
      "Loss at iteration 955 : 7.137844161390439e-05\n",
      "Loss at iteration 956 : 7.121744849666051e-05\n",
      "Loss at iteration 957 : 7.105699197162307e-05\n",
      "Loss at iteration 958 : 7.089706968143901e-05\n",
      "Loss at iteration 959 : 7.073767928157681e-05\n",
      "Loss at iteration 960 : 7.057881844025891e-05\n",
      "Loss at iteration 961 : 7.04204848383695e-05\n",
      "Loss at iteration 962 : 7.026267616937779e-05\n",
      "Loss at iteration 963 : 7.010539013925298e-05\n",
      "Loss at iteration 964 : 6.99486244663808e-05\n",
      "Loss at iteration 965 : 6.979237688149205e-05\n",
      "Loss at iteration 966 : 6.963664512758047e-05\n",
      "Loss at iteration 967 : 6.948142695981553e-05\n",
      "Loss at iteration 968 : 6.932672014547103e-05\n",
      "Loss at iteration 969 : 6.917252246385173e-05\n",
      "Loss at iteration 970 : 6.901883170620936e-05\n",
      "Loss at iteration 971 : 6.886564567566247e-05\n",
      "Loss at iteration 972 : 6.871296218713234e-05\n",
      "Loss at iteration 973 : 6.856077906725473e-05\n",
      "Loss at iteration 974 : 6.840909415431882e-05\n",
      "Loss at iteration 975 : 6.825790529817461e-05\n",
      "Loss at iteration 976 : 6.810721036018139e-05\n",
      "Loss at iteration 977 : 6.795700721311287e-05\n",
      "Loss at iteration 978 : 6.780729374109676e-05\n",
      "Loss at iteration 979 : 6.765806783954521e-05\n",
      "Loss at iteration 980 : 6.750932741507401e-05\n",
      "Loss at iteration 981 : 6.736107038543192e-05\n",
      "Loss at iteration 982 : 6.721329467944133e-05\n",
      "Loss at iteration 983 : 6.706599823691382e-05\n",
      "Loss at iteration 984 : 6.691917900859416e-05\n",
      "Loss at iteration 985 : 6.677283495607392e-05\n",
      "Loss at iteration 986 : 6.662696405174724e-05\n",
      "Loss at iteration 987 : 6.648156427871446e-05\n",
      "Loss at iteration 988 : 6.633663363074254e-05\n",
      "Loss at iteration 989 : 6.619217011217456e-05\n",
      "Loss at iteration 990 : 6.60481717378755e-05\n",
      "Loss at iteration 991 : 6.590463653316945e-05\n",
      "Loss at iteration 992 : 6.576156253376144e-05\n",
      "Loss at iteration 993 : 6.561894778568208e-05\n",
      "Loss at iteration 994 : 6.547679034521875e-05\n",
      "Loss at iteration 995 : 6.533508827885634e-05\n",
      "Loss at iteration 996 : 6.519383966320562e-05\n",
      "Loss at iteration 997 : 6.505304258494634e-05\n",
      "Loss at iteration 998 : 6.491269514076028e-05\n",
      "Loss at iteration 999 : 6.477279543727842e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss List for Different Learning Rates: \")\n",
    "print(\n",
    "    \"loss of learning rate 0.1: \",\n",
    ")\n",
    "loss_list_l1 = nn_l1.train(\n",
    "    np.array([[1, 0.91, 1.37]]),\n",
    "    np.array([[1, 0]]),\n",
    "    early_stopping=False,\n",
    "    epochs=no_of_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of learning rate 0.01: \n",
      "Loss at iteration 0 : 0.31827364004543107\n",
      "Loss at iteration 1 : 0.31693542759790966\n",
      "Loss at iteration 2 : 0.31559760905844614\n",
      "Loss at iteration 3 : 0.31426023665089975\n",
      "Loss at iteration 4 : 0.31292336272129784\n",
      "Loss at iteration 5 : 0.3115870397248514\n",
      "Loss at iteration 6 : 0.31025132021294766\n",
      "Loss at iteration 7 : 0.30891625682012436\n",
      "Loss at iteration 8 : 0.30758190225103255\n",
      "Loss at iteration 9 : 0.30624830926739277\n",
      "Loss at iteration 10 : 0.3049155306749506\n",
      "Loss at iteration 11 : 0.3035836193104373\n",
      "Loss at iteration 12 : 0.302252628028542\n",
      "Loss at iteration 13 : 0.3009226096888993\n",
      "Loss at iteration 14 : 0.2995936171431006\n",
      "Loss at iteration 15 : 0.29826570322173324\n",
      "Loss at iteration 16 : 0.29693892072145284\n",
      "Loss at iteration 17 : 0.29561332239209603\n",
      "Loss at iteration 18 : 0.29428896092383844\n",
      "Loss at iteration 19 : 0.29296588893440373\n",
      "Loss at iteration 20 : 0.29164415895632867\n",
      "Loss at iteration 21 : 0.29032382342429147\n",
      "Loss at iteration 22 : 0.2890049346625076\n",
      "Loss at iteration 23 : 0.2876875448721984\n",
      "Loss at iteration 24 : 0.28637170611913965\n",
      "Loss at iteration 25 : 0.2850574703212936\n",
      "Loss at iteration 26 : 0.2837448892365314\n",
      "Loss at iteration 27 : 0.28243401445045\n",
      "Loss at iteration 28 : 0.2811248973642895\n",
      "Loss at iteration 29 : 0.27981758918295624\n",
      "Loss at iteration 30 : 0.27851214090315596\n",
      "Loss at iteration 31 : 0.27720860330164293\n",
      "Loss at iteration 32 : 0.2759070269235899\n",
      "Loss at iteration 33 : 0.27460746207108266\n",
      "Loss at iteration 34 : 0.2733099587917454\n",
      "Loss at iteration 35 : 0.2720145668675009\n",
      "Loss at iteration 36 : 0.27072133580347035\n",
      "Loss at iteration 37 : 0.2694303148170164\n",
      "Loss at iteration 38 : 0.2681415528269356\n",
      "Loss at iteration 39 : 0.2668550984428026\n",
      "Loss at iteration 40 : 0.26557099995447164\n",
      "Loss at iteration 41 : 0.2642893053217389\n",
      "Loss at iteration 42 : 0.26301006216416906\n",
      "Loss at iteration 43 : 0.26173331775109177\n",
      "Loss at iteration 44 : 0.2604591189917685\n",
      "Loss at iteration 45 : 0.25918751242573723\n",
      "Loss at iteration 46 : 0.2579185442133356\n",
      "Loss at iteration 47 : 0.2566522601264065\n",
      "Loss at iteration 48 : 0.2553887055391901\n",
      "Loss at iteration 49 : 0.25412792541940454\n",
      "Loss at iteration 50 : 0.2528699643195187\n",
      "Loss at iteration 51 : 0.25161486636821945\n",
      "Loss at iteration 52 : 0.2503626752620764\n",
      "Loss at iteration 53 : 0.2491134342574064\n",
      "Loss at iteration 54 : 0.24786718616234016\n",
      "Loss at iteration 55 : 0.246623973329094\n",
      "Loss at iteration 56 : 0.24538383764644733\n",
      "Loss at iteration 57 : 0.24414682053242967\n",
      "Loss at iteration 58 : 0.24291296292721676\n",
      "Loss at iteration 59 : 0.24168230528624024\n",
      "Loss at iteration 60 : 0.24045488757350966\n",
      "Loss at iteration 61 : 0.23923074925515056\n",
      "Loss at iteration 62 : 0.23800992929315762\n",
      "Loss at iteration 63 : 0.2367924661393665\n",
      "Loss at iteration 64 : 0.23557839772964262\n",
      "Loss at iteration 65 : 0.23436776147829042\n",
      "Loss at iteration 66 : 0.23316059427268154\n",
      "Loss at iteration 67 : 0.23195693246810348\n",
      "Loss at iteration 68 : 0.23075681188282943\n",
      "Loss at iteration 69 : 0.22956026779340885\n",
      "Loss at iteration 70 : 0.22836733493017955\n",
      "Loss at iteration 71 : 0.2271780474730002\n",
      "Loss at iteration 72 : 0.22599243904720456\n",
      "Loss at iteration 73 : 0.22481054271977632\n",
      "Loss at iteration 74 : 0.22363239099574417\n",
      "Loss at iteration 75 : 0.22245801581479646\n",
      "Loss at iteration 76 : 0.22128744854811547\n",
      "Loss at iteration 77 : 0.22012071999542954\n",
      "Loss at iteration 78 : 0.21895786038228301\n",
      "Loss at iteration 79 : 0.2177988993575224\n",
      "Loss at iteration 80 : 0.21664386599099744\n",
      "Loss at iteration 81 : 0.21549278877147693\n",
      "Loss at iteration 82 : 0.21434569560477648\n",
      "Loss at iteration 83 : 0.21320261381209696\n",
      "Loss at iteration 84 : 0.21206357012857388\n",
      "Loss at iteration 85 : 0.2109285907020328\n",
      "Loss at iteration 86 : 0.20979770109195184\n",
      "Loss at iteration 87 : 0.20867092626862754\n",
      "Loss at iteration 88 : 0.2075482906125429\n",
      "Loss at iteration 89 : 0.2064298179139355\n",
      "Loss at iteration 90 : 0.20531553137256278\n",
      "Loss at iteration 91 : 0.20420545359766315\n",
      "Loss at iteration 92 : 0.20309960660810966\n",
      "Loss at iteration 93 : 0.20199801183275456\n",
      "Loss at iteration 94 : 0.20090069011096143\n",
      "Loss at iteration 95 : 0.19980766169332265\n",
      "Loss at iteration 96 : 0.19871894624255984\n",
      "Loss at iteration 97 : 0.1976345628346038\n",
      "Loss at iteration 98 : 0.1965545299598514\n",
      "Loss at iteration 99 : 0.1954788655245968\n",
      "Loss at iteration 100 : 0.1944075868526339\n",
      "Loss at iteration 101 : 0.19334071068702632\n",
      "Loss at iteration 102 : 0.1922782531920428\n",
      "Loss at iteration 103 : 0.191220229955255\n",
      "Loss at iteration 104 : 0.1901666559897927\n",
      "Loss at iteration 105 : 0.1891175457367559\n",
      "Loss at iteration 106 : 0.18807291306777812\n",
      "Loss at iteration 107 : 0.18703277128773957\n",
      "Loss at iteration 108 : 0.1859971331376246\n",
      "Loss at iteration 109 : 0.18496601079752278\n",
      "Loss at iteration 110 : 0.18393941588976814\n",
      "Loss at iteration 111 : 0.18291735948221338\n",
      "Loss at iteration 112 : 0.18189985209163723\n",
      "Loss at iteration 113 : 0.1808869036872787\n",
      "Loss at iteration 114 : 0.1798785236944977\n",
      "Loss at iteration 115 : 0.17887472099855667\n",
      "Loss at iteration 116 : 0.1778755039485198\n",
      "Loss at iteration 117 : 0.17688088036126748\n",
      "Loss at iteration 118 : 0.1758908575256208\n",
      "Loss at iteration 119 : 0.17490544220657456\n",
      "Loss at iteration 120 : 0.17392464064963292\n",
      "Loss at iteration 121 : 0.17294845858524657\n",
      "Loss at iteration 122 : 0.17197690123334577\n",
      "Loss at iteration 123 : 0.17100997330796758\n",
      "Loss at iteration 124 : 0.17004767902197226\n",
      "Loss at iteration 125 : 0.16909002209184645\n",
      "Loss at iteration 126 : 0.16813700574258864\n",
      "Loss at iteration 127 : 0.16718863271267495\n",
      "Loss at iteration 128 : 0.16624490525910018\n",
      "Loss at iteration 129 : 0.1653058251624913\n",
      "Loss at iteration 130 : 0.1643713937322908\n",
      "Loss at iteration 131 : 0.16344161181200537\n",
      "Loss at iteration 132 : 0.1625164797845169\n",
      "Loss at iteration 133 : 0.16159599757745277\n",
      "Loss at iteration 134 : 0.16068016466861237\n",
      "Loss at iteration 135 : 0.15976898009144555\n",
      "Loss at iteration 136 : 0.15886244244058106\n",
      "Loss at iteration 137 : 0.1579605498774007\n",
      "Loss at iteration 138 : 0.157063300135657\n",
      "Loss at iteration 139 : 0.15617069052713045\n",
      "Loss at iteration 140 : 0.15528271794732415\n",
      "Loss at iteration 141 : 0.15439937888119173\n",
      "Loss at iteration 142 : 0.15352066940889678\n",
      "Loss at iteration 143 : 0.15264658521159988\n",
      "Loss at iteration 144 : 0.15177712157727075\n",
      "Loss at iteration 145 : 0.15091227340652272\n",
      "Loss at iteration 146 : 0.15005203521846683\n",
      "Loss at iteration 147 : 0.14919640115658245\n",
      "Loss at iteration 148 : 0.14834536499460152\n",
      "Loss at iteration 149 : 0.147498920142405\n",
      "Loss at iteration 150 : 0.14665705965192724\n",
      "Loss at iteration 151 : 0.14581977622306735\n",
      "Loss at iteration 152 : 0.14498706220960325\n",
      "Loss at iteration 153 : 0.14415890962510813\n",
      "Loss at iteration 154 : 0.14333531014886458\n",
      "Loss at iteration 155 : 0.1425162551317767\n",
      "Loss at iteration 156 : 0.14170173560227478\n",
      "Loss at iteration 157 : 0.14089174227221316\n",
      "Loss at iteration 158 : 0.14008626554275783\n",
      "Loss at iteration 159 : 0.13928529551026084\n",
      "Loss at iteration 160 : 0.13848882197212142\n",
      "Loss at iteration 161 : 0.1376968344326301\n",
      "Loss at iteration 162 : 0.13690932210879428\n",
      "Loss at iteration 163 : 0.13612627393614413\n",
      "Loss at iteration 164 : 0.13534767857451577\n",
      "Loss at iteration 165 : 0.13457352441381099\n",
      "Loss at iteration 166 : 0.13380379957973068\n",
      "Loss at iteration 167 : 0.1330384919394817\n",
      "Loss at iteration 168 : 0.1322775891074537\n",
      "Loss at iteration 169 : 0.13152107845086602\n",
      "Loss at iteration 170 : 0.13076894709538248\n",
      "Loss at iteration 171 : 0.13002118193069168\n",
      "Loss at iteration 172 : 0.12927776961605358\n",
      "Loss at iteration 173 : 0.12853869658580808\n",
      "Loss at iteration 174 : 0.12780394905484696\n",
      "Loss at iteration 175 : 0.12707351302404604\n",
      "Loss at iteration 176 : 0.12634737428565765\n",
      "Loss at iteration 177 : 0.1256255184286607\n",
      "Loss at iteration 178 : 0.12490793084406926\n",
      "Loss at iteration 179 : 0.12419459673019631\n",
      "Loss at iteration 180 : 0.12348550109787357\n",
      "Loss at iteration 181 : 0.12278062877562504\n",
      "Loss at iteration 182 : 0.12207996441479428\n",
      "Loss at iteration 183 : 0.12138349249462399\n",
      "Loss at iteration 184 : 0.1206911973272865\n",
      "Loss at iteration 185 : 0.12000306306286652\n",
      "Loss at iteration 186 : 0.11931907369429234\n",
      "Loss at iteration 187 : 0.11863921306221711\n",
      "Loss at iteration 188 : 0.1179634648598487\n",
      "Loss at iteration 189 : 0.11729181263772728\n",
      "Loss at iteration 190 : 0.11662423980845052\n",
      "Loss at iteration 191 : 0.11596072965134555\n",
      "Loss at iteration 192 : 0.11530126531708706\n",
      "Loss at iteration 193 : 0.11464582983226151\n",
      "Loss at iteration 194 : 0.11399440610387643\n",
      "Loss at iteration 195 : 0.11334697692381521\n",
      "Loss at iteration 196 : 0.11270352497323598\n",
      "Loss at iteration 197 : 0.11206403282691496\n",
      "Loss at iteration 198 : 0.1114284829575343\n",
      "Loss at iteration 199 : 0.11079685773991285\n",
      "Loss at iteration 200 : 0.11016913945518123\n",
      "Loss at iteration 201 : 0.10954531029489967\n",
      "Loss at iteration 202 : 0.1089253523651193\n",
      "Loss at iteration 203 : 0.10830924769038658\n",
      "Loss at iteration 204 : 0.10769697821769039\n",
      "Loss at iteration 205 : 0.10708852582035211\n",
      "Loss at iteration 206 : 0.10648387230185875\n",
      "Loss at iteration 207 : 0.10588299939963837\n",
      "Loss at iteration 208 : 0.10528588878877887\n",
      "Loss at iteration 209 : 0.10469252208568919\n",
      "Loss at iteration 210 : 0.10410288085170374\n",
      "Loss at iteration 211 : 0.10351694659662987\n",
      "Loss at iteration 212 : 0.10293470078223783\n",
      "Loss at iteration 213 : 0.1023561248256949\n",
      "Loss at iteration 214 : 0.10178120010294218\n",
      "Loss at iteration 215 : 0.10120990795201512\n",
      "Loss at iteration 216 : 0.1006422296763083\n",
      "Loss at iteration 217 : 0.1000781465477833\n",
      "Loss at iteration 218 : 0.09951763981012175\n",
      "Loss at iteration 219 : 0.0989606906818221\n",
      "Loss at iteration 220 : 0.09840728035924139\n",
      "Loss at iteration 221 : 0.09785739001958244\n",
      "Loss at iteration 222 : 0.09731100082382547\n",
      "Loss at iteration 223 : 0.09676809391960658\n",
      "Loss at iteration 224 : 0.09622865044404108\n",
      "Loss at iteration 225 : 0.09569265152649392\n",
      "Loss at iteration 226 : 0.09516007829129658\n",
      "Loss at iteration 227 : 0.09463091186041091\n",
      "Loss at iteration 228 : 0.09410513335604083\n",
      "Loss at iteration 229 : 0.09358272390319161\n",
      "Loss at iteration 230 : 0.09306366463217743\n",
      "Loss at iteration 231 : 0.09254793668107793\n",
      "Loss at iteration 232 : 0.09203552119814368\n",
      "Loss at iteration 233 : 0.09152639934415148\n",
      "Loss at iteration 234 : 0.09102055229470946\n",
      "Loss at iteration 235 : 0.09051796124251281\n",
      "Loss at iteration 236 : 0.09001860739955077\n",
      "Loss at iteration 237 : 0.08952247199926465\n",
      "Loss at iteration 238 : 0.08902953629865824\n",
      "Loss at iteration 239 : 0.08853978158036019\n",
      "Loss at iteration 240 : 0.08805318915464012\n",
      "Loss at iteration 241 : 0.0875697403613772\n",
      "Loss at iteration 242 : 0.08708941657198367\n",
      "Loss at iteration 243 : 0.08661219919128219\n",
      "Loss at iteration 244 : 0.08613806965933841\n",
      "Loss at iteration 245 : 0.08566700945324929\n",
      "Loss at iteration 246 : 0.0851990000888871\n",
      "Loss at iteration 247 : 0.08473402312260038\n",
      "Loss at iteration 248 : 0.08427206015287175\n",
      "Loss at iteration 249 : 0.0838130928219337\n",
      "Loss at iteration 250 : 0.0833571028173421\n",
      "Loss at iteration 251 : 0.08290407187350907\n",
      "Loss at iteration 252 : 0.08245398177319468\n",
      "Loss at iteration 253 : 0.08200681434895873\n",
      "Loss at iteration 254 : 0.08156255148457277\n",
      "Loss at iteration 255 : 0.08112117511639312\n",
      "Loss at iteration 256 : 0.0806826672346954\n",
      "Loss at iteration 257 : 0.080247009884971\n",
      "Loss at iteration 258 : 0.07981418516918616\n",
      "Loss at iteration 259 : 0.07938417524700406\n",
      "Loss at iteration 260 : 0.07895696233697075\n",
      "Loss at iteration 261 : 0.07853252871766514\n",
      "Loss at iteration 262 : 0.07811085672881382\n",
      "Loss at iteration 263 : 0.07769192877237086\n",
      "Loss at iteration 264 : 0.07727572731356398\n",
      "Loss at iteration 265 : 0.07686223488190648\n",
      "Loss at iteration 266 : 0.0764514340721765\n",
      "Loss at iteration 267 : 0.07604330754536337\n",
      "Loss at iteration 268 : 0.07563783802958214\n",
      "Loss at iteration 269 : 0.07523500832095655\n",
      "Loss at iteration 270 : 0.07483480128447079\n",
      "Loss at iteration 271 : 0.074437199854791\n",
      "Loss at iteration 272 : 0.07404218703705676\n",
      "Loss at iteration 273 : 0.073649745907643\n",
      "Loss at iteration 274 : 0.07325985961489315\n",
      "Loss at iteration 275 : 0.07287251137982378\n",
      "Loss at iteration 276 : 0.07248768449680112\n",
      "Loss at iteration 277 : 0.07210536233419051\n",
      "Loss at iteration 278 : 0.07172552833497861\n",
      "Loss at iteration 279 : 0.07134816601736929\n",
      "Loss at iteration 280 : 0.07097325897535357\n",
      "Loss at iteration 281 : 0.070600790879254\n",
      "Loss at iteration 282 : 0.070230745476244\n",
      "Loss at iteration 283 : 0.0698631065908431\n",
      "Loss at iteration 284 : 0.06949785812538734\n",
      "Loss at iteration 285 : 0.06913498406047679\n",
      "Loss at iteration 286 : 0.06877446845539957\n",
      "Loss at iteration 287 : 0.06841629544853337\n",
      "Loss at iteration 288 : 0.06806044925772463\n",
      "Loss at iteration 289 : 0.06770691418064584\n",
      "Loss at iteration 290 : 0.06735567459513181\n",
      "Loss at iteration 291 : 0.06700671495949471\n",
      "Loss at iteration 292 : 0.0666600198128189\n",
      "Loss at iteration 293 : 0.06631557377523542\n",
      "Loss at iteration 294 : 0.06597336154817725\n",
      "Loss at iteration 295 : 0.06563336791461473\n",
      "Loss at iteration 296 : 0.06529557773927303\n",
      "Loss at iteration 297 : 0.06495997596883041\n",
      "Loss at iteration 298 : 0.06462654763209896\n",
      "Loss at iteration 299 : 0.06429527784018765\n",
      "Loss at iteration 300 : 0.06396615178664795\n",
      "Loss at iteration 301 : 0.06363915474760298\n",
      "Loss at iteration 302 : 0.06331427208185986\n",
      "Loss at iteration 303 : 0.06299148923100623\n",
      "Loss at iteration 304 : 0.06267079171949094\n",
      "Loss at iteration 305 : 0.06235216515468951\n",
      "Loss at iteration 306 : 0.06203559522695436\n",
      "Loss at iteration 307 : 0.061721067709650766\n",
      "Loss at iteration 308 : 0.06140856845917811\n",
      "Loss at iteration 309 : 0.06109808341497772\n",
      "Loss at iteration 310 : 0.06078959859952657\n",
      "Loss at iteration 311 : 0.060483100118318034\n",
      "Loss at iteration 312 : 0.0601785741598296\n",
      "Loss at iteration 313 : 0.05987600699547805\n",
      "Loss at iteration 314 : 0.05957538497956222\n",
      "Loss at iteration 315 : 0.05927669454919374\n",
      "Loss at iteration 316 : 0.05897992222421648\n",
      "Loss at iteration 317 : 0.0586850546071139\n",
      "Loss at iteration 318 : 0.05839207838290615\n",
      "Loss at iteration 319 : 0.05810098031903567\n",
      "Loss at iteration 320 : 0.057811747265242866\n",
      "Loss at iteration 321 : 0.057524366153431115\n",
      "Loss at iteration 322 : 0.05723882399752216\n",
      "Loss at iteration 323 : 0.056955107893301646\n",
      "Loss at iteration 324 : 0.056673205018255395\n",
      "Loss at iteration 325 : 0.05639310263139653\n",
      "Loss at iteration 326 : 0.056114788073083635\n",
      "Loss at iteration 327 : 0.055838248764830394\n",
      "Loss at iteration 328 : 0.055563472209106936\n",
      "Loss at iteration 329 : 0.05529044598913291\n",
      "Loss at iteration 330 : 0.055019157768662834\n",
      "Loss at iteration 331 : 0.054749595291763674\n",
      "Loss at iteration 332 : 0.05448174638258524\n",
      "Loss at iteration 333 : 0.05421559894512305\n",
      "Loss at iteration 334 : 0.05395114096297479\n",
      "Loss at iteration 335 : 0.05368836049908947\n",
      "Loss at iteration 336 : 0.053427245695510425\n",
      "Loss at iteration 337 : 0.053167784773112015\n",
      "Loss at iteration 338 : 0.05290996603133005\n",
      "Loss at iteration 339 : 0.052653777847886635\n",
      "Loss at iteration 340 : 0.05239920867850884\n",
      "Loss at iteration 341 : 0.05214624705664248\n",
      "Loss at iteration 342 : 0.05189488159316017\n",
      "Loss at iteration 343 : 0.05164510097606453\n",
      "Loss at iteration 344 : 0.05139689397018619\n",
      "Loss at iteration 345 : 0.051150249416877416\n",
      "Loss at iteration 346 : 0.050905156233700954\n",
      "Loss at iteration 347 : 0.0506616034141144\n",
      "Loss at iteration 348 : 0.05041958002715063\n",
      "Loss at iteration 349 : 0.05017907521709402\n",
      "Loss at iteration 350 : 0.049940078203152743\n",
      "Loss at iteration 351 : 0.04970257827912745\n",
      "Loss at iteration 352 : 0.049466564813076236\n",
      "Loss at iteration 353 : 0.04923202724697644\n",
      "Loss at iteration 354 : 0.04899895509638297\n",
      "Loss at iteration 355 : 0.04876733795008339\n",
      "Loss at iteration 356 : 0.048537165469750496\n",
      "Loss at iteration 357 : 0.048308427389591596\n",
      "Loss at iteration 358 : 0.04808111351599534\n",
      "Loss at iteration 359 : 0.047855213727175785\n",
      "Loss at iteration 360 : 0.047630717972814374\n",
      "Loss at iteration 361 : 0.04740761627369923\n",
      "Loss at iteration 362 : 0.04718589872136249\n",
      "Loss at iteration 363 : 0.04696555547771558\n",
      "Loss at iteration 364 : 0.04674657677468243\n",
      "Loss at iteration 365 : 0.046528952913830995\n",
      "Loss at iteration 366 : 0.04631267426600305\n",
      "Loss at iteration 367 : 0.046097731270942376\n",
      "Loss at iteration 368 : 0.045884114436921336\n",
      "Loss at iteration 369 : 0.045671814340366414\n",
      "Loss at iteration 370 : 0.04546082162548199\n",
      "Loss at iteration 371 : 0.04525112700387347\n",
      "Loss at iteration 372 : 0.045042721254168944\n",
      "Loss at iteration 373 : 0.04483559522164003\n",
      "Loss at iteration 374 : 0.04462973981782194\n",
      "Loss at iteration 375 : 0.044425146020132394\n",
      "Loss at iteration 376 : 0.044221804871490245\n",
      "Loss at iteration 377 : 0.04401970747993334\n",
      "Loss at iteration 378 : 0.0438188450182357\n",
      "Loss at iteration 379 : 0.04361920872352443\n",
      "Loss at iteration 380 : 0.043420789896896315\n",
      "Loss at iteration 381 : 0.04322357990303391\n",
      "Loss at iteration 382 : 0.04302757016982153\n",
      "Loss at iteration 383 : 0.04283275218796116\n",
      "Loss at iteration 384 : 0.042639117510588305\n",
      "Loss at iteration 385 : 0.0424466577528877\n",
      "Loss at iteration 386 : 0.0422553645917092\n",
      "Loss at iteration 387 : 0.042065229765183856\n",
      "Loss at iteration 388 : 0.0418762450723401\n",
      "Loss at iteration 389 : 0.041688402372720285\n",
      "Loss at iteration 390 : 0.04150169358599748\n",
      "Loss at iteration 391 : 0.041316110691592696\n",
      "Loss at iteration 392 : 0.04113164572829255\n",
      "Loss at iteration 393 : 0.040948290793867505\n",
      "Loss at iteration 394 : 0.04076603804469055\n",
      "Loss at iteration 395 : 0.04058487969535654\n",
      "Loss at iteration 396 : 0.04040480801830226\n",
      "Loss at iteration 397 : 0.04022581534342713\n",
      "Loss at iteration 398 : 0.04004789405771475\n",
      "Loss at iteration 399 : 0.03987103660485506\n",
      "Loss at iteration 400 : 0.03969523548486768\n",
      "Loss at iteration 401 : 0.03952048325372592\n",
      "Loss at iteration 402 : 0.03934677252298167\n",
      "Loss at iteration 403 : 0.03917409595939152\n",
      "Loss at iteration 404 : 0.03900244628454376\n",
      "Loss at iteration 405 : 0.03883181627448637\n",
      "Loss at iteration 406 : 0.03866219875935628\n",
      "Loss at iteration 407 : 0.038493586623009626\n",
      "Loss at iteration 408 : 0.03832597280265337\n",
      "Loss at iteration 409 : 0.03815935028847768\n",
      "Loss at iteration 410 : 0.03799371212329024\n",
      "Loss at iteration 411 : 0.03782905140215116\n",
      "Loss at iteration 412 : 0.03766536127200966\n",
      "Loss at iteration 413 : 0.03750263493134169\n",
      "Loss at iteration 414 : 0.03734086562978943\n",
      "Loss at iteration 415 : 0.037180046667801475\n",
      "Loss at iteration 416 : 0.037020171396275135\n",
      "Loss at iteration 417 : 0.03686123321619966\n",
      "Loss at iteration 418 : 0.036703225578301205\n",
      "Loss at iteration 419 : 0.036546141982689205\n",
      "Loss at iteration 420 : 0.036389975978504165\n",
      "Loss at iteration 421 : 0.036234721163567074\n",
      "Loss at iteration 422 : 0.036080371184030395\n",
      "Loss at iteration 423 : 0.0359269197340305\n",
      "Loss at iteration 424 : 0.03577436055534192\n",
      "Loss at iteration 425 : 0.035622687437032764\n",
      "Loss at iteration 426 : 0.035471894215122333\n",
      "Loss at iteration 427 : 0.03532197477223988\n",
      "Loss at iteration 428 : 0.03517292303728532\n",
      "Loss at iteration 429 : 0.03502473298509147\n",
      "Loss at iteration 430 : 0.03487739863608798\n",
      "Loss at iteration 431 : 0.034730914055967094\n",
      "Loss at iteration 432 : 0.03458527335535087\n",
      "Loss at iteration 433 : 0.03444047068946037\n",
      "Loss at iteration 434 : 0.03429650025778644\n",
      "Loss at iteration 435 : 0.03415335630376226\n",
      "Loss at iteration 436 : 0.03401103311443766\n",
      "Loss at iteration 437 : 0.033869525020155146\n",
      "Loss at iteration 438 : 0.03372882639422792\n",
      "Loss at iteration 439 : 0.03358893165261918\n",
      "Loss at iteration 440 : 0.03344983525362382\n",
      "Loss at iteration 441 : 0.03331153169755146\n",
      "Loss at iteration 442 : 0.033174015526411534\n",
      "Loss at iteration 443 : 0.03303728132360002\n",
      "Loss at iteration 444 : 0.032901323713588095\n",
      "Loss at iteration 445 : 0.03276613736161255\n",
      "Loss at iteration 446 : 0.03263171697336807\n",
      "Loss at iteration 447 : 0.032498057294701246\n",
      "Loss at iteration 448 : 0.03236515311130651\n",
      "Loss at iteration 449 : 0.032232999248423926\n",
      "Loss at iteration 450 : 0.03210159057053864\n",
      "Loss at iteration 451 : 0.031970921981082416\n",
      "Loss at iteration 452 : 0.03184098842213675\n",
      "Loss at iteration 453 : 0.03171178487413803\n",
      "Loss at iteration 454 : 0.0315833063555844\n",
      "Loss at iteration 455 : 0.031455547922744624\n",
      "Loss at iteration 456 : 0.03132850466936861\n",
      "Loss at iteration 457 : 0.03120217172639979\n",
      "Loss at iteration 458 : 0.03107654426168957\n",
      "Loss at iteration 459 : 0.03095161747971334\n",
      "Loss at iteration 460 : 0.03082738662128846\n",
      "Loss at iteration 461 : 0.030703846963294\n",
      "Loss at iteration 462 : 0.03058099381839258\n",
      "Loss at iteration 463 : 0.030458822534753592\n",
      "Loss at iteration 464 : 0.030337328495778627\n",
      "Loss at iteration 465 : 0.030216507119828536\n",
      "Loss at iteration 466 : 0.030096353859952584\n",
      "Loss at iteration 467 : 0.029976864203618923\n",
      "Loss at iteration 468 : 0.029858033672447434\n",
      "Loss at iteration 469 : 0.029739857821943994\n",
      "Loss at iteration 470 : 0.029622332241236816\n",
      "Loss at iteration 471 : 0.029505452552814324\n",
      "Loss at iteration 472 : 0.029389214412265177\n",
      "Loss at iteration 473 : 0.029273613508019734\n",
      "Loss at iteration 474 : 0.02915864556109357\n",
      "Loss at iteration 475 : 0.02904430632483268\n",
      "Loss at iteration 476 : 0.028930591584660464\n",
      "Loss at iteration 477 : 0.02881749715782647\n",
      "Loss at iteration 478 : 0.028705018893156988\n",
      "Loss at iteration 479 : 0.028593152670807403\n",
      "Loss at iteration 480 : 0.028481894402016088\n",
      "Loss at iteration 481 : 0.028371240028860524\n",
      "Loss at iteration 482 : 0.028261185524014548\n",
      "Loss at iteration 483 : 0.028151726890507916\n",
      "Loss at iteration 484 : 0.028042860161487302\n",
      "Loss at iteration 485 : 0.027934581399979015\n",
      "Loss at iteration 486 : 0.02782688669865355\n",
      "Loss at iteration 487 : 0.027719772179591783\n",
      "Loss at iteration 488 : 0.027613233994052935\n",
      "Loss at iteration 489 : 0.02750726832224417\n",
      "Loss at iteration 490 : 0.02740187137309192\n",
      "Loss at iteration 491 : 0.027297039384014878\n",
      "Loss at iteration 492 : 0.0271927686206987\n",
      "Loss at iteration 493 : 0.027089055376872357\n",
      "Loss at iteration 494 : 0.02698589597408619\n",
      "Loss at iteration 495 : 0.026883286761491428\n",
      "Loss at iteration 496 : 0.02678122411562173\n",
      "Loss at iteration 497 : 0.026679704440175936\n",
      "Loss at iteration 498 : 0.02657872416580279\n",
      "Loss at iteration 499 : 0.026478279749887076\n",
      "Loss at iteration 500 : 0.026378367676337534\n",
      "Loss at iteration 501 : 0.026278984455376117\n",
      "Loss at iteration 502 : 0.026180126623329213\n",
      "Loss at iteration 503 : 0.026081790742420136\n",
      "Loss at iteration 504 : 0.025983973400563368\n",
      "Loss at iteration 505 : 0.025886671211160252\n",
      "Loss at iteration 506 : 0.02578988081289655\n",
      "Loss at iteration 507 : 0.025693598869541028\n",
      "Loss at iteration 508 : 0.025597822069746076\n",
      "Loss at iteration 509 : 0.025502547126849632\n",
      "Loss at iteration 510 : 0.02540777077867871\n",
      "Loss at iteration 511 : 0.025313489787354322\n",
      "Loss at iteration 512 : 0.02521970093909818\n",
      "Loss at iteration 513 : 0.025126401044040556\n",
      "Loss at iteration 514 : 0.02503358693602987\n",
      "Loss at iteration 515 : 0.024941255472443677\n",
      "Loss at iteration 516 : 0.02484940353400133\n",
      "Loss at iteration 517 : 0.024758028024577543\n",
      "Loss at iteration 518 : 0.024667125871018224\n",
      "Loss at iteration 519 : 0.024576694022957042\n",
      "Loss at iteration 520 : 0.024486729452633853\n",
      "Loss at iteration 521 : 0.024397229154714338\n",
      "Loss at iteration 522 : 0.024308190146111287\n",
      "Loss at iteration 523 : 0.024219609465806986\n",
      "Loss at iteration 524 : 0.024131484174677288\n",
      "Loss at iteration 525 : 0.02404381135531696\n",
      "Loss at iteration 526 : 0.02395658811186639\n",
      "Loss at iteration 527 : 0.023869811569839694\n",
      "Loss at iteration 528 : 0.02378347887595423\n",
      "Loss at iteration 529 : 0.023697587197961435\n",
      "Loss at iteration 530 : 0.02361213372447902\n",
      "Loss at iteration 531 : 0.02352711566482444\n",
      "Loss at iteration 532 : 0.023442530248849815\n",
      "Loss at iteration 533 : 0.023358374726778104\n",
      "Loss at iteration 534 : 0.023274646369040582\n",
      "Loss at iteration 535 : 0.023191342466115636\n",
      "Loss at iteration 536 : 0.023108460328368847\n",
      "Loss at iteration 537 : 0.023025997285894374\n",
      "Loss at iteration 538 : 0.02294395068835764\n",
      "Loss at iteration 539 : 0.022862317904839235\n",
      "Loss at iteration 540 : 0.02278109632368004\n",
      "Loss at iteration 541 : 0.022700283352327776\n",
      "Loss at iteration 542 : 0.022619876417184503\n",
      "Loss at iteration 543 : 0.022539872963455748\n",
      "Loss at iteration 544 : 0.022460270455000455\n",
      "Loss at iteration 545 : 0.022381066374182357\n",
      "Loss at iteration 546 : 0.022302258221722594\n",
      "Loss at iteration 547 : 0.02222384351655341\n",
      "Loss at iteration 548 : 0.0221458197956731\n",
      "Loss at iteration 549 : 0.022068184614002093\n",
      "Loss at iteration 550 : 0.021990935544240316\n",
      "Loss at iteration 551 : 0.02191407017672555\n",
      "Loss at iteration 552 : 0.02183758611929306\n",
      "Loss at iteration 553 : 0.021761480997136463\n",
      "Loss at iteration 554 : 0.021685752452669398\n",
      "Loss at iteration 555 : 0.021610398145388718\n",
      "Loss at iteration 556 : 0.021535415751738504\n",
      "Loss at iteration 557 : 0.021460802964975448\n",
      "Loss at iteration 558 : 0.021386557495035097\n",
      "Loss at iteration 559 : 0.021312677068399257\n",
      "Loss at iteration 560 : 0.021239159427964706\n",
      "Loss at iteration 561 : 0.02116600233291263\n",
      "Loss at iteration 562 : 0.021093203558579358\n",
      "Loss at iteration 563 : 0.02102076089632818\n",
      "Loss at iteration 564 : 0.020948672153422044\n",
      "Loss at iteration 565 : 0.020876935152897375\n",
      "Loss at iteration 566 : 0.020805547733439154\n",
      "Loss at iteration 567 : 0.02073450774925659\n",
      "Loss at iteration 568 : 0.02066381306996022\n",
      "Loss at iteration 569 : 0.020593461580439773\n",
      "Loss at iteration 570 : 0.020523451180743148\n",
      "Loss at iteration 571 : 0.02045377978595637\n",
      "Loss at iteration 572 : 0.020384445326084525\n",
      "Loss at iteration 573 : 0.02031544574593377\n",
      "Loss at iteration 574 : 0.020246779004994025\n",
      "Loss at iteration 575 : 0.020178443077323083\n",
      "Loss at iteration 576 : 0.02011043595143127\n",
      "Loss at iteration 577 : 0.02004275563016735\n",
      "Loss at iteration 578 : 0.019975400130605114\n",
      "Loss at iteration 579 : 0.019908367483931155\n",
      "Loss at iteration 580 : 0.019841655735333443\n",
      "Loss at iteration 581 : 0.019775262943890752\n",
      "Loss at iteration 582 : 0.019709187182463242\n",
      "Loss at iteration 583 : 0.01964342653758365\n",
      "Loss at iteration 584 : 0.019577979109349584\n",
      "Loss at iteration 585 : 0.019512843011316713\n",
      "Loss at iteration 586 : 0.01944801637039269\n",
      "Loss at iteration 587 : 0.019383497326732113\n",
      "Loss at iteration 588 : 0.019319284033632207\n",
      "Loss at iteration 589 : 0.019255374657429592\n",
      "Loss at iteration 590 : 0.01919176737739767\n",
      "Loss at iteration 591 : 0.01912846038564498\n",
      "Loss at iteration 592 : 0.01906545188701441\n",
      "Loss at iteration 593 : 0.019002740098983232\n",
      "Loss at iteration 594 : 0.01894032325156384\n",
      "Loss at iteration 595 : 0.018878199587205633\n",
      "Loss at iteration 596 : 0.018816367360697264\n",
      "Loss at iteration 597 : 0.01875482483907016\n",
      "Loss at iteration 598 : 0.018693570301502455\n",
      "Loss at iteration 599 : 0.018632602039224042\n",
      "Loss at iteration 600 : 0.01857191835542213\n",
      "Loss at iteration 601 : 0.018511517565147805\n",
      "Loss at iteration 602 : 0.01845139799522326\n",
      "Loss at iteration 603 : 0.018391557984149796\n",
      "Loss at iteration 604 : 0.018331995882016644\n",
      "Loss at iteration 605 : 0.018272710050410507\n",
      "Loss at iteration 606 : 0.018213698862325857\n",
      "Loss at iteration 607 : 0.018154960702075906\n",
      "Loss at iteration 608 : 0.018096493965204553\n",
      "Loss at iteration 609 : 0.01803829705839871\n",
      "Loss at iteration 610 : 0.01798036839940169\n",
      "Loss at iteration 611 : 0.017922706416927107\n",
      "Loss at iteration 612 : 0.017865309550573562\n",
      "Loss at iteration 613 : 0.017808176250740063\n",
      "Loss at iteration 614 : 0.017751304978542017\n",
      "Loss at iteration 615 : 0.01769469420572824\n",
      "Loss at iteration 616 : 0.01763834241459813\n",
      "Loss at iteration 617 : 0.01758224809792007\n",
      "Loss at iteration 618 : 0.017526409758850257\n",
      "Loss at iteration 619 : 0.01747082591085208\n",
      "Loss at iteration 620 : 0.017415495077616434\n",
      "Loss at iteration 621 : 0.01736041579298255\n",
      "Loss at iteration 622 : 0.017305586600859475\n",
      "Loss at iteration 623 : 0.01725100605514826\n",
      "Loss at iteration 624 : 0.01719667271966478\n",
      "Loss at iteration 625 : 0.017142585168063117\n",
      "Loss at iteration 626 : 0.017088741983759738\n",
      "Loss at iteration 627 : 0.017035141759858142\n",
      "Loss at iteration 628 : 0.016981783099074225\n",
      "Loss at iteration 629 : 0.016928664613662242\n",
      "Loss at iteration 630 : 0.016875784925341385\n",
      "Loss at iteration 631 : 0.016823142665222984\n",
      "Loss at iteration 632 : 0.016770736473738196\n",
      "Loss at iteration 633 : 0.01671856500056653\n",
      "Loss at iteration 634 : 0.016666626904564715\n",
      "Loss at iteration 635 : 0.01661492085369637\n",
      "Loss at iteration 636 : 0.016563445524962042\n",
      "Loss at iteration 637 : 0.016512199604330043\n",
      "Loss at iteration 638 : 0.016461181786667674\n",
      "Loss at iteration 639 : 0.016410390775673155\n",
      "Loss at iteration 640 : 0.01635982528380802\n",
      "Loss at iteration 641 : 0.01630948403223014\n",
      "Loss at iteration 642 : 0.016259365750727308\n",
      "Loss at iteration 643 : 0.016209469177651276\n",
      "Loss at iteration 644 : 0.016159793059852393\n",
      "Loss at iteration 645 : 0.016110336152614882\n",
      "Loss at iteration 646 : 0.016061097219592476\n",
      "Loss at iteration 647 : 0.016012075032744735\n",
      "Loss at iteration 648 : 0.015963268372273784\n",
      "Loss at iteration 649 : 0.01591467602656162\n",
      "Loss at iteration 650 : 0.015866296792107947\n",
      "Loss at iteration 651 : 0.01581812947346855\n",
      "Loss at iteration 652 : 0.01577017288319403\n",
      "Loss at iteration 653 : 0.01572242584176927\n",
      "Loss at iteration 654 : 0.015674887177553186\n",
      "Loss at iteration 655 : 0.01562755572671919\n",
      "Loss at iteration 656 : 0.015580430333195904\n",
      "Loss at iteration 657 : 0.015533509848608539\n",
      "Loss at iteration 658 : 0.015486793132220698\n",
      "Loss at iteration 659 : 0.015440279050876676\n",
      "Loss at iteration 660 : 0.015393966478944199\n",
      "Loss at iteration 661 : 0.015347854298257689\n",
      "Loss at iteration 662 : 0.01530194139806191\n",
      "Loss at iteration 663 : 0.015256226674956196\n",
      "Loss at iteration 664 : 0.015210709032839007\n",
      "Loss at iteration 665 : 0.01516538738285304\n",
      "Loss at iteration 666 : 0.015120260643330793\n",
      "Loss at iteration 667 : 0.015075327739740477\n",
      "Loss at iteration 668 : 0.01503058760463245\n",
      "Loss at iteration 669 : 0.01498603917758612\n",
      "Loss at iteration 670 : 0.01494168140515718\n",
      "Loss at iteration 671 : 0.014897513240825363\n",
      "Loss at iteration 672 : 0.014853533644942607\n",
      "Loss at iteration 673 : 0.0148097415846816\n",
      "Loss at iteration 674 : 0.014766136033984831\n",
      "Loss at iteration 675 : 0.014722715973513973\n",
      "Loss at iteration 676 : 0.014679480390599717\n",
      "Loss at iteration 677 : 0.014636428279192001\n",
      "Loss at iteration 678 : 0.014593558639810749\n",
      "Loss at iteration 679 : 0.014550870479496752\n",
      "Loss at iteration 680 : 0.014508362811763294\n",
      "Loss at iteration 681 : 0.014466034656547916\n",
      "Loss at iteration 682 : 0.01442388504016465\n",
      "Loss at iteration 683 : 0.01438191299525671\n",
      "Loss at iteration 684 : 0.014340117560749408\n",
      "Loss at iteration 685 : 0.01429849778180367\n",
      "Loss at iteration 686 : 0.014257052709769742\n",
      "Loss at iteration 687 : 0.014215781402141386\n",
      "Loss at iteration 688 : 0.014174682922510347\n",
      "Loss at iteration 689 : 0.014133756340521338\n",
      "Loss at iteration 690 : 0.01409300073182729\n",
      "Loss at iteration 691 : 0.014052415178044838\n",
      "Loss at iteration 692 : 0.014011998766710592\n",
      "Loss at iteration 693 : 0.01397175059123719\n",
      "Loss at iteration 694 : 0.013931669750870204\n",
      "Loss at iteration 695 : 0.013891755350645109\n",
      "Loss at iteration 696 : 0.013852006501344653\n",
      "Loss at iteration 697 : 0.013812422319456733\n",
      "Loss at iteration 698 : 0.013773001927132319\n",
      "Loss at iteration 699 : 0.013733744452144004\n",
      "Loss at iteration 700 : 0.013694649027844725\n",
      "Loss at iteration 701 : 0.013655714793126857\n",
      "Loss at iteration 702 : 0.013616940892381618\n",
      "Loss at iteration 703 : 0.013578326475458872\n",
      "Loss at iteration 704 : 0.013539870697627219\n",
      "Loss at iteration 705 : 0.013501572719534378\n",
      "Loss at iteration 706 : 0.013463431707167853\n",
      "Loss at iteration 707 : 0.01342544683181606\n",
      "Loss at iteration 708 : 0.013387617270029632\n",
      "Loss at iteration 709 : 0.013349942203583083\n",
      "Loss at iteration 710 : 0.013312420819436878\n",
      "Loss at iteration 711 : 0.013275052309699515\n",
      "Loss at iteration 712 : 0.013237835871590296\n",
      "Loss at iteration 713 : 0.013200770707402101\n",
      "Loss at iteration 714 : 0.013163856024464644\n",
      "Loss at iteration 715 : 0.013127091035107884\n",
      "Loss at iteration 716 : 0.013090474956625816\n",
      "Loss at iteration 717 : 0.013054007011240584\n",
      "Loss at iteration 718 : 0.013017686426066726\n",
      "Loss at iteration 719 : 0.012981512433075904\n",
      "Loss at iteration 720 : 0.012945484269061799\n",
      "Loss at iteration 721 : 0.012909601175605264\n",
      "Loss at iteration 722 : 0.012873862399039832\n",
      "Loss at iteration 723 : 0.012838267190417493\n",
      "Loss at iteration 724 : 0.01280281480547468\n",
      "Loss at iteration 725 : 0.012767504504598591\n",
      "Loss at iteration 726 : 0.012732335552793711\n",
      "Loss at iteration 727 : 0.012697307219648717\n",
      "Loss at iteration 728 : 0.012662418779303566\n",
      "Loss at iteration 729 : 0.012627669510416741\n",
      "Loss at iteration 730 : 0.012593058696133015\n",
      "Loss at iteration 731 : 0.01255858562405125\n",
      "Loss at iteration 732 : 0.012524249586192563\n",
      "Loss at iteration 733 : 0.012490049878968684\n",
      "Loss at iteration 734 : 0.012455985803150566\n",
      "Loss at iteration 735 : 0.012422056663837354\n",
      "Loss at iteration 736 : 0.012388261770425455\n",
      "Loss at iteration 737 : 0.012354600436577937\n",
      "Loss at iteration 738 : 0.012321071980194094\n",
      "Loss at iteration 739 : 0.012287675723379417\n",
      "Loss at iteration 740 : 0.01225441099241558\n",
      "Loss at iteration 741 : 0.012221277117730814\n",
      "Loss at iteration 742 : 0.012188273433870526\n",
      "Loss at iteration 743 : 0.012155399279468047\n",
      "Loss at iteration 744 : 0.012122653997215634\n",
      "Loss at iteration 745 : 0.012090036933835827\n",
      "Loss at iteration 746 : 0.012057547440052791\n",
      "Loss at iteration 747 : 0.012025184870564233\n",
      "Loss at iteration 748 : 0.011992948584013147\n",
      "Loss at iteration 749 : 0.011960837942960012\n",
      "Loss at iteration 750 : 0.011928852313855279\n",
      "Loss at iteration 751 : 0.011896991067011833\n",
      "Loss at iteration 752 : 0.011865253576577828\n",
      "Loss at iteration 753 : 0.011833639220509739\n",
      "Loss at iteration 754 : 0.011802147380545606\n",
      "Loss at iteration 755 : 0.011770777442178403\n",
      "Loss at iteration 756 : 0.011739528794629764\n",
      "Loss at iteration 757 : 0.011708400830823786\n",
      "Loss at iteration 758 : 0.01167739294736111\n",
      "Loss at iteration 759 : 0.011646504544493197\n",
      "Loss at iteration 760 : 0.01161573502609678\n",
      "Loss at iteration 761 : 0.011585083799648482\n",
      "Loss at iteration 762 : 0.011554550276199792\n",
      "Loss at iteration 763 : 0.011524133870351984\n",
      "Loss at iteration 764 : 0.011493834000231481\n",
      "Loss at iteration 765 : 0.011463650087465246\n",
      "Loss at iteration 766 : 0.011433581557156385\n",
      "Loss at iteration 767 : 0.011403627837860074\n",
      "Loss at iteration 768 : 0.011373788361559455\n",
      "Loss at iteration 769 : 0.011344062563641922\n",
      "Loss at iteration 770 : 0.01131444988287548\n",
      "Loss at iteration 771 : 0.011284949761385277\n",
      "Loss at iteration 772 : 0.011255561644630362\n",
      "Loss at iteration 773 : 0.011226284981380709\n",
      "Loss at iteration 774 : 0.0111971192236942\n",
      "Loss at iteration 775 : 0.011168063826893926\n",
      "Loss at iteration 776 : 0.011139118249545726\n",
      "Loss at iteration 777 : 0.011110281953435774\n",
      "Loss at iteration 778 : 0.011081554403548334\n",
      "Loss at iteration 779 : 0.011052935068043852\n",
      "Loss at iteration 780 : 0.011024423418237032\n",
      "Loss at iteration 781 : 0.010996018928575104\n",
      "Loss at iteration 782 : 0.010967721076616433\n",
      "Loss at iteration 783 : 0.010939529343009088\n",
      "Loss at iteration 784 : 0.010911443211469642\n",
      "Loss at iteration 785 : 0.010883462168762171\n",
      "Loss at iteration 786 : 0.010855585704677428\n",
      "Loss at iteration 787 : 0.01082781331201208\n",
      "Loss at iteration 788 : 0.010800144486548207\n",
      "Loss at iteration 789 : 0.010772578727032897\n",
      "Loss at iteration 790 : 0.010745115535157982\n",
      "Loss at iteration 791 : 0.010717754415540062\n",
      "Loss at iteration 792 : 0.010690494875700448\n",
      "Loss at iteration 793 : 0.010663336426045545\n",
      "Loss at iteration 794 : 0.010636278579847098\n",
      "Loss at iteration 795 : 0.010609320853222746\n",
      "Loss at iteration 796 : 0.01058246276511683\n",
      "Loss at iteration 797 : 0.010555703837281029\n",
      "Loss at iteration 798 : 0.01052904359425548\n",
      "Loss at iteration 799 : 0.01050248156334983\n",
      "Loss at iteration 800 : 0.010476017274624484\n",
      "Loss at iteration 801 : 0.010449650260872068\n",
      "Loss at iteration 802 : 0.010423380057598918\n",
      "Loss at iteration 803 : 0.010397206203006793\n",
      "Loss at iteration 804 : 0.010371128237974685\n",
      "Loss at iteration 805 : 0.010345145706040797\n",
      "Loss at iteration 806 : 0.01031925815338464\n",
      "Loss at iteration 807 : 0.010293465128809215\n",
      "Loss at iteration 808 : 0.010267766183723484\n",
      "Loss at iteration 809 : 0.010242160872124748\n",
      "Loss at iteration 810 : 0.010216648750581387\n",
      "Loss at iteration 811 : 0.010191229378215559\n",
      "Loss at iteration 812 : 0.01016590231668614\n",
      "Loss at iteration 813 : 0.010140667130171675\n",
      "Loss at iteration 814 : 0.01011552338535362\n",
      "Loss at iteration 815 : 0.010090470651399593\n",
      "Loss at iteration 816 : 0.010065508499946666\n",
      "Loss at iteration 817 : 0.010040636505085097\n",
      "Loss at iteration 818 : 0.010015854243341804\n",
      "Loss at iteration 819 : 0.009991161293664244\n",
      "Loss at iteration 820 : 0.009966557237404229\n",
      "Loss at iteration 821 : 0.009942041658302064\n",
      "Loss at iteration 822 : 0.009917614142470523\n",
      "Loss at iteration 823 : 0.00989327427837925\n",
      "Loss at iteration 824 : 0.009869021656839002\n",
      "Loss at iteration 825 : 0.00984485587098629\n",
      "Loss at iteration 826 : 0.009820776516267856\n",
      "Loss at iteration 827 : 0.009796783190425401\n",
      "Loss at iteration 828 : 0.009772875493480507\n",
      "Loss at iteration 829 : 0.009749053027719527\n",
      "Loss at iteration 830 : 0.009725315397678663\n",
      "Loss at iteration 831 : 0.00970166221012905\n",
      "Loss at iteration 832 : 0.009678093074062206\n",
      "Loss at iteration 833 : 0.009654607600675272\n",
      "Loss at iteration 834 : 0.00963120540335656\n",
      "Loss at iteration 835 : 0.009607886097671171\n",
      "Loss at iteration 836 : 0.009584649301346716\n",
      "Loss at iteration 837 : 0.009561494634259074\n",
      "Loss at iteration 838 : 0.00953842171841841\n",
      "Loss at iteration 839 : 0.009515430177955137\n",
      "Loss at iteration 840 : 0.009492519639106004\n",
      "Loss at iteration 841 : 0.009469689730200456\n",
      "Loss at iteration 842 : 0.009446940081646862\n",
      "Loss at iteration 843 : 0.009424270325919021\n",
      "Loss at iteration 844 : 0.00940168009754258\n",
      "Loss at iteration 845 : 0.009379169033081818\n",
      "Loss at iteration 846 : 0.009356736771126343\n",
      "Loss at iteration 847 : 0.009334382952277773\n",
      "Loss at iteration 848 : 0.009312107219136896\n",
      "Loss at iteration 849 : 0.00928990921629048\n",
      "Loss at iteration 850 : 0.009267788590298559\n",
      "Loss at iteration 851 : 0.009245744989681564\n",
      "Loss at iteration 852 : 0.00922377806490759\n",
      "Loss at iteration 853 : 0.009201887468379896\n",
      "Loss at iteration 854 : 0.009180072854424303\n",
      "Loss at iteration 855 : 0.009158333879276854\n",
      "Loss at iteration 856 : 0.009136670201071426\n",
      "Loss at iteration 857 : 0.00911508147982751\n",
      "Loss at iteration 858 : 0.009093567377438098\n",
      "Loss at iteration 859 : 0.009072127557657583\n",
      "Loss at iteration 860 : 0.00905076168608979\n",
      "Loss at iteration 861 : 0.0090294694301761\n",
      "Loss at iteration 862 : 0.009008250459183704\n",
      "Loss at iteration 863 : 0.008987104444193766\n",
      "Loss at iteration 864 : 0.008966031058089942\n",
      "Loss at iteration 865 : 0.008945029975546703\n",
      "Loss at iteration 866 : 0.008924100873017992\n",
      "Loss at iteration 867 : 0.00890324342872577\n",
      "Loss at iteration 868 : 0.008882457322648736\n",
      "Loss at iteration 869 : 0.008861742236511148\n",
      "Loss at iteration 870 : 0.008841097853771676\n",
      "Loss at iteration 871 : 0.00882052385961231\n",
      "Loss at iteration 872 : 0.008800019940927443\n",
      "Loss at iteration 873 : 0.008779585786312993\n",
      "Loss at iteration 874 : 0.008759221086055482\n",
      "Loss at iteration 875 : 0.008738925532121444\n",
      "Loss at iteration 876 : 0.008718698818146672\n",
      "Loss at iteration 877 : 0.008698540639425633\n",
      "Loss at iteration 878 : 0.00867845069290104\n",
      "Loss at iteration 879 : 0.008658428677153331\n",
      "Loss at iteration 880 : 0.008638474292390386\n",
      "Loss at iteration 881 : 0.008618587240437183\n",
      "Loss at iteration 882 : 0.008598767224725651\n",
      "Loss at iteration 883 : 0.008579013950284486\n",
      "Loss at iteration 884 : 0.008559327123729098\n",
      "Loss at iteration 885 : 0.008539706453251649\n",
      "Loss at iteration 886 : 0.008520151648611104\n",
      "Loss at iteration 887 : 0.008500662421123427\n",
      "Loss at iteration 888 : 0.00848123848365172\n",
      "Loss at iteration 889 : 0.008461879550596576\n",
      "Loss at iteration 890 : 0.00844258533788645\n",
      "Loss at iteration 891 : 0.008423355562968048\n",
      "Loss at iteration 892 : 0.00840418994479684\n",
      "Loss at iteration 893 : 0.008385088203827652\n",
      "Loss at iteration 894 : 0.008366050062005243\n",
      "Loss at iteration 895 : 0.008347075242755025\n",
      "Loss at iteration 896 : 0.008328163470973864\n",
      "Loss at iteration 897 : 0.008309314473020853\n",
      "Loss at iteration 898 : 0.008290527976708257\n",
      "Loss at iteration 899 : 0.008271803711292424\n",
      "Loss at iteration 900 : 0.008253141407464849\n",
      "Loss at iteration 901 : 0.008234540797343235\n",
      "Loss at iteration 902 : 0.008216001614462634\n",
      "Loss at iteration 903 : 0.00819752359376666\n",
      "Loss at iteration 904 : 0.008179106471598831\n",
      "Loss at iteration 905 : 0.00816074998569379\n",
      "Loss at iteration 906 : 0.008142453875168786\n",
      "Loss at iteration 907 : 0.008124217880515058\n",
      "Loss at iteration 908 : 0.008106041743589466\n",
      "Loss at iteration 909 : 0.008087925207605914\n",
      "Loss at iteration 910 : 0.008069868017127115\n",
      "Loss at iteration 911 : 0.00805186991805621\n",
      "Loss at iteration 912 : 0.008033930657628538\n",
      "Loss at iteration 913 : 0.00801604998440345\n",
      "Loss at iteration 914 : 0.0079982276482562\n",
      "Loss at iteration 915 : 0.007980463400369786\n",
      "Loss at iteration 916 : 0.007962756993227002\n",
      "Loss at iteration 917 : 0.007945108180602513\n",
      "Loss at iteration 918 : 0.007927516717554777\n",
      "Loss at iteration 919 : 0.007909982360418392\n",
      "Loss at iteration 920 : 0.007892504866796171\n",
      "Loss at iteration 921 : 0.007875083995551403\n",
      "Loss at iteration 922 : 0.007857719506800233\n",
      "Loss at iteration 923 : 0.007840411161903971\n",
      "Loss at iteration 924 : 0.00782315872346146\n",
      "Loss at iteration 925 : 0.00780596195530166\n",
      "Loss at iteration 926 : 0.007788820622476078\n",
      "Loss at iteration 927 : 0.007771734491251387\n",
      "Loss at iteration 928 : 0.007754703329101964\n",
      "Loss at iteration 929 : 0.007737726904702693\n",
      "Loss at iteration 930 : 0.007720804987921588\n",
      "Loss at iteration 931 : 0.0077039373498126226\n",
      "Loss at iteration 932 : 0.0076871237626084925\n",
      "Loss at iteration 933 : 0.007670363999713585\n",
      "Loss at iteration 934 : 0.007653657835696792\n",
      "Loss at iteration 935 : 0.007637005046284546\n",
      "Loss at iteration 936 : 0.007620405408353865\n",
      "Loss at iteration 937 : 0.007603858699925338\n",
      "Loss at iteration 938 : 0.007587364700156283\n",
      "Loss at iteration 939 : 0.007570923189333957\n",
      "Loss at iteration 940 : 0.007554533948868675\n",
      "Loss at iteration 941 : 0.007538196761287093\n",
      "Loss at iteration 942 : 0.007521911410225572\n",
      "Loss at iteration 943 : 0.007505677680423469\n",
      "Loss at iteration 944 : 0.007489495357716484\n",
      "Loss at iteration 945 : 0.007473364229030232\n",
      "Loss at iteration 946 : 0.0074572840823735964\n",
      "Loss at iteration 947 : 0.007441254706832313\n",
      "Loss at iteration 948 : 0.0074252758925625485\n",
      "Loss at iteration 949 : 0.00740934743078445\n",
      "Loss at iteration 950 : 0.007393469113775962\n",
      "Loss at iteration 951 : 0.00737764073486627\n",
      "Loss at iteration 952 : 0.007361862088429819\n",
      "Loss at iteration 953 : 0.007346132969879921\n",
      "Loss at iteration 954 : 0.0073304531756626335\n",
      "Loss at iteration 955 : 0.0073148225032506516\n",
      "Loss at iteration 956 : 0.0072992407511371805\n",
      "Loss at iteration 957 : 0.0072837077188299395\n",
      "Loss at iteration 958 : 0.007268223206845087\n",
      "Loss at iteration 959 : 0.007252787016701319\n",
      "Loss at iteration 960 : 0.007237398950913923\n",
      "Loss at iteration 961 : 0.007222058812988865\n",
      "Loss at iteration 962 : 0.007206766407416985\n",
      "Loss at iteration 963 : 0.007191521539668165\n",
      "Loss at iteration 964 : 0.007176324016185548\n",
      "Loss at iteration 965 : 0.0071611736443798965\n",
      "Loss at iteration 966 : 0.007146070232623742\n",
      "Loss at iteration 967 : 0.007131013590245914\n",
      "Loss at iteration 968 : 0.007116003527525764\n",
      "Loss at iteration 969 : 0.007101039855687717\n",
      "Loss at iteration 970 : 0.007086122386895645\n",
      "Loss at iteration 971 : 0.007071250934247425\n",
      "Loss at iteration 972 : 0.007056425311769433\n",
      "Loss at iteration 973 : 0.0070416453344111195\n",
      "Loss at iteration 974 : 0.007026910818039649\n",
      "Loss at iteration 975 : 0.007012221579434495\n",
      "Loss at iteration 976 : 0.006997577436282175\n",
      "Loss at iteration 977 : 0.0069829782071709\n",
      "Loss at iteration 978 : 0.006968423711585397\n",
      "Loss at iteration 979 : 0.00695391376990163\n",
      "Loss at iteration 980 : 0.006939448203381632\n",
      "Loss at iteration 981 : 0.0069250268341684105\n",
      "Loss at iteration 982 : 0.006910649485280766\n",
      "Loss at iteration 983 : 0.006896315980608242\n",
      "Loss at iteration 984 : 0.006882026144906097\n",
      "Loss at iteration 985 : 0.006867779803790267\n",
      "Loss at iteration 986 : 0.0068535767837324\n",
      "Loss at iteration 987 : 0.006839416912054918\n",
      "Loss at iteration 988 : 0.006825300016926068\n",
      "Loss at iteration 989 : 0.006811225927355099\n",
      "Loss at iteration 990 : 0.006797194473187355\n",
      "Loss at iteration 991 : 0.006783205485099518\n",
      "Loss at iteration 992 : 0.006769258794594753\n",
      "Loss at iteration 993 : 0.006755354233998017\n",
      "Loss at iteration 994 : 0.006741491636451328\n",
      "Loss at iteration 995 : 0.006727670835909012\n",
      "Loss at iteration 996 : 0.006713891667133145\n",
      "Loss at iteration 997 : 0.0067001539656888496\n",
      "Loss at iteration 998 : 0.006686457567939695\n",
      "Loss at iteration 999 : 0.006672802311043167\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"loss of learning rate 0.01: \",\n",
    ")\n",
    "loss_list_l2 = nn_l2.train(\n",
    "    np.array([[1, 0.91, 1.37]]),\n",
    "    np.array([[1, 0]]),\n",
    "    early_stopping=False,\n",
    "    epochs=no_of_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of learning rate 0.001: \n",
      "Loss at iteration 0 : 0.3507690180009263\n",
      "Loss at iteration 1 : 0.35067623608023424\n",
      "Loss at iteration 2 : 0.3505834358331547\n",
      "Loss at iteration 3 : 0.35049061728275865\n",
      "Loss at iteration 4 : 0.35039778045213704\n",
      "Loss at iteration 5 : 0.35030492536440067\n",
      "Loss at iteration 6 : 0.35021205204268063\n",
      "Loss at iteration 7 : 0.35011916051012787\n",
      "Loss at iteration 8 : 0.35002625078991356\n",
      "Loss at iteration 9 : 0.3499333229052286\n",
      "Loss at iteration 10 : 0.3498403768792839\n",
      "Loss at iteration 11 : 0.3497474127353104\n",
      "Loss at iteration 12 : 0.3496544304965589\n",
      "Loss at iteration 13 : 0.3495614301862999\n",
      "Loss at iteration 14 : 0.3494684118278244\n",
      "Loss at iteration 15 : 0.3493753754444424\n",
      "Loss at iteration 16 : 0.3492823210594845\n",
      "Loss at iteration 17 : 0.3491892486963005\n",
      "Loss at iteration 18 : 0.3490961583782604\n",
      "Loss at iteration 19 : 0.34900305012875366\n",
      "Loss at iteration 20 : 0.3489099239711898\n",
      "Loss at iteration 21 : 0.34881677992899784\n",
      "Loss at iteration 22 : 0.34872361802562674\n",
      "Loss at iteration 23 : 0.3486304382845446\n",
      "Loss at iteration 24 : 0.34853724072923986\n",
      "Loss at iteration 25 : 0.34844402538322017\n",
      "Loss at iteration 26 : 0.34835079227001303\n",
      "Loss at iteration 27 : 0.34825754141316523\n",
      "Loss at iteration 28 : 0.34816427283624346\n",
      "Loss at iteration 29 : 0.3480709865628339\n",
      "Loss at iteration 30 : 0.34797768261654216\n",
      "Loss at iteration 31 : 0.34788436102099335\n",
      "Loss at iteration 32 : 0.3477910217998321\n",
      "Loss at iteration 33 : 0.34769766497672244\n",
      "Loss at iteration 34 : 0.34760429057534803\n",
      "Loss at iteration 35 : 0.3475108986194117\n",
      "Loss at iteration 36 : 0.3474174891326361\n",
      "Loss at iteration 37 : 0.34732406213876277\n",
      "Loss at iteration 38 : 0.3472306176615527\n",
      "Loss at iteration 39 : 0.3471371557247867\n",
      "Loss at iteration 40 : 0.34704367635226413\n",
      "Loss at iteration 41 : 0.34695017956780416\n",
      "Loss at iteration 42 : 0.34685666539524496\n",
      "Loss at iteration 43 : 0.3467631338584445\n",
      "Loss at iteration 44 : 0.34666958498127914\n",
      "Loss at iteration 45 : 0.346576018787645\n",
      "Loss at iteration 46 : 0.3464824353014571\n",
      "Loss at iteration 47 : 0.34638883454664987\n",
      "Loss at iteration 48 : 0.34629521654717665\n",
      "Loss at iteration 49 : 0.34620158132701023\n",
      "Loss at iteration 50 : 0.34610792891014186\n",
      "Loss at iteration 51 : 0.3460142593205824\n",
      "Loss at iteration 52 : 0.34592057258236164\n",
      "Loss at iteration 53 : 0.34582686871952817\n",
      "Loss at iteration 54 : 0.34573314775614994\n",
      "Loss at iteration 55 : 0.3456394097163135\n",
      "Loss at iteration 56 : 0.3455456546241247\n",
      "Loss at iteration 57 : 0.34545188250370784\n",
      "Loss at iteration 58 : 0.3453580933792068\n",
      "Loss at iteration 59 : 0.3452642872747836\n",
      "Loss at iteration 60 : 0.34517046421461983\n",
      "Loss at iteration 61 : 0.3450766242229153\n",
      "Loss at iteration 62 : 0.34498276732388894\n",
      "Loss at iteration 63 : 0.3448888935417785\n",
      "Loss at iteration 64 : 0.3447950029008404\n",
      "Loss at iteration 65 : 0.34470109542534993\n",
      "Loss at iteration 66 : 0.3446071711396008\n",
      "Loss at iteration 67 : 0.3445132300679058\n",
      "Loss at iteration 68 : 0.344419272234596\n",
      "Loss at iteration 69 : 0.34432529766402137\n",
      "Loss at iteration 70 : 0.3442313063805506\n",
      "Loss at iteration 71 : 0.3441372984085708\n",
      "Loss at iteration 72 : 0.3440432737724878\n",
      "Loss at iteration 73 : 0.3439492324967256\n",
      "Loss at iteration 74 : 0.3438551746057271\n",
      "Loss at iteration 75 : 0.3437611001239539\n",
      "Loss at iteration 76 : 0.34366700907588543\n",
      "Loss at iteration 77 : 0.3435729014860202\n",
      "Loss at iteration 78 : 0.34347877737887494\n",
      "Loss at iteration 79 : 0.34338463677898456\n",
      "Loss at iteration 80 : 0.3432904797109028\n",
      "Loss at iteration 81 : 0.3431963061992014\n",
      "Loss at iteration 82 : 0.34310211626847065\n",
      "Loss at iteration 83 : 0.3430079099433189\n",
      "Loss at iteration 84 : 0.34291368724837323\n",
      "Loss at iteration 85 : 0.34281944820827853\n",
      "Loss at iteration 86 : 0.3427251928476982\n",
      "Loss at iteration 87 : 0.342630921191314\n",
      "Loss at iteration 88 : 0.3425366332638252\n",
      "Loss at iteration 89 : 0.34244232908995015\n",
      "Loss at iteration 90 : 0.34234800869442483\n",
      "Loss at iteration 91 : 0.3422536721020033\n",
      "Loss at iteration 92 : 0.34215931933745813\n",
      "Loss at iteration 93 : 0.34206495042557944\n",
      "Loss at iteration 94 : 0.3419705653911756\n",
      "Loss at iteration 95 : 0.34187616425907336\n",
      "Loss at iteration 96 : 0.3417817470541168\n",
      "Loss at iteration 97 : 0.3416873138011685\n",
      "Loss at iteration 98 : 0.34159286452510906\n",
      "Loss at iteration 99 : 0.34149839925083647\n",
      "Loss at iteration 100 : 0.3414039180032669\n",
      "Loss at iteration 101 : 0.3413094208073348\n",
      "Loss at iteration 102 : 0.34121490768799173\n",
      "Loss at iteration 103 : 0.34112037867020756\n",
      "Loss at iteration 104 : 0.3410258337789699\n",
      "Loss at iteration 105 : 0.34093127303928406\n",
      "Loss at iteration 106 : 0.34083669647617304\n",
      "Loss at iteration 107 : 0.340742104114678\n",
      "Loss at iteration 108 : 0.34064749597985694\n",
      "Loss at iteration 109 : 0.34055287209678653\n",
      "Loss at iteration 110 : 0.34045823249056034\n",
      "Loss at iteration 111 : 0.34036357718628996\n",
      "Loss at iteration 112 : 0.3402689062091043\n",
      "Loss at iteration 113 : 0.34017421958415045\n",
      "Loss at iteration 114 : 0.34007951733659203\n",
      "Loss at iteration 115 : 0.33998479949161137\n",
      "Loss at iteration 116 : 0.3398900660744073\n",
      "Loss at iteration 117 : 0.3397953171101965\n",
      "Loss at iteration 118 : 0.33970055262421345\n",
      "Loss at iteration 119 : 0.33960577264170955\n",
      "Loss at iteration 120 : 0.33951097718795376\n",
      "Loss at iteration 121 : 0.33941616628823257\n",
      "Loss at iteration 122 : 0.33932133996784947\n",
      "Loss at iteration 123 : 0.3392264982521256\n",
      "Loss at iteration 124 : 0.33913164116639943\n",
      "Loss at iteration 125 : 0.3390367687360264\n",
      "Loss at iteration 126 : 0.3389418809863793\n",
      "Loss at iteration 127 : 0.3388469779428482\n",
      "Loss at iteration 128 : 0.3387520596308405\n",
      "Loss at iteration 129 : 0.3386571260757804\n",
      "Loss at iteration 130 : 0.3385621773031097\n",
      "Loss at iteration 131 : 0.33846721333828683\n",
      "Loss at iteration 132 : 0.3383722342067878\n",
      "Loss at iteration 133 : 0.3382772399341052\n",
      "Loss at iteration 134 : 0.338182230545749\n",
      "Loss at iteration 135 : 0.33808720606724607\n",
      "Loss at iteration 136 : 0.33799216652414027\n",
      "Loss at iteration 137 : 0.33789711194199223\n",
      "Loss at iteration 138 : 0.33780204234638\n",
      "Loss at iteration 139 : 0.3377069577628981\n",
      "Loss at iteration 140 : 0.3376118582171579\n",
      "Loss at iteration 141 : 0.3375167437347879\n",
      "Loss at iteration 142 : 0.3374216143414334\n",
      "Loss at iteration 143 : 0.3373264700627564\n",
      "Loss at iteration 144 : 0.3372313109244356\n",
      "Loss at iteration 145 : 0.3371361369521664\n",
      "Loss at iteration 146 : 0.33704094817166114\n",
      "Loss at iteration 147 : 0.33694574460864885\n",
      "Loss at iteration 148 : 0.336850526288875\n",
      "Loss at iteration 149 : 0.336755293238102\n",
      "Loss at iteration 150 : 0.3366600454821086\n",
      "Loss at iteration 151 : 0.33656478304669013\n",
      "Loss at iteration 152 : 0.3364695059576588\n",
      "Loss at iteration 153 : 0.336374214240843\n",
      "Loss at iteration 154 : 0.336278907922088\n",
      "Loss at iteration 155 : 0.3361835870272549\n",
      "Loss at iteration 156 : 0.33608825158222205\n",
      "Loss at iteration 157 : 0.3359929016128837\n",
      "Loss at iteration 158 : 0.3358975371451506\n",
      "Loss at iteration 159 : 0.33580215820495\n",
      "Loss at iteration 160 : 0.3357067648182252\n",
      "Loss at iteration 161 : 0.33561135701093636\n",
      "Loss at iteration 162 : 0.3355159348090594\n",
      "Loss at iteration 163 : 0.33542049823858655\n",
      "Loss at iteration 164 : 0.33532504732552665\n",
      "Loss at iteration 165 : 0.3352295820959043\n",
      "Loss at iteration 166 : 0.3351341025757608\n",
      "Loss at iteration 167 : 0.33503860879115294\n",
      "Loss at iteration 168 : 0.33494310076815426\n",
      "Loss at iteration 169 : 0.33484757853285396\n",
      "Loss at iteration 170 : 0.33475204211135745\n",
      "Loss at iteration 171 : 0.3346564915297864\n",
      "Loss at iteration 172 : 0.33456092681427796\n",
      "Loss at iteration 173 : 0.3344653479909859\n",
      "Loss at iteration 174 : 0.3343697550860794\n",
      "Loss at iteration 175 : 0.33427414812574413\n",
      "Loss at iteration 176 : 0.3341785271361812\n",
      "Loss at iteration 177 : 0.33408289214360776\n",
      "Loss at iteration 178 : 0.33398724317425676\n",
      "Loss at iteration 179 : 0.33389158025437704\n",
      "Loss at iteration 180 : 0.33379590341023324\n",
      "Loss at iteration 181 : 0.33370021266810557\n",
      "Loss at iteration 182 : 0.33360450805429026\n",
      "Loss at iteration 183 : 0.33350878959509894\n",
      "Loss at iteration 184 : 0.3334130573168594\n",
      "Loss at iteration 185 : 0.33331731124591457\n",
      "Loss at iteration 186 : 0.33322155140862325\n",
      "Loss at iteration 187 : 0.33312577783135966\n",
      "Loss at iteration 188 : 0.3330299905405139\n",
      "Loss at iteration 189 : 0.33293418956249154\n",
      "Loss at iteration 190 : 0.3328383749237132\n",
      "Loss at iteration 191 : 0.3327425466506155\n",
      "Loss at iteration 192 : 0.33264670476965047\n",
      "Loss at iteration 193 : 0.3325508493072852\n",
      "Loss at iteration 194 : 0.33245498029000253\n",
      "Loss at iteration 195 : 0.33235909774430056\n",
      "Loss at iteration 196 : 0.3322632016966926\n",
      "Loss at iteration 197 : 0.33216729217370766\n",
      "Loss at iteration 198 : 0.3320713692018894\n",
      "Loss at iteration 199 : 0.33197543280779745\n",
      "Loss at iteration 200 : 0.33187948301800607\n",
      "Loss at iteration 201 : 0.3317835198591049\n",
      "Loss at iteration 202 : 0.33168754335769907\n",
      "Loss at iteration 203 : 0.3315915535404084\n",
      "Loss at iteration 204 : 0.3314955504338681\n",
      "Loss at iteration 205 : 0.33139953406472816\n",
      "Loss at iteration 206 : 0.331303504459654\n",
      "Loss at iteration 207 : 0.3312074616453259\n",
      "Loss at iteration 208 : 0.331111405648439\n",
      "Loss at iteration 209 : 0.3310153364957036\n",
      "Loss at iteration 210 : 0.33091925421384466\n",
      "Loss at iteration 211 : 0.33082315882960267\n",
      "Loss at iteration 212 : 0.3307270503697321\n",
      "Loss at iteration 213 : 0.33063092886100304\n",
      "Loss at iteration 214 : 0.33053479433020005\n",
      "Loss at iteration 215 : 0.3304386468041225\n",
      "Loss at iteration 216 : 0.3303424863095844\n",
      "Loss at iteration 217 : 0.330246312873415\n",
      "Loss at iteration 218 : 0.33015012652245757\n",
      "Loss at iteration 219 : 0.33005392728357036\n",
      "Loss at iteration 220 : 0.32995771518362627\n",
      "Loss at iteration 221 : 0.32986149024951317\n",
      "Loss at iteration 222 : 0.3297652525081329\n",
      "Loss at iteration 223 : 0.3296690019864019\n",
      "Loss at iteration 224 : 0.32957273871125187\n",
      "Loss at iteration 225 : 0.3294764627096281\n",
      "Loss at iteration 226 : 0.3293801740084908\n",
      "Loss at iteration 227 : 0.32928387263481446\n",
      "Loss at iteration 228 : 0.3291875586155883\n",
      "Loss at iteration 229 : 0.3290912319778155\n",
      "Loss at iteration 230 : 0.32899489274851396\n",
      "Loss at iteration 231 : 0.32889854095471543\n",
      "Loss at iteration 232 : 0.32880217662346634\n",
      "Loss at iteration 233 : 0.3287057997818273\n",
      "Loss at iteration 234 : 0.3286094104568731\n",
      "Loss at iteration 235 : 0.3285130086756926\n",
      "Loss at iteration 236 : 0.3284165944653891\n",
      "Loss at iteration 237 : 0.3283201678530799\n",
      "Loss at iteration 238 : 0.32822372886589624\n",
      "Loss at iteration 239 : 0.3281272775309838\n",
      "Loss at iteration 240 : 0.32803081387550187\n",
      "Loss at iteration 241 : 0.3279343379266242\n",
      "Loss at iteration 242 : 0.32783784971153834\n",
      "Loss at iteration 243 : 0.3277413492574454\n",
      "Loss at iteration 244 : 0.32764483659156124\n",
      "Loss at iteration 245 : 0.32754831174111493\n",
      "Loss at iteration 246 : 0.32745177473334974\n",
      "Loss at iteration 247 : 0.3273552255955224\n",
      "Loss at iteration 248 : 0.32725866435490414\n",
      "Loss at iteration 249 : 0.32716209103877925\n",
      "Loss at iteration 250 : 0.32706550567444603\n",
      "Loss at iteration 251 : 0.3269689082892167\n",
      "Loss at iteration 252 : 0.32687229891041675\n",
      "Loss at iteration 253 : 0.32677567756538584\n",
      "Loss at iteration 254 : 0.32667904428147676\n",
      "Loss at iteration 255 : 0.326582399086056\n",
      "Loss at iteration 256 : 0.326485742006504\n",
      "Loss at iteration 257 : 0.32638907307021414\n",
      "Loss at iteration 258 : 0.3262923923045936\n",
      "Loss at iteration 259 : 0.3261956997370633\n",
      "Loss at iteration 260 : 0.3260989953950569\n",
      "Loss at iteration 261 : 0.32600227930602227\n",
      "Loss at iteration 262 : 0.32590555149741995\n",
      "Loss at iteration 263 : 0.3258088119967243\n",
      "Loss at iteration 264 : 0.32571206083142273\n",
      "Loss at iteration 265 : 0.32561529802901595\n",
      "Loss at iteration 266 : 0.3255185236170182\n",
      "Loss at iteration 267 : 0.3254217376229568\n",
      "Loss at iteration 268 : 0.32532494007437185\n",
      "Loss at iteration 269 : 0.32522813099881714\n",
      "Loss at iteration 270 : 0.3251313104238594\n",
      "Loss at iteration 271 : 0.32503447837707866\n",
      "Loss at iteration 272 : 0.32493763488606736\n",
      "Loss at iteration 273 : 0.32484077997843175\n",
      "Loss at iteration 274 : 0.3247439136817905\n",
      "Loss at iteration 275 : 0.32464703602377576\n",
      "Loss at iteration 276 : 0.32455014703203217\n",
      "Loss at iteration 277 : 0.32445324673421766\n",
      "Loss at iteration 278 : 0.32435633515800255\n",
      "Loss at iteration 279 : 0.3242594123310705\n",
      "Loss at iteration 280 : 0.32416247828111777\n",
      "Loss at iteration 281 : 0.32406553303585334\n",
      "Loss at iteration 282 : 0.32396857662299894\n",
      "Loss at iteration 283 : 0.3238716090702892\n",
      "Loss at iteration 284 : 0.32377463040547133\n",
      "Loss at iteration 285 : 0.32367764065630517\n",
      "Loss at iteration 286 : 0.3235806398505631\n",
      "Loss at iteration 287 : 0.3234836280160303\n",
      "Loss at iteration 288 : 0.3233866051805043\n",
      "Loss at iteration 289 : 0.32328957137179537\n",
      "Loss at iteration 290 : 0.3231925266177262\n",
      "Loss at iteration 291 : 0.32309547094613156\n",
      "Loss at iteration 292 : 0.3229984043848592\n",
      "Loss at iteration 293 : 0.3229013269617693\n",
      "Loss at iteration 294 : 0.32280423870473396\n",
      "Loss at iteration 295 : 0.32270713964163766\n",
      "Loss at iteration 296 : 0.3226100298003777\n",
      "Loss at iteration 297 : 0.32251290920886316\n",
      "Loss at iteration 298 : 0.3224157778950155\n",
      "Loss at iteration 299 : 0.3223186358867683\n",
      "Loss at iteration 300 : 0.32222148321206756\n",
      "Loss at iteration 301 : 0.3221243198988712\n",
      "Loss at iteration 302 : 0.3220271459751493\n",
      "Loss at iteration 303 : 0.3219299614688841\n",
      "Loss at iteration 304 : 0.32183276640806985\n",
      "Loss at iteration 305 : 0.32173556082071275\n",
      "Loss at iteration 306 : 0.32163834473483094\n",
      "Loss at iteration 307 : 0.3215411181784547\n",
      "Loss at iteration 308 : 0.32144388117962625\n",
      "Loss at iteration 309 : 0.3213466337663994\n",
      "Loss at iteration 310 : 0.32124937596683983\n",
      "Loss at iteration 311 : 0.3211521078090256\n",
      "Loss at iteration 312 : 0.3210548293210458\n",
      "Loss at iteration 313 : 0.3209575405310019\n",
      "Loss at iteration 314 : 0.32086024146700665\n",
      "Loss at iteration 315 : 0.3207629321571847\n",
      "Loss at iteration 316 : 0.3206656126296722\n",
      "Loss at iteration 317 : 0.32056828291261724\n",
      "Loss at iteration 318 : 0.3204709430341792\n",
      "Loss at iteration 319 : 0.32037359302252916\n",
      "Loss at iteration 320 : 0.3202762329058496\n",
      "Loss at iteration 321 : 0.32017886271233476\n",
      "Loss at iteration 322 : 0.32008148247018997\n",
      "Loss at iteration 323 : 0.31998409220763224\n",
      "Loss at iteration 324 : 0.31988669195289\n",
      "Loss at iteration 325 : 0.3197892817342029\n",
      "Loss at iteration 326 : 0.31969186157982193\n",
      "Loss at iteration 327 : 0.31959443151800954\n",
      "Loss at iteration 328 : 0.31949699157703926\n",
      "Loss at iteration 329 : 0.31939954178519575\n",
      "Loss at iteration 330 : 0.31930208217077544\n",
      "Loss at iteration 331 : 0.3192046127620852\n",
      "Loss at iteration 332 : 0.31910713358744347\n",
      "Loss at iteration 333 : 0.31900964467517967\n",
      "Loss at iteration 334 : 0.3189121460536343\n",
      "Loss at iteration 335 : 0.3188146377511588\n",
      "Loss at iteration 336 : 0.3187171197961158\n",
      "Loss at iteration 337 : 0.3186195922168786\n",
      "Loss at iteration 338 : 0.31852205504183184\n",
      "Loss at iteration 339 : 0.3184245082993707\n",
      "Loss at iteration 340 : 0.3183269520179013\n",
      "Loss at iteration 341 : 0.3182293862258408\n",
      "Loss at iteration 342 : 0.3181318109516169\n",
      "Loss at iteration 343 : 0.31803422622366834\n",
      "Loss at iteration 344 : 0.31793663207044415\n",
      "Loss at iteration 345 : 0.31783902852040463\n",
      "Loss at iteration 346 : 0.3177414156020202\n",
      "Loss at iteration 347 : 0.31764379334377224\n",
      "Loss at iteration 348 : 0.3175461617741528\n",
      "Loss at iteration 349 : 0.31744852092166426\n",
      "Loss at iteration 350 : 0.31735087081481955\n",
      "Loss at iteration 351 : 0.31725321148214214\n",
      "Loss at iteration 352 : 0.3171555429521661\n",
      "Loss at iteration 353 : 0.31705786525343566\n",
      "Loss at iteration 354 : 0.31696017841450574\n",
      "Loss at iteration 355 : 0.31686248246394144\n",
      "Loss at iteration 356 : 0.3167647774303183\n",
      "Loss at iteration 357 : 0.31666706334222194\n",
      "Loss at iteration 358 : 0.31656934022824845\n",
      "Loss at iteration 359 : 0.31647160811700414\n",
      "Loss at iteration 360 : 0.31637386703710557\n",
      "Loss at iteration 361 : 0.316276117017179\n",
      "Loss at iteration 362 : 0.31617835808586153\n",
      "Loss at iteration 363 : 0.3160805902717997\n",
      "Loss at iteration 364 : 0.3159828136036504\n",
      "Loss at iteration 365 : 0.31588502811008085\n",
      "Loss at iteration 366 : 0.3157872338197676\n",
      "Loss at iteration 367 : 0.3156894307613976\n",
      "Loss at iteration 368 : 0.3155916189636677\n",
      "Loss at iteration 369 : 0.31549379845528447\n",
      "Loss at iteration 370 : 0.3153959692649646\n",
      "Loss at iteration 371 : 0.31529813142143415\n",
      "Loss at iteration 372 : 0.31520028495342933\n",
      "Loss at iteration 373 : 0.31510242988969617\n",
      "Loss at iteration 374 : 0.31500456625899\n",
      "Loss at iteration 375 : 0.31490669409007616\n",
      "Loss at iteration 376 : 0.3148088134117298\n",
      "Loss at iteration 377 : 0.314710924252735\n",
      "Loss at iteration 378 : 0.3146130266418861\n",
      "Loss at iteration 379 : 0.31451512060798686\n",
      "Loss at iteration 380 : 0.3144172061798504\n",
      "Loss at iteration 381 : 0.314319283386299\n",
      "Loss at iteration 382 : 0.3142213522561652\n",
      "Loss at iteration 383 : 0.31412341281829015\n",
      "Loss at iteration 384 : 0.314025465101525\n",
      "Loss at iteration 385 : 0.31392750913472967\n",
      "Loss at iteration 386 : 0.31382954494677373\n",
      "Loss at iteration 387 : 0.31373157256653594\n",
      "Loss at iteration 388 : 0.3136335920229044\n",
      "Loss at iteration 389 : 0.3135356033447762\n",
      "Loss at iteration 390 : 0.31343760656105774\n",
      "Loss at iteration 391 : 0.3133396017006644\n",
      "Loss at iteration 392 : 0.31324158879252095\n",
      "Loss at iteration 393 : 0.31314356786556086\n",
      "Loss at iteration 394 : 0.313045538948727\n",
      "Loss at iteration 395 : 0.3129475020709708\n",
      "Loss at iteration 396 : 0.3128494572612529\n",
      "Loss at iteration 397 : 0.3127514045485431\n",
      "Loss at iteration 398 : 0.3126533439618196\n",
      "Loss at iteration 399 : 0.3125552755300698\n",
      "Loss at iteration 400 : 0.3124571992822896\n",
      "Loss at iteration 401 : 0.312359115247484\n",
      "Loss at iteration 402 : 0.3122610234546667\n",
      "Loss at iteration 403 : 0.31216292393286005\n",
      "Loss at iteration 404 : 0.3120648167110948\n",
      "Loss at iteration 405 : 0.3119667018184109\n",
      "Loss at iteration 406 : 0.3118685792838565\n",
      "Loss at iteration 407 : 0.3117704491364884\n",
      "Loss at iteration 408 : 0.3116723114053721\n",
      "Loss at iteration 409 : 0.3115741661195812\n",
      "Loss at iteration 410 : 0.3114760133081983\n",
      "Loss at iteration 411 : 0.3113778530003141\n",
      "Loss at iteration 412 : 0.31127968522502775\n",
      "Loss at iteration 413 : 0.31118151001144684\n",
      "Loss at iteration 414 : 0.3110833273886872\n",
      "Loss at iteration 415 : 0.31098513738587286\n",
      "Loss at iteration 416 : 0.31088694003213635\n",
      "Loss at iteration 417 : 0.31078873535661833\n",
      "Loss at iteration 418 : 0.31069052338846737\n",
      "Loss at iteration 419 : 0.3105923041568407\n",
      "Loss at iteration 420 : 0.31049407769090326\n",
      "Loss at iteration 421 : 0.3103958440198284\n",
      "Loss at iteration 422 : 0.3102976031727968\n",
      "Loss at iteration 423 : 0.31019935517899827\n",
      "Loss at iteration 424 : 0.3101011000676297\n",
      "Loss at iteration 425 : 0.3100028378678961\n",
      "Loss at iteration 426 : 0.3099045686090108\n",
      "Loss at iteration 427 : 0.30980629232019435\n",
      "Loss at iteration 428 : 0.30970800903067564\n",
      "Loss at iteration 429 : 0.3096097187696912\n",
      "Loss at iteration 430 : 0.30951142156648515\n",
      "Loss at iteration 431 : 0.30941311745030964\n",
      "Loss at iteration 432 : 0.3093148064504241\n",
      "Loss at iteration 433 : 0.3092164885960963\n",
      "Loss at iteration 434 : 0.30911816391660085\n",
      "Loss at iteration 435 : 0.3090198324412204\n",
      "Loss at iteration 436 : 0.3089214941992449\n",
      "Loss at iteration 437 : 0.308823149219972\n",
      "Loss at iteration 438 : 0.3087247975327069\n",
      "Loss at iteration 439 : 0.3086264391667619\n",
      "Loss at iteration 440 : 0.30852807415145717\n",
      "Loss at iteration 441 : 0.3084297025161197\n",
      "Loss at iteration 442 : 0.3083313242900842\n",
      "Loss at iteration 443 : 0.30823293950269254\n",
      "Loss at iteration 444 : 0.308134548183294\n",
      "Loss at iteration 445 : 0.3080361503612448\n",
      "Loss at iteration 446 : 0.3079377460659087\n",
      "Loss at iteration 447 : 0.30783933532665625\n",
      "Loss at iteration 448 : 0.3077409181728653\n",
      "Loss at iteration 449 : 0.30764249463392096\n",
      "Loss at iteration 450 : 0.30754406473921486\n",
      "Loss at iteration 451 : 0.3074456285181462\n",
      "Loss at iteration 452 : 0.30734718600012106\n",
      "Loss at iteration 453 : 0.307248737214552\n",
      "Loss at iteration 454 : 0.3071502821908591\n",
      "Loss at iteration 455 : 0.3070518209584687\n",
      "Loss at iteration 456 : 0.3069533535468145\n",
      "Loss at iteration 457 : 0.3068548799853368\n",
      "Loss at iteration 458 : 0.3067564003034824\n",
      "Loss at iteration 459 : 0.3066579145307051\n",
      "Loss at iteration 460 : 0.30655942269646563\n",
      "Loss at iteration 461 : 0.30646092483023063\n",
      "Loss at iteration 462 : 0.3063624209614741\n",
      "Loss at iteration 463 : 0.30626391111967605\n",
      "Loss at iteration 464 : 0.3061653953343234\n",
      "Loss at iteration 465 : 0.3060668736349095\n",
      "Loss at iteration 466 : 0.30596834605093404\n",
      "Loss at iteration 467 : 0.30586981261190327\n",
      "Loss at iteration 468 : 0.30577127334732984\n",
      "Loss at iteration 469 : 0.3056727282867325\n",
      "Loss at iteration 470 : 0.30557417745963666\n",
      "Loss at iteration 471 : 0.305475620895574\n",
      "Loss at iteration 472 : 0.305377058624082\n",
      "Loss at iteration 473 : 0.30527849067470486\n",
      "Loss at iteration 474 : 0.3051799170769928\n",
      "Loss at iteration 475 : 0.30508133786050207\n",
      "Loss at iteration 476 : 0.3049827530547952\n",
      "Loss at iteration 477 : 0.3048841626894406\n",
      "Loss at iteration 478 : 0.30478556679401286\n",
      "Loss at iteration 479 : 0.3046869653980925\n",
      "Loss at iteration 480 : 0.30458835853126587\n",
      "Loss at iteration 481 : 0.3044897462231256\n",
      "Loss at iteration 482 : 0.30439112850326977\n",
      "Loss at iteration 483 : 0.3042925054013025\n",
      "Loss at iteration 484 : 0.3041938769468339\n",
      "Loss at iteration 485 : 0.30409524316947967\n",
      "Loss at iteration 486 : 0.30399660409886115\n",
      "Loss at iteration 487 : 0.30389795976460554\n",
      "Loss at iteration 488 : 0.3037993101963457\n",
      "Loss at iteration 489 : 0.30370065542372\n",
      "Loss at iteration 490 : 0.3036019954763725\n",
      "Loss at iteration 491 : 0.3035033303839529\n",
      "Loss at iteration 492 : 0.303404660176116\n",
      "Loss at iteration 493 : 0.30330598488252275\n",
      "Loss at iteration 494 : 0.303207304532839\n",
      "Loss at iteration 495 : 0.30310861915673626\n",
      "Loss at iteration 496 : 0.3030099287838913\n",
      "Loss at iteration 497 : 0.3029112334439863\n",
      "Loss at iteration 498 : 0.3028125331667087\n",
      "Loss at iteration 499 : 0.3027138279817512\n",
      "Loss at iteration 500 : 0.30261511791881174\n",
      "Loss at iteration 501 : 0.3025164030075933\n",
      "Loss at iteration 502 : 0.30241768327780416\n",
      "Loss at iteration 503 : 0.3023189587591581\n",
      "Loss at iteration 504 : 0.30222022948137317\n",
      "Loss at iteration 505 : 0.30212149547417283\n",
      "Loss at iteration 506 : 0.30202275676728574\n",
      "Loss at iteration 507 : 0.30192401339044533\n",
      "Loss at iteration 508 : 0.30182526537338994\n",
      "Loss at iteration 509 : 0.30172651274586293\n",
      "Loss at iteration 510 : 0.30162775553761245\n",
      "Loss at iteration 511 : 0.3015289937783913\n",
      "Loss at iteration 512 : 0.30143022749795734\n",
      "Loss at iteration 513 : 0.3013314567260731\n",
      "Loss at iteration 514 : 0.3012326814925056\n",
      "Loss at iteration 515 : 0.30113390182702665\n",
      "Loss at iteration 516 : 0.30103511775941305\n",
      "Loss at iteration 517 : 0.30093632931944553\n",
      "Loss at iteration 518 : 0.3008375365369101\n",
      "Loss at iteration 519 : 0.3007387394415965\n",
      "Loss at iteration 520 : 0.30063993806329964\n",
      "Loss at iteration 521 : 0.30054113243181857\n",
      "Loss at iteration 522 : 0.3004423225769567\n",
      "Loss at iteration 523 : 0.300343508528522\n",
      "Loss at iteration 524 : 0.3002446903163266\n",
      "Loss at iteration 525 : 0.30014586797018705\n",
      "Loss at iteration 526 : 0.30004704151992423\n",
      "Loss at iteration 527 : 0.299948210995363\n",
      "Loss at iteration 528 : 0.2998493764263325\n",
      "Loss at iteration 529 : 0.29975053784266625\n",
      "Loss at iteration 530 : 0.2996516952742015\n",
      "Loss at iteration 531 : 0.29955284875077987\n",
      "Loss at iteration 532 : 0.2994539983022469\n",
      "Loss at iteration 533 : 0.2993551439584522\n",
      "Loss at iteration 534 : 0.29925628574924906\n",
      "Loss at iteration 535 : 0.2991574237044951\n",
      "Loss at iteration 536 : 0.2990585578540517\n",
      "Loss at iteration 537 : 0.29895968822778407\n",
      "Loss at iteration 538 : 0.2988608148555611\n",
      "Loss at iteration 539 : 0.29876193776725557\n",
      "Loss at iteration 540 : 0.298663056992744\n",
      "Loss at iteration 541 : 0.2985641725619067\n",
      "Loss at iteration 542 : 0.29846528450462745\n",
      "Loss at iteration 543 : 0.2983663928507939\n",
      "Loss at iteration 544 : 0.2982674976302969\n",
      "Loss at iteration 545 : 0.29816859887303143\n",
      "Loss at iteration 546 : 0.2980696966088954\n",
      "Loss at iteration 547 : 0.29797079086779077\n",
      "Loss at iteration 548 : 0.2978718816796222\n",
      "Loss at iteration 549 : 0.2977729690742985\n",
      "Loss at iteration 550 : 0.2976740530817314\n",
      "Loss at iteration 551 : 0.2975751337318361\n",
      "Loss at iteration 552 : 0.2974762110545312\n",
      "Loss at iteration 553 : 0.29737728507973826\n",
      "Loss at iteration 554 : 0.2972783558373823\n",
      "Loss at iteration 555 : 0.2971794233573914\n",
      "Loss at iteration 556 : 0.297080487669697\n",
      "Loss at iteration 557 : 0.2969815488042332\n",
      "Loss at iteration 558 : 0.2968826067909377\n",
      "Loss at iteration 559 : 0.29678366165975084\n",
      "Loss at iteration 560 : 0.2966847134406161\n",
      "Loss at iteration 561 : 0.29658576216347976\n",
      "Loss at iteration 562 : 0.29648680785829135\n",
      "Loss at iteration 563 : 0.29638785055500294\n",
      "Loss at iteration 564 : 0.2962888902835697\n",
      "Loss at iteration 565 : 0.2961899270739493\n",
      "Loss at iteration 566 : 0.29609096095610243\n",
      "Loss at iteration 567 : 0.2959919919599923\n",
      "Loss at iteration 568 : 0.2958930201155852\n",
      "Loss at iteration 569 : 0.29579404545284976\n",
      "Loss at iteration 570 : 0.2956950680017571\n",
      "Loss at iteration 571 : 0.2955960877922812\n",
      "Loss at iteration 572 : 0.29549710485439845\n",
      "Loss at iteration 573 : 0.29539811921808784\n",
      "Loss at iteration 574 : 0.29529913091333065\n",
      "Loss at iteration 575 : 0.2952001399701107\n",
      "Loss at iteration 576 : 0.2951011464184142\n",
      "Loss at iteration 577 : 0.29500215028822974\n",
      "Loss at iteration 578 : 0.2949031516095483\n",
      "Loss at iteration 579 : 0.2948041504123626\n",
      "Loss at iteration 580 : 0.2947051467266684\n",
      "Loss at iteration 581 : 0.2946061405824631\n",
      "Loss at iteration 582 : 0.29450713200974665\n",
      "Loss at iteration 583 : 0.29440812103852054\n",
      "Loss at iteration 584 : 0.2943091076987891\n",
      "Loss at iteration 585 : 0.29421009202055803\n",
      "Loss at iteration 586 : 0.2941110740338356\n",
      "Loss at iteration 587 : 0.2940120537686315\n",
      "Loss at iteration 588 : 0.293913031254958\n",
      "Loss at iteration 589 : 0.29381400652282863\n",
      "Loss at iteration 590 : 0.2937149796022592\n",
      "Loss at iteration 591 : 0.2936159505232672\n",
      "Loss at iteration 592 : 0.2935169193158719\n",
      "Loss at iteration 593 : 0.2934178860100943\n",
      "Loss at iteration 594 : 0.29331885063595725\n",
      "Loss at iteration 595 : 0.29321981322348517\n",
      "Loss at iteration 596 : 0.29312077380270396\n",
      "Loss at iteration 597 : 0.29302173240364143\n",
      "Loss at iteration 598 : 0.2929226890563266\n",
      "Loss at iteration 599 : 0.29282364379079057\n",
      "Loss at iteration 600 : 0.29272459663706507\n",
      "Loss at iteration 601 : 0.2926255476251841\n",
      "Loss at iteration 602 : 0.2925264967851825\n",
      "Loss at iteration 603 : 0.2924274441470968\n",
      "Loss at iteration 604 : 0.2923283897409649\n",
      "Loss at iteration 605 : 0.29222933359682574\n",
      "Loss at iteration 606 : 0.2921302757447195\n",
      "Loss at iteration 607 : 0.29203121621468797\n",
      "Loss at iteration 608 : 0.29193215503677356\n",
      "Loss at iteration 609 : 0.29183309224102033\n",
      "Loss at iteration 610 : 0.29173402785747327\n",
      "Loss at iteration 611 : 0.2916349619161782\n",
      "Loss at iteration 612 : 0.2915358944471824\n",
      "Loss at iteration 613 : 0.2914368254805338\n",
      "Loss at iteration 614 : 0.29133775504628134\n",
      "Loss at iteration 615 : 0.291238683174475\n",
      "Loss at iteration 616 : 0.29113960989516563\n",
      "Loss at iteration 617 : 0.2910405352384048\n",
      "Loss at iteration 618 : 0.29094145923424475\n",
      "Loss at iteration 619 : 0.29084238191273903\n",
      "Loss at iteration 620 : 0.29074330330394127\n",
      "Loss at iteration 621 : 0.29064422343790614\n",
      "Loss at iteration 622 : 0.29054514234468903\n",
      "Loss at iteration 623 : 0.2904460600543456\n",
      "Loss at iteration 624 : 0.29034697659693237\n",
      "Loss at iteration 625 : 0.29024789200250634\n",
      "Loss at iteration 626 : 0.2901488063011249\n",
      "Loss at iteration 627 : 0.29004971952284614\n",
      "Loss at iteration 628 : 0.2899506316977283\n",
      "Loss at iteration 629 : 0.2898515428558301\n",
      "Loss at iteration 630 : 0.2897524530272107\n",
      "Loss at iteration 631 : 0.28965336224192934\n",
      "Loss at iteration 632 : 0.28955427053004595\n",
      "Loss at iteration 633 : 0.2894551779216202\n",
      "Loss at iteration 634 : 0.28935608444671207\n",
      "Loss at iteration 635 : 0.2892569901353821\n",
      "Loss at iteration 636 : 0.28915789501769057\n",
      "Loss at iteration 637 : 0.28905879912369775\n",
      "Loss at iteration 638 : 0.28895970248346425\n",
      "Loss at iteration 639 : 0.2888606051270507\n",
      "Loss at iteration 640 : 0.2887615070845172\n",
      "Loss at iteration 641 : 0.2886624083859244\n",
      "Loss at iteration 642 : 0.2885633090613325\n",
      "Loss at iteration 643 : 0.28846420914080173\n",
      "Loss at iteration 644 : 0.2883651086543918\n",
      "Loss at iteration 645 : 0.2882660076321627\n",
      "Loss at iteration 646 : 0.28816690610417367\n",
      "Loss at iteration 647 : 0.28806780410048394\n",
      "Loss at iteration 648 : 0.2879687016511524\n",
      "Loss at iteration 649 : 0.2878695987862375\n",
      "Loss at iteration 650 : 0.2877704955357971\n",
      "Loss at iteration 651 : 0.28767139192988883\n",
      "Loss at iteration 652 : 0.2875722879985699\n",
      "Loss at iteration 653 : 0.28747318377189685\n",
      "Loss at iteration 654 : 0.2873740792799257\n",
      "Loss at iteration 655 : 0.28727497455271167\n",
      "Loss at iteration 656 : 0.2871758696203096\n",
      "Loss at iteration 657 : 0.2870767645127737\n",
      "Loss at iteration 658 : 0.2869776592601572\n",
      "Loss at iteration 659 : 0.2868785538925127\n",
      "Loss at iteration 660 : 0.2867794484398921\n",
      "Loss at iteration 661 : 0.2866803429323463\n",
      "Loss at iteration 662 : 0.28658123739992547\n",
      "Loss at iteration 663 : 0.2864821318726788\n",
      "Loss at iteration 664 : 0.28638302638065444\n",
      "Loss at iteration 665 : 0.28628392095389976\n",
      "Loss at iteration 666 : 0.28618481562246106\n",
      "Loss at iteration 667 : 0.28608571041638364\n",
      "Loss at iteration 668 : 0.2859866053657113\n",
      "Loss at iteration 669 : 0.28588750050048733\n",
      "Loss at iteration 670 : 0.2857883958507532\n",
      "Loss at iteration 671 : 0.2856892914465498\n",
      "Loss at iteration 672 : 0.28559018731791636\n",
      "Loss at iteration 673 : 0.28549108349489083\n",
      "Loss at iteration 674 : 0.2853919800075101\n",
      "Loss at iteration 675 : 0.2852928768858094\n",
      "Loss at iteration 676 : 0.2851937741598226\n",
      "Loss at iteration 677 : 0.2850946718595826\n",
      "Loss at iteration 678 : 0.28499557001512016\n",
      "Loss at iteration 679 : 0.28489646865646484\n",
      "Loss at iteration 680 : 0.2847973678136448\n",
      "Loss at iteration 681 : 0.2846982675166862\n",
      "Loss at iteration 682 : 0.284599167795614\n",
      "Loss at iteration 683 : 0.28450006868045113\n",
      "Loss at iteration 684 : 0.2844009702012192\n",
      "Loss at iteration 685 : 0.2843018723879376\n",
      "Loss at iteration 686 : 0.28420277527062443\n",
      "Loss at iteration 687 : 0.28410367887929566\n",
      "Loss at iteration 688 : 0.28400458324396544\n",
      "Loss at iteration 689 : 0.2839054883946464\n",
      "Loss at iteration 690 : 0.2838063943613484\n",
      "Loss at iteration 691 : 0.28370730117408033\n",
      "Loss at iteration 692 : 0.2836082088628484\n",
      "Loss at iteration 693 : 0.28350911745765695\n",
      "Loss at iteration 694 : 0.28341002698850826\n",
      "Loss at iteration 695 : 0.2833109374854025\n",
      "Loss at iteration 696 : 0.2832118489783378\n",
      "Loss at iteration 697 : 0.2831127614973098\n",
      "Loss at iteration 698 : 0.2830136750723121\n",
      "Loss at iteration 699 : 0.28291458973333605\n",
      "Loss at iteration 700 : 0.28281550551037066\n",
      "Loss at iteration 701 : 0.28271642243340256\n",
      "Loss at iteration 702 : 0.28261734053241594\n",
      "Loss at iteration 703 : 0.28251825983739276\n",
      "Loss at iteration 704 : 0.2824191803783122\n",
      "Loss at iteration 705 : 0.2823201021851514\n",
      "Loss at iteration 706 : 0.2822210252878844\n",
      "Loss at iteration 707 : 0.2821219497164833\n",
      "Loss at iteration 708 : 0.2820228755009168\n",
      "Loss at iteration 709 : 0.28192380267115197\n",
      "Loss at iteration 710 : 0.2818247312571522\n",
      "Loss at iteration 711 : 0.28172566128887866\n",
      "Loss at iteration 712 : 0.28162659279628993\n",
      "Loss at iteration 713 : 0.281527525809341\n",
      "Loss at iteration 714 : 0.28142846035798513\n",
      "Loss at iteration 715 : 0.2813293964721718\n",
      "Loss at iteration 716 : 0.281230334181848\n",
      "Loss at iteration 717 : 0.2811312735169577\n",
      "Loss at iteration 718 : 0.28103221450744165\n",
      "Loss at iteration 719 : 0.2809331571832381\n",
      "Loss at iteration 720 : 0.2808341015742817\n",
      "Loss at iteration 721 : 0.28073504771050417\n",
      "Loss at iteration 722 : 0.2806359956218343\n",
      "Loss at iteration 723 : 0.28053694533819734\n",
      "Loss at iteration 724 : 0.2804378968895157\n",
      "Loss at iteration 725 : 0.2803388503057082\n",
      "Loss at iteration 726 : 0.28023980561669065\n",
      "Loss at iteration 727 : 0.2801407628523751\n",
      "Loss at iteration 728 : 0.28004172204267086\n",
      "Loss at iteration 729 : 0.27994268321748333\n",
      "Loss at iteration 730 : 0.2798436464067147\n",
      "Loss at iteration 731 : 0.27974461164026365\n",
      "Loss at iteration 732 : 0.2796455789480253\n",
      "Loss at iteration 733 : 0.279546548359891\n",
      "Loss at iteration 734 : 0.27944751990574906\n",
      "Loss at iteration 735 : 0.2793484936154837\n",
      "Loss at iteration 736 : 0.2792494695189755\n",
      "Loss at iteration 737 : 0.27915044764610164\n",
      "Loss at iteration 738 : 0.27905142802673527\n",
      "Loss at iteration 739 : 0.2789524106907458\n",
      "Loss at iteration 740 : 0.27885339566799894\n",
      "Loss at iteration 741 : 0.2787543829883563\n",
      "Loss at iteration 742 : 0.27865537268167595\n",
      "Loss at iteration 743 : 0.27855636477781176\n",
      "Loss at iteration 744 : 0.2784573593066138\n",
      "Loss at iteration 745 : 0.27835835629792793\n",
      "Loss at iteration 746 : 0.2782593557815962\n",
      "Loss at iteration 747 : 0.2781603577874563\n",
      "Loss at iteration 748 : 0.2780613623453422\n",
      "Loss at iteration 749 : 0.2779623694850833\n",
      "Loss at iteration 750 : 0.277863379236505\n",
      "Loss at iteration 751 : 0.27776439162942845\n",
      "Loss at iteration 752 : 0.27766540669367074\n",
      "Loss at iteration 753 : 0.27756642445904406\n",
      "Loss at iteration 754 : 0.277467444955357\n",
      "Loss at iteration 755 : 0.2773684682124131\n",
      "Loss at iteration 756 : 0.2772694942600122\n",
      "Loss at iteration 757 : 0.2771705231279489\n",
      "Loss at iteration 758 : 0.27707155484601387\n",
      "Loss at iteration 759 : 0.276972589443993\n",
      "Loss at iteration 760 : 0.2768736269516677\n",
      "Loss at iteration 761 : 0.2767746673988148\n",
      "Loss at iteration 762 : 0.2766757108152063\n",
      "Loss at iteration 763 : 0.27657675723060976\n",
      "Loss at iteration 764 : 0.27647780667478794\n",
      "Loss at iteration 765 : 0.27637885917749877\n",
      "Loss at iteration 766 : 0.27627991476849534\n",
      "Loss at iteration 767 : 0.2761809734775263\n",
      "Loss at iteration 768 : 0.27608203533433484\n",
      "Loss at iteration 769 : 0.27598310036865964\n",
      "Loss at iteration 770 : 0.2758841686102344\n",
      "Loss at iteration 771 : 0.27578524008878785\n",
      "Loss at iteration 772 : 0.2756863148340435\n",
      "Loss at iteration 773 : 0.27558739287572004\n",
      "Loss at iteration 774 : 0.27548847424353096\n",
      "Loss at iteration 775 : 0.2753895589671846\n",
      "Loss at iteration 776 : 0.2752906470763843\n",
      "Loss at iteration 777 : 0.27519173860082785\n",
      "Loss at iteration 778 : 0.2750928335702082\n",
      "Loss at iteration 779 : 0.2749939320142129\n",
      "Loss at iteration 780 : 0.274895033962524\n",
      "Loss at iteration 781 : 0.2747961394448184\n",
      "Loss at iteration 782 : 0.27469724849076754\n",
      "Loss at iteration 783 : 0.2745983611300373\n",
      "Loss at iteration 784 : 0.27449947739228847\n",
      "Loss at iteration 785 : 0.27440059730717603\n",
      "Loss at iteration 786 : 0.2743017209043495\n",
      "Loss at iteration 787 : 0.27420284821345287\n",
      "Loss at iteration 788 : 0.27410397926412433\n",
      "Loss at iteration 789 : 0.27400511408599676\n",
      "Loss at iteration 790 : 0.27390625270869706\n",
      "Loss at iteration 791 : 0.27380739516184655\n",
      "Loss at iteration 792 : 0.27370854147506085\n",
      "Loss at iteration 793 : 0.2736096916779495\n",
      "Loss at iteration 794 : 0.2735108458001165\n",
      "Loss at iteration 795 : 0.2734120038711599\n",
      "Loss at iteration 796 : 0.2733131659206718\n",
      "Loss at iteration 797 : 0.2732143319782384\n",
      "Loss at iteration 798 : 0.27311550207344\n",
      "Loss at iteration 799 : 0.2730166762358506\n",
      "Loss at iteration 800 : 0.2729178544950385\n",
      "Loss at iteration 801 : 0.27281903688056564\n",
      "Loss at iteration 802 : 0.27272022342198804\n",
      "Loss at iteration 803 : 0.2726214141488553\n",
      "Loss at iteration 804 : 0.2725226090907111\n",
      "Loss at iteration 805 : 0.27242380827709256\n",
      "Loss at iteration 806 : 0.272325011737531\n",
      "Loss at iteration 807 : 0.27222621950155107\n",
      "Loss at iteration 808 : 0.2721274315986709\n",
      "Loss at iteration 809 : 0.2720286480584029\n",
      "Loss at iteration 810 : 0.2719298689102522\n",
      "Loss at iteration 811 : 0.2718310941837183\n",
      "Loss at iteration 812 : 0.2717323239082936\n",
      "Loss at iteration 813 : 0.2716335581134641\n",
      "Loss at iteration 814 : 0.2715347968287097\n",
      "Loss at iteration 815 : 0.27143604008350286\n",
      "Loss at iteration 816 : 0.2713372879073101\n",
      "Loss at iteration 817 : 0.27123854032959105\n",
      "Loss at iteration 818 : 0.27113979737979854\n",
      "Loss at iteration 819 : 0.2710410590873787\n",
      "Loss at iteration 820 : 0.2709423254817707\n",
      "Loss at iteration 821 : 0.2708435965924073\n",
      "Loss at iteration 822 : 0.27074487244871404\n",
      "Loss at iteration 823 : 0.2706461530801097\n",
      "Loss at iteration 824 : 0.2705474385160062\n",
      "Loss at iteration 825 : 0.2704487287858081\n",
      "Loss at iteration 826 : 0.27035002391891355\n",
      "Loss at iteration 827 : 0.27025132394471324\n",
      "Loss at iteration 828 : 0.2701526288925909\n",
      "Loss at iteration 829 : 0.27005393879192313\n",
      "Loss at iteration 830 : 0.2699552536720793\n",
      "Loss at iteration 831 : 0.26985657356242193\n",
      "Loss at iteration 832 : 0.2697578984923057\n",
      "Loss at iteration 833 : 0.26965922849107876\n",
      "Loss at iteration 834 : 0.2695605635880812\n",
      "Loss at iteration 835 : 0.26946190381264673\n",
      "Loss at iteration 836 : 0.26936324919410043\n",
      "Loss at iteration 837 : 0.26926459976176115\n",
      "Loss at iteration 838 : 0.2691659555449398\n",
      "Loss at iteration 839 : 0.2690673165729395\n",
      "Loss at iteration 840 : 0.2689686828750565\n",
      "Loss at iteration 841 : 0.26887005448057905\n",
      "Loss at iteration 842 : 0.26877143141878784\n",
      "Loss at iteration 843 : 0.2686728137189564\n",
      "Loss at iteration 844 : 0.2685742014103499\n",
      "Loss at iteration 845 : 0.2684755945222263\n",
      "Loss at iteration 846 : 0.2683769930838355\n",
      "Loss at iteration 847 : 0.26827839712442\n",
      "Loss at iteration 848 : 0.2681798066732142\n",
      "Loss at iteration 849 : 0.268081221759445\n",
      "Loss at iteration 850 : 0.26798264241233094\n",
      "Loss at iteration 851 : 0.26788406866108294\n",
      "Loss at iteration 852 : 0.2677855005349039\n",
      "Loss at iteration 853 : 0.26768693806298893\n",
      "Loss at iteration 854 : 0.2675883812745247\n",
      "Loss at iteration 855 : 0.2674898301986904\n",
      "Loss at iteration 856 : 0.2673912848646566\n",
      "Loss at iteration 857 : 0.26729274530158587\n",
      "Loss at iteration 858 : 0.267194211538633\n",
      "Loss at iteration 859 : 0.267095683604944\n",
      "Loss at iteration 860 : 0.26699716152965697\n",
      "Loss at iteration 861 : 0.2668986453419017\n",
      "Loss at iteration 862 : 0.26680013507079975\n",
      "Loss at iteration 863 : 0.2667016307454643\n",
      "Loss at iteration 864 : 0.2666031323949999\n",
      "Loss at iteration 865 : 0.266504640048503\n",
      "Loss at iteration 866 : 0.2664061537350614\n",
      "Loss at iteration 867 : 0.2663076734837545\n",
      "Loss at iteration 868 : 0.2662091993236534\n",
      "Loss at iteration 869 : 0.26611073128382023\n",
      "Loss at iteration 870 : 0.2660122693933088\n",
      "Loss at iteration 871 : 0.2659138136811641\n",
      "Loss at iteration 872 : 0.2658153641764227\n",
      "Loss at iteration 873 : 0.2657169209081124\n",
      "Loss at iteration 874 : 0.26561848390525183\n",
      "Loss at iteration 875 : 0.2655200531968516\n",
      "Loss at iteration 876 : 0.26542162881191317\n",
      "Loss at iteration 877 : 0.2653232107794289\n",
      "Loss at iteration 878 : 0.2652247991283825\n",
      "Loss at iteration 879 : 0.265126393887749\n",
      "Loss at iteration 880 : 0.265027995086494\n",
      "Loss at iteration 881 : 0.26492960275357447\n",
      "Loss at iteration 882 : 0.26483121691793854\n",
      "Loss at iteration 883 : 0.2647328376085245\n",
      "Loss at iteration 884 : 0.26463446485426234\n",
      "Loss at iteration 885 : 0.2645360986840728\n",
      "Loss at iteration 886 : 0.26443773912686697\n",
      "Loss at iteration 887 : 0.26433938621154734\n",
      "Loss at iteration 888 : 0.2642410399670069\n",
      "Loss at iteration 889 : 0.2641427004221292\n",
      "Loss at iteration 890 : 0.2640443676057888\n",
      "Loss at iteration 891 : 0.2639460415468508\n",
      "Loss at iteration 892 : 0.263847722274171\n",
      "Loss at iteration 893 : 0.2637494098165956\n",
      "Loss at iteration 894 : 0.2636511042029617\n",
      "Loss at iteration 895 : 0.26355280546209653\n",
      "Loss at iteration 896 : 0.2634545136228179\n",
      "Loss at iteration 897 : 0.26335622871393455\n",
      "Loss at iteration 898 : 0.2632579507642449\n",
      "Loss at iteration 899 : 0.26315967980253824\n",
      "Loss at iteration 900 : 0.2630614158575942\n",
      "Loss at iteration 901 : 0.2629631589581824\n",
      "Loss at iteration 902 : 0.26286490913306315\n",
      "Loss at iteration 903 : 0.26276666641098667\n",
      "Loss at iteration 904 : 0.2626684308206936\n",
      "Loss at iteration 905 : 0.26257020239091455\n",
      "Loss at iteration 906 : 0.2624719811503705\n",
      "Loss at iteration 907 : 0.2623737671277726\n",
      "Loss at iteration 908 : 0.2622755603518217\n",
      "Loss at iteration 909 : 0.2621773608512089\n",
      "Loss at iteration 910 : 0.2620791686546154\n",
      "Loss at iteration 911 : 0.2619809837907123\n",
      "Loss at iteration 912 : 0.26188280628816035\n",
      "Loss at iteration 913 : 0.2617846361756108\n",
      "Loss at iteration 914 : 0.2616864734817041\n",
      "Loss at iteration 915 : 0.26158831823507117\n",
      "Loss at iteration 916 : 0.261490170464332\n",
      "Loss at iteration 917 : 0.26139203019809715\n",
      "Loss at iteration 918 : 0.2612938974649663\n",
      "Loss at iteration 919 : 0.26119577229352897\n",
      "Loss at iteration 920 : 0.2610976547123644\n",
      "Loss at iteration 921 : 0.26099954475004145\n",
      "Loss at iteration 922 : 0.26090144243511865\n",
      "Loss at iteration 923 : 0.26080334779614384\n",
      "Loss at iteration 924 : 0.2607052608616546\n",
      "Loss at iteration 925 : 0.2606071816601779\n",
      "Loss at iteration 926 : 0.2605091102202304\n",
      "Loss at iteration 927 : 0.26041104657031744\n",
      "Loss at iteration 928 : 0.26031299073893477\n",
      "Loss at iteration 929 : 0.26021494275456675\n",
      "Loss at iteration 930 : 0.2601169026456873\n",
      "Loss at iteration 931 : 0.2600188704407598\n",
      "Loss at iteration 932 : 0.25992084616823635\n",
      "Loss at iteration 933 : 0.25982282985655886\n",
      "Loss at iteration 934 : 0.25972482153415793\n",
      "Loss at iteration 935 : 0.2596268212294538\n",
      "Loss at iteration 936 : 0.2595288289708553\n",
      "Loss at iteration 937 : 0.2594308447867607\n",
      "Loss at iteration 938 : 0.2593328687055572\n",
      "Loss at iteration 939 : 0.25923490075562095\n",
      "Loss at iteration 940 : 0.25913694096531725\n",
      "Loss at iteration 941 : 0.25903898936300007\n",
      "Loss at iteration 942 : 0.2589410459770125\n",
      "Loss at iteration 943 : 0.25884311083568645\n",
      "Loss at iteration 944 : 0.25874518396734253\n",
      "Loss at iteration 945 : 0.2586472654002904\n",
      "Loss at iteration 946 : 0.25854935516282845\n",
      "Loss at iteration 947 : 0.2584514532832436\n",
      "Loss at iteration 948 : 0.2583535597898116\n",
      "Loss at iteration 949 : 0.258255674710797\n",
      "Loss at iteration 950 : 0.25815779807445277\n",
      "Loss at iteration 951 : 0.25805992990902055\n",
      "Loss at iteration 952 : 0.2579620702427307\n",
      "Loss at iteration 953 : 0.25786421910380186\n",
      "Loss at iteration 954 : 0.25776637652044143\n",
      "Loss at iteration 955 : 0.25766854252084503\n",
      "Loss at iteration 956 : 0.257570717133197\n",
      "Loss at iteration 957 : 0.2574729003856698\n",
      "Loss at iteration 958 : 0.2573750923064244\n",
      "Loss at iteration 959 : 0.25727729292361007\n",
      "Loss at iteration 960 : 0.2571795022653645\n",
      "Loss at iteration 961 : 0.2570817203598136\n",
      "Loss at iteration 962 : 0.25698394723507123\n",
      "Loss at iteration 963 : 0.25688618291924\n",
      "Loss at iteration 964 : 0.2567884274404102\n",
      "Loss at iteration 965 : 0.2566906808266604\n",
      "Loss at iteration 966 : 0.2565929431060574\n",
      "Loss at iteration 967 : 0.2564952143066559\n",
      "Loss at iteration 968 : 0.2563974944564989\n",
      "Loss at iteration 969 : 0.25629978358361716\n",
      "Loss at iteration 970 : 0.25620208171602943\n",
      "Loss at iteration 971 : 0.2561043888817424\n",
      "Loss at iteration 972 : 0.25600670510875084\n",
      "Loss at iteration 973 : 0.2559090304250372\n",
      "Loss at iteration 974 : 0.2558113648585718\n",
      "Loss at iteration 975 : 0.2557137084373129\n",
      "Loss at iteration 976 : 0.25561606118920643\n",
      "Loss at iteration 977 : 0.25551842314218604\n",
      "Loss at iteration 978 : 0.255420794324173\n",
      "Loss at iteration 979 : 0.25532317476307653\n",
      "Loss at iteration 980 : 0.2552255644867934\n",
      "Loss at iteration 981 : 0.25512796352320777\n",
      "Loss at iteration 982 : 0.25503037190019145\n",
      "Loss at iteration 983 : 0.2549327896456042\n",
      "Loss at iteration 984 : 0.2548352167872927\n",
      "Loss at iteration 985 : 0.25473765335309145\n",
      "Loss at iteration 986 : 0.2546400993708224\n",
      "Loss at iteration 987 : 0.25454255486829486\n",
      "Loss at iteration 988 : 0.2544450198733054\n",
      "Loss at iteration 989 : 0.2543474944136382\n",
      "Loss at iteration 990 : 0.2542499785170644\n",
      "Loss at iteration 991 : 0.2541524722113429\n",
      "Loss at iteration 992 : 0.25405497552421946\n",
      "Loss at iteration 993 : 0.2539574884834271\n",
      "Loss at iteration 994 : 0.2538600111166862\n",
      "Loss at iteration 995 : 0.2537625434517043\n",
      "Loss at iteration 996 : 0.25366508551617584\n",
      "Loss at iteration 997 : 0.25356763733778265\n",
      "Loss at iteration 998 : 0.25347019894419326\n",
      "Loss at iteration 999 : 0.25337277036306366\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"loss of learning rate 0.001: \",\n",
    ")\n",
    "loss_list_l3 = nn_l3.train(\n",
    "    np.array([[1, 0.91, 1.37]]), np.array([[1, 0]]), early_stopping=False, epochs=no_of_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list,    label=\"Learning Rate 1\")\n",
    "plt.plot(loss_list_l1, label=\"Learning Rate 0.1\")\n",
    "plt.plot(loss_list_l2, label=\"Learning Rate 0.01\")\n",
    "plt.plot(loss_list_l3, label=\"Learning Rate 0.001\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epochs for different Learning Rates\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
